---
aliases:
  - authorities and hubs
  - authority and hub
  - HITS
  - HITS algorithm
  - HITS algorithms
  - Hyperlink Induced Topic Search
  - Hyperlink-Induced Topic Search
  - hub and authority
  - hubs and authorities
  - hyperlink induced topic search
  - hyperlink-induced topic search
tags:
  - flashcard/active/general/HITS_algorithm
  - language/in/English
---

# HITS algorithm

## algorithm

### steps

In the HITS algorithm, the 1st step is {@{retrieving the most relevant pages to the search query}@}. This set is called {@{the _root set_ and may be obtained by taking the top pages returned by a text-based search algorithm}@}. Then, a larger set called {@{the _base set_}@} is generated by {@{adding to the root set all web pages linked from the root set and some web pages linking to the root set}@}. The base set and its hyperlinks form {@{a _focused subgraph_ of the entire web}@}. The HITS algorithm is {@{performed only on this focused subgraph}@}.

Authority and hub are defined {@{in terms of one another in [mutual recursion](mutual%20recursion.md)}@}. The authority value of a page is {@{computed as the sum of the scaled hub values that point to that page}@}. The hub value of a page is {@{computed as the sum of the scaled authority values the page points to}@}.

The algorithm performs {@{a series of iterations}@}, consisting of {@{2 main steps, starting with the authority update}@}:

1. __authority update__ ::@:: Update each node's authority value to the sum of the hub values of nodes pointing to it.
2. __hub update__ ::@:: Update each node's hub value to the sum of the authority values of nodes it points to.

There are {@{2 variants of the algorithm}@}: {@{async iteration and sync iteration}@}, with the former being more common. Both variants with other steps are described below:

1. __initialization__ ::@:: Start with each node having an authority value and hub value of 1. Optionally, normalize the values like in step 4 for convergence.
2. __authority update__ ::@:: Run the authority update rule.
3. __hub update__ ::@:: Run the hub update rule. For async iteration, the authority values are taken from step 2. For sync iteration, the authority values are taken from _before_ step 2.
4. __normalization__ ::@:: Optionally, normalize the values for convergence. Treat the authority values and hub values of all nodes as 2 vectors. Normalize their lengths ([norms](norm%20(mathematics).md)) to either 1 or the number of nodes. One could use the [taxicab norm](norm%20(mathematics).md#taxicab%20norm%20or%20Manhattan%20norm) (_p_ = 1), the conventional [Euclidean norm](norm%20(mathematics).md#Euclidean%20norm) (_p_ = 2), or the very general [_p_-norm](norm%20(mathematics).md#_p_-norm).
5. __repeat__ ::@:: Repeat from the 2nd step as necessary.

Finally, after {@{the values have converged or after a predetermined number of iterations}@}, the authority values and hub values are {@{used for ranking}@}. Note that HITS {@{does not specify how the values are used}@}. Possible ways to use the values are {@{rank in descending authority value only, rank in descending hub value only, or rank in descending sum of authority value and hub value, etc.}@} {@{This rather arbitrary usage of authority and hub values}@} is one of the disadvantages of HITS, which is resolved by {@{[PageRank](PageRank.md)}@}.

## in detail

After obtaining {@{the base set}@}, let the _n_ pages be {@{$p_1, \ldots, p_n$}@}. Store the authority values $a(p)$ and node values $h(p)$ {@{in an authority column vector $\mathbf{A} = \begin{bmatrix} a(p_1) & \cdots & a(p_n) \end{bmatrix}^\intercal$ and a hub column vector $\mathbf{H} = \begin{bmatrix} h(p_1) & \cdots & h(p_n) \end{bmatrix}^\intercal$ respectively}@}. Initialize {@{the 2 column vectors to either all 1}@}. Optionally, {@{[normalize](#normalization) the initial values}@}.

To help with the update rules, construct {@{a [directed adjacency matrix](adjacency%20matrix.md#directed%20graphs) $\mathbf{M}$ representing links between the pages}@}. The matrix element $\mathbf{M}_{i, j}$ {@{is 1 iff $p_i$ is linked to $p_j$, and otherwise 0}@}.

Let $k$ be {@{the current number of iterations}@}, and $\mathbf{A}_k$ and $\mathbf{H}_k$ be {@{the authority and hub column vectors that are outputted by the current iteration}@}. $\mathbf{A}_0$ and $\mathbf{H}_0$ are {@{the initial values, after normalization if any}@}.

### authority update rule

For each $p$, we {@{update $a(p)$ to $a(p) = \sum_{q \in p_{\text{to} } } h(q)$ where $p_{\text{to} }$ are all pages linking to $p$}@}. That is, a page's authority value is {@{the sum of the hub values of nodes pointing to it}@}. This can also be expressed {@{using [matrix multiplication](matrix%20multiplication.md)}@}: {@{$\mathbf{A}_k \gets \mathbf{M}^\intercal \mathbf{H}_{k - 1}$}@}.

Consider the authority vector after several updates (without normalization):

| iteration | async                                                                                                                                                                                                            | sync                                                                                                                                                                                                      |
| --------- | ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------:| ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------:|
| 0         | $\mathbf{A}_0$                                                                                                                                                                                                   | $\mathbf{A}_0$                                                                                                                                                                                            |
| 1         | $\mathbf{A}_1 \gets \mathbf{M}^\intercal \mathbf{H}_0$                                                                                                                                                           | $\mathbf{A}_1 \gets \mathbf{M}^\intercal \mathbf{H}_0$                                                                                                                                                    |
| 2         | $\mathbf{A}_2 \gets \mathbf{M}^\intercal \mathbf{H}_1 = \mathbf{M}^\intercal \mathbf{M} \mathbf{A}_1 = \left(\mathbf{M}^\intercal \mathbf{M}\right)^1 \mathbf{M}^\intercal \mathbf{H}_0$                         | $\mathbf{A}_2 \gets \mathbf{M}^\intercal \mathbf{H}_1 = \left(\mathbf{M}^\intercal \mathbf{M}\right)^1 \mathbf{A}_0$                                                                                      |
| 3         | $\mathbf{A}_3 \gets \mathbf{M}^\intercal \mathbf{H}_2 = \mathbf{M}^\intercal \mathbf{M} \mathbf{A}_2 = \left(\mathbf{M}^\intercal \mathbf{M}\right)^2 \mathbf{M}^\intercal \mathbf{H}_0$                         | $\mathbf{A}_3 \gets \mathbf{M}^\intercal \mathbf{H}_2 = \mathbf{M}^\intercal \mathbf{M} \mathbf{A}_1 = \left(\mathbf{M}^\intercal \mathbf{M}\right)^1 \mathbf{M}^\intercal \mathbf{H}_0$                  |
| 4         | $\mathbf{A}_4 \gets \mathbf{M}^\intercal \mathbf{H}_3 = \mathbf{M}^\intercal \mathbf{M} \mathbf{A}_3 = \left(\mathbf{M}^\intercal \mathbf{M}\right)^3 \mathbf{M}^\intercal \mathbf{H}_0$                         | $\mathbf{A}_4 \gets \mathbf{M}^\intercal \mathbf{H}_3 = \mathbf{M}^\intercal \mathbf{M} \mathbf{A}_2 = \left(\mathbf{M}^\intercal \mathbf{M}\right)^2 \mathbf{A}_0$                                       |
| 5         | $\mathbf{A}_5 \gets \mathbf{M}^\intercal \mathbf{H}_4 = \mathbf{M}^\intercal \mathbf{M} \mathbf{A}_4 = \left(\mathbf{M}^\intercal \mathbf{M}\right)^4 \mathbf{M}^\intercal \mathbf{H}_0$                         | $\mathbf{A}_5 \gets \mathbf{M}^\intercal \mathbf{H}_4 = \mathbf{M}^\intercal \mathbf{M} \mathbf{A}_3 = \left(\mathbf{M}^\intercal \mathbf{M}\right)^2 \mathbf{M}^\intercal \mathbf{H}_0$                  |
| 6         | $\mathbf{A}_6 \gets \mathbf{M}^\intercal \mathbf{H}_5 = \mathbf{M}^\intercal \mathbf{M} \mathbf{A}_5 = \left(\mathbf{M}^\intercal \mathbf{M}\right)^5 \mathbf{M}^\intercal \mathbf{H}_0$                         | $\mathbf{A}_6 \gets \mathbf{M}^\intercal \mathbf{H}_5 = \mathbf{M}^\intercal \mathbf{M} \mathbf{A}_4 = \left(\mathbf{M}^\intercal \mathbf{M}\right)^3 \mathbf{A}_0$                                       |
| ⋮         | ⋮                                                                                                                                                                                                                | ⋮                                                                                                                                                                                                         |
| $2n$      | $\mathbf{A}_{2n} \gets \mathbf{M}^\intercal \mathbf{H}_{2n - 1} = \mathbf{M}^\intercal \mathbf{M} \mathbf{A}_{2n - 1} = \left(\mathbf{M}^\intercal \mathbf{M}\right)^{2n - 1} \mathbf{M}^\intercal \mathbf{H}_0$ | $\mathbf{A}_{2n} \gets \mathbf{M}^\intercal \mathbf{H}_{2n - 1} = \mathbf{M}^\intercal \mathbf{M} \mathbf{A}_{2n - 2} = \left(\mathbf{M}^\intercal \mathbf{M}\right)^n \mathbf{A}_0$                      |
| $2n + 1$  | $\mathbf{A}_{2n + 1} \gets \mathbf{M}^\intercal \mathbf{H}_{2n} = \mathbf{M}^\intercal \mathbf{M} \mathbf{A}_{2n} = \left(\mathbf{M}^\intercal \mathbf{M}\right)^{2n} \mathbf{M}^\intercal \mathbf{H}_0$         | $\mathbf{A}_{2n + 1} \gets \mathbf{M}^\intercal \mathbf{H}_{2n} = \mathbf{M}^\intercal \mathbf{M} \mathbf{A}_{2n - 1} = \left(\mathbf{M}^\intercal \mathbf{M}\right)^n \mathbf{M}^\intercal \mathbf{H}_0$ |

From the table above, we can obtain {@{a closed expression and a recursive expression}@}. Let {@{$\mathbf{A}_1 \gets \mathbf{M}^\intercal \mathbf{H}_0$}@}. For async iteration, the expressions are {@{$$\begin{aligned} \mathbf{A}_k & \gets \left(\mathbf{M}^\intercal \mathbf{M}\right)^{k - 1} \mathbf{A}_1 \\ \mathbf{A}_k & \gets \mathbf{M}^\intercal \mathbf{M} \mathbf{A}_{k - 1} \end{aligned}$$}@}. For sync iteration, the expressions are {@{$$\begin{aligned} \mathbf{A}_{2k} & \gets \left(\mathbf{M}^\intercal \mathbf{M}\right)^k \mathbf{A}_0 \\ \mathbf{A}_{2k + 1} & \gets \left(\mathbf{M}^\intercal \mathbf{M}\right)^k \mathbf{A}_1 \\ \mathbf{A}_k & \gets \mathbf{M}^\intercal \mathbf{M} \mathbf{A}_{k - 2} \end{aligned}$$}@}.

Notice that both iterations involve {@{left multiplying the authority vector by $\mathbf{M}^\intercal \mathbf{M}$ repeatedly}@}. This is how computation is done in practice. Mathematically, this is also known as {@{[power iteration](power%20iteration.md)}@}. By this, if {@{the authority vector is [normalized](#normalization) after each iteration}@}, then the authority vector {@{tends to the normalized principal [eigenvector](eigenvalues%20and%20eigenvectors.md) (the normalized eigenvector with the largest eigenvalue) of $\mathbf{M}^\intercal \mathbf{M}$ regardless of the starting initial values}@}.

### hub update rule

For each $p$, we {@{update $h(p)$ to $h(p) = \sum_{q \in p_{\text{from} } } a(q)$ where $p_{\text{from} }$ are all pages linked from $p$}@}. That is, a page's hub value is {@{the sum of the authority values of nodes it points to}@}. This can also be expressed {@{using [matrix multiplication](matrix%20multiplication.md)}@}: {@{$\mathbf{H}_k \gets \mathbf{M} \mathbf{A}_k$ for async iteration and $\mathbf{H}_k \gets \mathbf{M} \mathbf{A}_{k - 1}$ for sync iteration}@}.

Consider the hub vector after several updates (without normalization):

| iteration | async                                                                                                                                                                             | sync                                                                                                                                                                                  |
| --------- | ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------:| -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------:|
| 0         | $\mathbf{H}_0$                                                                                                                                                                    | $\mathbf{H}_0$                                                                                                                                                                        |
| 1         | $\mathbf{H}_1 \gets \mathbf{M} \mathbf{A}_1 = \left(\mathbf{M} \mathbf{M}^\intercal\right)^1 \mathbf{H}_0$                                                                        | $\mathbf{H}_1 \gets \mathbf{M} \mathbf{A}_0$                                                                                                                                          |
| 2         | $\mathbf{H}_2 \gets \mathbf{M} \mathbf{A}_2 = \mathbf{M} \mathbf{M}^\intercal \mathbf{H}_1 = \left(\mathbf{M} \mathbf{M}^\intercal\right)^2 \mathbf{H}_0$                         | $\mathbf{H}_2 \gets \mathbf{M} \mathbf{A}_1 = \left(\mathbf{M} \mathbf{M}^\intercal\right)^1 \mathbf{H}_0$                                                                            |
| 3         | $\mathbf{H}_3 \gets \mathbf{M} \mathbf{A}_3 = \mathbf{M} \mathbf{M}^\intercal \mathbf{H}_2 = \left(\mathbf{M} \mathbf{M}^\intercal\right)^3 \mathbf{H}_0$                         | $\mathbf{H}_3 \gets \mathbf{M} \mathbf{A}_2 = \mathbf{M} \mathbf{M}^\intercal \mathbf{H}_1 = \left(\mathbf{M} \mathbf{M}^\intercal \right)^1 \mathbf{M} \mathbf{A}_0$                 |
| 4         | $\mathbf{H}_4 \gets \mathbf{M} \mathbf{A}_4 = \mathbf{M} \mathbf{M}^\intercal \mathbf{H}_3 = \left(\mathbf{M} \mathbf{M}^\intercal\right)^4 \mathbf{H}_0$                         | $\mathbf{H}_4 \gets \mathbf{M} \mathbf{A}_3 = \mathbf{M} \mathbf{M}^\intercal \mathbf{H}_2 = \left(\mathbf{M} \mathbf{M}^\intercal \right)^2 \mathbf{H}_0$                            |
| 5         | $\mathbf{H}_5 \gets \mathbf{M} \mathbf{A}_5 = \mathbf{M} \mathbf{M}^\intercal \mathbf{H}_4 = \left(\mathbf{M} \mathbf{M}^\intercal\right)^5 \mathbf{H}_0$                         | $\mathbf{H}_5 \gets \mathbf{M} \mathbf{A}_4 = \mathbf{M} \mathbf{M}^\intercal \mathbf{H}_3 = \left(\mathbf{M} \mathbf{M}^\intercal \right)^2 \mathbf{M} \mathbf{A}_0$                 |
| 6         | $\mathbf{H}_6 \gets \mathbf{M} \mathbf{A}_6 = \mathbf{M} \mathbf{M}^\intercal \mathbf{H}_5 = \left(\mathbf{M} \mathbf{M}^\intercal\right)^6 \mathbf{H}_0$                         | $\mathbf{H}_6 \gets \mathbf{M} \mathbf{A}_5 = \mathbf{M} \mathbf{M}^\intercal \mathbf{H}_4 = \left(\mathbf{M} \mathbf{M}^\intercal \right)^3 \mathbf{H}_0$                            |
| ⋮         | ⋮                                                                                                                                                                                 | ⋮                                                                                                                                                                                     |
| $2n$      | $\mathbf{H}_{2n} \gets \mathbf{M} \mathbf{A}_{2n} = \mathbf{M} \mathbf{M}^\intercal \mathbf{H}_{2n - 1} = \left(\mathbf{M} \mathbf{M}^\intercal\right)^{2n} \mathbf{H}_0$         | $\mathbf{H}_{2n} \gets \mathbf{M} \mathbf{A}_{2n - 1} = \mathbf{M} \mathbf{M}^\intercal \mathbf{H}_{2n - 2} = \left(\mathbf{M} \mathbf{M}^\intercal\right)^n \mathbf{H}_0$            |
| $2n + 1$  | $\mathbf{H}_{2n + 1} \gets \mathbf{M} \mathbf{A}_{2n + 1} = \mathbf{M} \mathbf{M}^\intercal \mathbf{H}_{2n} = \left(\mathbf{M} \mathbf{M}^\intercal\right)^{2n + 1} \mathbf{H}_0$ | $\mathbf{H}_{2n + 1} \gets \mathbf{M} \mathbf{A}_{2n} = \mathbf{M} \mathbf{M}^\intercal \mathbf{H}_{2n - 1} = \left(\mathbf{M} \mathbf{M}^\intercal\right)^n \mathbf{M} \mathbf{A}_0$ |

From the table above, we can obtain {@{a closed expression and a recursive expression}@}. Let {@{$\mathbf{H}_1 \gets \mathbf{M} \mathbf{A}_0$ for sync iteration only}@}. For async iteration, the expressions are {@{$$\begin{aligned} \mathbf{H}_k & \gets \left(\mathbf{M} \mathbf{M}^\intercal\right)^k \mathbf{H}_0 \\ \mathbf{H}_k & \gets \mathbf{M} \mathbf{M}^\intercal \mathbf{H}_{k - 1} \end{aligned}$$}@}. For sync iteration, the expressions are {@{$$\begin{aligned} \mathbf{H}_{2k} & \gets \left(\mathbf{M} \mathbf{M}^\intercal\right)^k \mathbf{H}_0 \\ \mathbf{H}_{2k + 1} & \gets \left(\mathbf{M} \mathbf{M}^\intercal\right)^k \mathbf{H}_1 \\ \mathbf{H}_k & \gets \mathbf{M} \mathbf{M}^\intercal \mathbf{H}_{k - 2} \end{aligned}$$}@}.

Notice that both iterations involve {@{left multiplying the hub vector by $\mathbf{M} \mathbf{M}^\intercal$ repeatedly}@}. This is how computation is done in practice. Mathematically, this is also known as {@{[power iteration](power%20iteration.md)}@}. By this, if {@{the hub vector is [normalized](#normalization) after each iteration}@}, then the hub vector {@{tends to the normalized principal [eigenvector](eigenvalues%20and%20eigenvectors.md) (the normalized eigenvector with the largest eigenvalue) of $\mathbf{M} \mathbf{M}^\intercal$ regardless of the starting initial values}@}.

### normalization

The authority or hub vector can be normalized by {@{dividing the vector by its length ([norm](norm%20(mathematics).md))}@}. Afterwards, the length {@{of the vector will be 1}@}.

The length is {@{usually defined as the [taxicab norm](norm%20(mathematics).md#taxicab%20norm%20or%20Manhattan%20norm) (_p_ = 1) or the conventional [Euclidean norm](norm%20(mathematics).md#Euclidean%20norm) (_p_ = 2)}@}. In the former, length is {@{the sum of absolute values of vector elements}@}. In the latter, length is {@{the square root of sum of squares of vector elements}@}. Both are {@{generalized by the [_p_-norm](norm%20(mathematics).md#_p_-norm)}@}: {@{$$\lVert \mathbf{x} \rVert_p := \left(\sum_{i = 1}^n \lvert x_i \rvert^p \right)^{\frac 1 p}$$}@}.

When using the taxicab norm, some may also choose to {@{normalize the vector length to the number of pages _n_ instead of 1}@}, which mathematically is {@{multiplying the above normalized vector by _n_}@}.

## references

This text incorporates [content](https://en.wikipedia.org/wiki/HITS_algorithm) from [Wikipedia](Wikipedia.md) available under the [CC BY-SA 4.0](https://creativecommons.org/licenses/by-sa/4.0/) license.
