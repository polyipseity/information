---
aliases:
  - Gaussian process
  - Gaussian processes
tags:
  - flashcard/active/general/eng/Gaussian_process
  - language/in/English
---

# Gaussian process

In {@{[probability theory](probability%20theory.md) and [statistics](statistics.md)}@}, {@{a __Gaussian process__}@} is {@{a [stochastic process](stochastic%20process.md) \(a collection of random variables indexed by time or space\)}@}, such that {@{every finite collection of those random variables has a [multivariate normal distribution](multivariate%20normal%20distribution.md)}@}. {@{The distribution of a Gaussian process}@} is {@{the [joint distribution](joint%20distribution.md) of all those \(infinitely many\) random variables}@}, and as such, it is {@{a distribution over functions with a continuous domain, e.g. time or space}@}. <!--SR:!2026-02-22,18,321!2026-04-14,66,310!2026-02-21,17,325!2026-02-22,18,329!2026-02-18,14,290!2026-02-20,16,316!2026-02-21,17,324-->

{@{The concept of Gaussian processes}@} is named after {@{[Carl Friedrich Gauss](Carl%20Friedrich%20Gauss.md) because it is based on the notion of the Gaussian distribution \([normal distribution](normal%20distribution.md)\)}@}. Gaussian processes can be seen as {@{an infinite-dimensional generalization of multivariate normal distributions}@}. <!--SR:!2026-02-22,18,325!2026-05-03,83,345!2026-02-20,17,316-->

Gaussian processes are useful in {@{[statistical modelling](statistical%20model.md)}@}, benefiting from properties {@{inherited from the normal distribution}@}. For example, if {@{a [random process](random%20process.md) is modelled as a Gaussian process}@}, {@{the distributions of various derived quantities}@} can be obtained explicitly. Such quantities include {@{the average value of the process}@} over {@{a range of times}@} and {@{the error in estimating the average}@} using {@{sample values at a small set of times}@}. While exact models often {@{scale poorly as the amount of data increases}@}, {@{multiple [approximation methods](gaussian%20process%20approximations.md)}@} have been developed which often retain {@{good accuracy while drastically reducing computation time}@}. <!--SR:!2026-02-22,18,321!2026-04-15,67,310!2026-02-22,18,325!2026-05-02,82,345!2026-04-21,73,336!2026-02-20,16,321!2026-02-19,15,316!2026-02-22,18,325!2026-04-13,65,310!2026-02-19,15,290!2026-02-19,15,290-->

## definition

{@{A time continuous [stochastic process](stochastic%20process.md) $\left\{X_{t};t\in T\right\}$ is Gaussian}@} {@{[if and only if](if%20and%20only%20if.md) for every [finite set](finite%20set.md) of [indices](indexed%20family.md) $t_{1},\ldots ,t_{k}$ in the index set $T$}@} {@{$$\mathbf {X} _{t_{1},\ldots ,t_{k} }=(X_{t_{1} },\ldots ,X_{t_{k} })$$ is a [multivariate Gaussian](multivariate%20normal%20distribution.md) [random variable](random%20variable.md)}@}.<sup>[\[1\]](#^ref-1)</sup> As the sum of {@{independent and Gaussian distributed random variables is again Gaussian distributed}@}, that is the same as saying every {@{linear combination of $(X_{t_{1} },\ldots ,X_{t_{k} })$ has a univariate Gaussian \(or normal\) distribution}@}. <!--SR:!2026-02-20,16,308!2026-02-21,18,330!2026-04-04,57,310!2026-02-20,17,308!2026-02-20,16,316-->

Using {@{[characteristic functions](characteristic%20function%20(probability%20theory).md) of random variables}@} with $i$ denoting {@{the [imaginary unit](imaginary%20unit.md) such that $i^{2}=-1$}@}, {@{the Gaussian property}@} can be formulated as follows: {@{$\left\{X_{t};t\in T\right\}$ is Gaussian}@} {@{if and only if, for every finite set of indices $t_{1},\ldots ,t_{k}$}@}, there are {@{real-valued $\sigma _{\ell j}$, $\mu _{\ell }$ with $\sigma _{jj}>0$ such that the following equality holds for all $s_{1},s_{2},\ldots ,s_{k}\in \mathbb {R}$}@}, {@{$${\mathbb {E} }\left[\exp \left(i\sum _{\ell =1}^{k}s_{\ell }\,\mathbf {X} _{t_{\ell } }\right)\right]=\exp \left(-{\tfrac {1}{2} }\sum _{\ell ,j}\sigma _{\ell j}s_{\ell }s_{j}+i\sum _{\ell }\mu _{\ell }s_{\ell }\right),$$}@} or {@{${\mathbb {E} }\left[{\mathrm {e} }^{i\,\mathbf {s} \,(\mathbf {X} _{t}-\mathbf {\mu } )}\right]={\mathrm {e} }^{-\mathbf {s} \,\sigma \,\mathbf {s} /2}$}@}. {@{The numbers $\sigma _{\ell j}$ and $\mu _{\ell }$}@} can be shown to be {@{the [covariances](covariance.md) and [means](mean%20(mathematics).md) of the variables in the process}@}.<sup>[\[2\]](#^ref-2)</sup> <!--SR:!2026-02-19,15,316!2026-02-20,16,308!2026-02-21,17,321!2026-04-26,77,336!2026-02-20,17,316!2026-05-02,82,341!2026-03-18,42,309!2026-02-17,13,301!2026-02-18,17,308!2026-05-02,82,345-->

## variance

{@{The variance of a Gaussian process}@} is {@{finite at any time $t$}@}, formally<sup>[\[3\]](#^ref-3)</sup><sup>:&hairsp;p. 515&hairsp;</sup> {@{$$\operatorname {var} [X(t)]={\mathbb {E} }\left[\left|X(t)-\operatorname {E} [X(t)]\right|^{2}\right]<\infty \quad {\text{for all } }t\in T.$$}@} <!--SR:!2026-02-22,18,325!2026-02-20,17,308!2026-02-19,15,290-->

## stationarity

For {@{general stochastic processes}@} {@{[strict-sense stationarity](stationary%20process.md#strict-sense%20stationarity)}@} implies {@{[wide-sense stationarity](stationary%20process.md#wide-sense%20stationarity) but not every wide-sense stationary stochastic process is strict-sense stationary}@}. However, for {@{a Gaussian stochastic process}@} {@{the two concepts are equivalent}@}.<sup>[\[3\]](#^ref-3)</sup><sup>:&hairsp;p. 518&hairsp;</sup> <!--SR:!2026-02-22,18,325!2026-02-20,17,316!2026-02-22,18,329!2026-05-04,84,345!2026-02-22,18,330-->

{@{A Gaussian stochastic process}@} is {@{strict-sense stationary if and only if it is wide-sense stationary}@}. <!--SR:!2026-05-01,81,341!2026-04-13,65,310-->

## example

There is {@{an explicit representation for stationary Gaussian processes}@}.<sup>[\[4\]](#^ref-4)</sup> A simple example of this representation is {@{$$X_{t}=\cos(at)\,\xi _{1}+\sin(at)\,\xi _{2}$$}@} where $\xi _{1}$ and $\xi _{2}$ are {@{independent random variables with the [standard normal distribution](normal%20distribution.md#standard%20normal%20distribution)}@}. <!--SR:!2026-02-21,17,316!2026-02-21,17,325!2026-02-18,14,290-->

## covariance functions

- Main article: ::@:: [Covariance function](covariance%20function.md) <!--SR:!2026-02-22,18,325!2026-03-29,53,325-->
- Further information: ::@:: [Variogram](variogram.md) <!--SR:!2026-02-20,17,329!2026-04-15,68,336-->

{@{A key fact of Gaussian processes}@} is that they can be {@{completely defined by their second-order statistics}@}.<sup>[\[5\]](#^ref-5)</sup> Thus, if a Gaussian process is assumed {@{to have mean zero}@}, defining {@{the [covariance function](covariance%20function.md) completely defines the process' behaviour}@}. Importantly {@{the non-negative definiteness of this function}@} enables its {@{spectral decomposition using the [Karhunen–Loève expansion](Karhunen–Loève%20theorem.md)}@}. {@{Basic aspects that can be defined}@} through the covariance function are the process' {@{[stationarity](stationary%20process.md), [isotropy](isotropy.md), [smoothness](smoothness.md) and [periodicity](periodic%20function.md)}@}.<sup>[\[6\]](#^ref-6)</sup><sup>[\[7\]](#^ref-7)</sup> <!--SR:!2026-02-22,18,325!2026-02-21,17,316!2026-02-21,18,325!2026-02-20,16,308!2026-02-19,15,290!2026-02-20,16,308!2026-02-21,17,316!2026-02-21,17,325-->

{@{[Stationarity](stationary%20process.md)}@} refers to the process' {@{behaviour regarding the separation of any two points $x$ and $x'$}@}. If {@{the process is stationary}@}, the covariance function {@{depends only on $x-x'$}@}. For example, {@{the [Ornstein–Uhlenbeck process](Ornstein–Uhlenbeck%20process.md)}@} is stationary. <!--SR:!2026-02-18,14,290!2026-02-20,17,316!2026-02-21,17,325!2026-02-22,18,321!2026-04-24,75,328-->

If the process {@{depends only on $|x-x'|$, the Euclidean distance \(not the direction\) between $x$ and $x'$}@}, then the process is {@{considered isotropic}@}. {@{A process that is concurrently stationary and isotropic}@} is considered to be {@{[homogeneous](homogeneous.md)}@};<sup>[\[8\]](#^ref-8)</sup> in practice these properties reflect {@{the differences \(or rather the lack of them\) in the behaviour of the process}@} given {@{the location of the observer}@}. <!--SR:!2026-04-01,55,310!2026-02-18,14,290!2026-02-19,16,308!2026-02-22,18,325!2026-02-16,15,290!2026-02-22,18,325-->

Ultimately Gaussian processes translate as taking {@{priors on functions}@} and {@{the smoothness of these priors}@} can be {@{induced by the covariance function}@}.<sup>[\[6\]](#^ref-6)</sup> If we expect that for {@{"near-by" input points $x$ and $x'$}@} their {@{corresponding output points $y$ and $y'$ to be "near-by"}@} also, then {@{the assumption of continuity is present}@}. If we wish to allow for {@{significant displacement}@} then we might choose {@{a rougher covariance function}@}. Extreme examples of the behaviour is {@{the Ornstein–Uhlenbeck covariance function and the squared exponential}@} where {@{the former is never differentiable and the latter infinitely differentiable}@}. <!--SR:!2026-05-01,81,341!2026-02-21,17,324!2026-02-20,16,308!2026-04-02,56,310!2026-02-21,17,325!2026-02-19,15,290!2026-02-22,18,321!2026-02-18,17,316!2026-02-20,16,308!2026-04-04,57,310-->

{@{Periodicity}@} refers to inducing {@{periodic patterns within the behaviour of the process}@}. Formally, this is achieved by mapping {@{the input $x$ to a two dimensional vector $u(x)=\left(\cos(x),\sin(x)\right)$}@}. <!--SR:!2026-05-01,81,341!2026-02-18,14,290!2026-02-19,15,290-->

### usual covariance functions

> {@{![The effect of choosing different kernels on the prior function distribution of the Gaussian process.](../../archives/Wikimedia%20Commons/Gaussian%20process%20draws%20from%20prior%20distribution.png)}@}
>
> The effect of choosing {@{different kernels on the prior function distribution of the Gaussian process}@}. Left is {@{a squared exponential kernel}@}. Middle is {@{Brownian}@}. Right is {@{quadratic}@}. <!--SR:!2026-02-20,16,321!2026-02-19,15,308!2026-02-21,17,324!2026-03-21,45,290!2026-02-22,18,321-->

There are a number of {@{common covariance functions}@}:<sup>[\[7\]](#^ref-7)</sup> <!--SR:!2026-02-20,16,316-->

- Constant: ::@:: $K_{\operatorname {C} }(x,x')=C$ <!--SR:!2026-02-20,16,308!2026-04-04,57,310-->
- Linear (annotation: bilinear): ::@:: $K_{\operatorname {L} }(x,x')=x^{\mathsf {T} }x'$ <!--SR:!2026-02-21,17,316!2026-02-17,13,309-->
- white Gaussian noise: ::@:: $K_{\operatorname {GN} }(x,x')=\sigma ^{2}\delta _{x,x'}$ (annotation: $\delta$ is the [Kronecker delta](Kronecker%20delta.md); $\sigma$ is the [standard deviation](standard%20deviation.md) of the noise) <!--SR:!2026-02-21,18,325!2026-04-21,73,336-->
- Squared exponential (annotation: looks like the PDF of a normal distribution): ::@:: $K_{\operatorname {SE} }(x,x')=\exp \left(-{\tfrac {d^{2} }{2\ell ^{2} } }\right)$ (annotation: $\ell$ is the characteristic length-scale) <!--SR:!2026-02-16,12,270!2026-02-20,16,290-->
- Ornstein–Uhlenbeck (annotation: looks like the PDF of an exponential distribution PDF): ::@:: $K_{\operatorname {OU} }(x,x')=\exp \left(-{\tfrac {d}{\ell } }\right)$ (annotation: $\ell$ is the characteristic length-scale) <!--SR:!2026-04-08,53,325!2026-02-22,18,324-->
- Matérn (annotation: quite complicated; not worth to memorize): ::@:: $K_{\operatorname {Matern} }(x,x')={\tfrac {2^{1-\nu } }{\Gamma (\nu )} }\left({\tfrac { {\sqrt {2\nu } }d}{\ell } }\right)^{\nu }K_{\nu }\left({\tfrac { {\sqrt {2\nu } }d}{\ell } }\right)$ (annotation: $\nu >0$ is a parameter controlling smoothness; $\ell$ is the characteristic length-scale; $K_{\nu }$ is the [modified Bessel function](modified%20Bessel%20function.md#modified%20Bessel%20functions) of order $\nu$; $\Gamma (\nu )$ is the [gamma function](gamma%20function.md) evaluated at $\nu$) <!--SR:!2026-02-22,18,325!2026-04-22,73,328-->
- Periodic (annotation: looks like squared exponential but with $d$ replaced by a sine function $2 \sin(d / 2)$): ::@:: $K_{\operatorname {P} }(x,x')=\exp \left(-{\tfrac {2}{\ell ^{2} } }\sin ^{2}(d/2)\right)$ (annotation: $\ell$ is the characteristic length-scale) <!--SR:!2026-02-16,12,288!2026-02-20,16,308-->
- Rational quadratic: ::@:: $K_{\operatorname {RQ} }(x,x')=\left(1+d^{2}\right)^{-\alpha },\quad \alpha \geq 0$ (annotation: $\alpha$ is a positive parameter controlling relative weighting of large-scale and small-scale variations, with larger values of $\alpha$ corresponding to less weight on large-scale variations) <!--SR:!2026-04-25,76,336!2026-02-16,12,270-->

Here {@{$d=|x-x'|$}@}, which is a result of {@{the stationary process property}@}, that is, for {@{any stationary process the covariance function will only depend on $d$}@}. {@{The parameter $\ell$}@} is {@{the characteristic length-scale of the process}@} \(practically, {@{"how close" two points $x$ and $x'$ have to be to influence each other significantly}@}\),  {@{$\delta$}@} is {@{the [Kronecker delta](Kronecker%20delta.md)}@} and {@{$\sigma$}@} {@{the [standard deviation](standard%20deviation.md) of the noise fluctuations}@}. Moreover, {@{$K_{\nu }$}@} is {@{the [modified Bessel function](modified%20Bessel%20function.md#modified%20Bessel%20functions) of order $\nu$}@} and {@{$\Gamma (\nu )$}@} is {@{the [gamma function](gamma%20function.md) evaluated at $\nu$}@}. Importantly, {@{a complicated covariance function}@} can be defined as {@{a linear combination of other simpler covariance functions}@} in order to incorporate {@{different insights about the data-set at hand}@}. <!--SR:!2026-02-21,18,329!2026-02-19,18,324!2026-02-20,17,316!2026-02-19,16,316!2026-02-18,14,290!2026-02-20,17,316!2026-02-19,15,316!2026-04-12,64,310!2026-02-21,17,321!2026-02-19,15,308!2026-02-20,16,308!2026-02-20,16,290!2026-05-05,85,349!2026-02-20,17,325!2026-05-04,84,345!2026-02-19,16,308!2026-02-19,15,290-->

{@{The inferential results}@} are dependent on {@{the values of the hyperparameters $\theta$ \(e.g. $\ell$ and $\sigma$\) defining the model's behaviour}@}. {@{A popular choice for $\theta$}@} is to provide {@{_[maximum a posteriori](maximum%20a%20posteriori.md)_ \(MAP\) estimates of it with some chosen prior}@}. (annotation: That is, find {@{$\argmax_\theta f(y \vert \theta) g(\theta)$}@} where {@{$f(y \vert \theta)$ is the likelihood of the observed process values $y$ given the hyperparameters $\theta$ and $g(\theta)$ is the prior distribution over the hyperparameters}@}.) If {@{the prior is very near uniform}@}, this is the same as {@{maximizing the [marginal likelihood](marginal%20likelihood.md) of the process}@}; the marginalization being done over {@{the observed process values $y$}@}.<sup>[\[7\]](#^ref-7)</sup> (annotation: That is, find {@{$\argmax_\theta f(y \mid \theta)$}@}.) This approach is also known as {@{_maximum likelihood II_, _evidence maximization_, or _[empirical Bayes](empirical%20Bayes.md)_}@}.<sup>[\[9\]](#^ref-9)</sup> <!--SR:!2026-02-19,16,316!2026-03-30,43,290!2026-02-21,17,308!2026-02-21,17,308!2026-04-19,71,328!2026-02-21,17,316!2026-02-21,18,329!2026-02-19,15,290!2026-03-31,54,310!2026-02-20,17,321!2026-02-22,18,325-->

## continuity

For {@{a Gaussian process}@}, {@{[continuity in probability](continuous%20stochastic%20process.md#continuity%20in%20probability)}@} is equivalent to {@{[mean-square continuity](continuous%20stochastic%20process.md#mean-square%20continuity)}@}<sup>[\[10\]](#^ref-10)</sup><sup>:&hairsp;145&hairsp;</sup><sup>:&hairsp;91 "Gaussian processes are {@{discontinuous at fixed points}@}."&hairsp;</sup><sup>[\[11\]](#^ref-11)</sup> and {@{[continuity with probability one](continuous%20stochastic%20process.md#continuity%20with%20probability%20one)}@} is equivalent to {@{[sample continuity](continuous%20stochastic%20process.md#sample%20continuity)}@}.<sup>[\[12\]](#^ref-12)</sup> The latter {@{implies, but is not implied by, continuity in probability}@}. {@{Continuity in probability}@} holds {@{if and only if the [mean and autocovariance](autocovariance.md) are continuous functions}@}. In contrast, {@{sample continuity}@} was {@{challenging even for [stationary Gaussian processes](#stationarity) \(as probably noted first by [Andrey Kolmogorov](Andrey%20Kolmogorov.md)\)}@}, and more {@{challenging for more general processes}@}.<sup>[\[13\]](#^ref-13)</sup><sup>:&hairsp;Sect. 2.8&hairsp;</sup> <sup>[\[14\]](#^ref-14)</sup><sup>:&hairsp;69,&hairsp;81&hairsp;</sup> <sup>[\[15\]](#^ref-15)</sup><sup>:&hairsp;80&hairsp;</sup> <sup>[\[16\]](#^ref-16)</sup> As usual, by {@{a sample continuous process}@} one means a process that {@{admits a sample continuous [modification](stochastic%20process.md#modification)}@}. <sup>[\[17\]](#^ref-17)</sup><sup>:&hairsp;292&hairsp;</sup> <sup>[\[18\]](#^ref-18)</sup><sup>:&hairsp;424&hairsp;</sup> <!--SR:!2026-02-22,18,329!2026-02-22,18,321!2026-03-26,50,308!2026-02-18,15,290!2026-04-09,54,321!2026-02-19,18,324!2026-02-22,18,324!2026-02-18,14,290!2026-02-17,13,296!2026-02-21,17,321!2026-02-18,14,290!2026-02-19,15,308!2026-05-04,84,345!2026-02-19,15,308-->

### stationary case

For {@{a stationary Gaussian process $X=(X_{t})_{t\in \mathbb {R} }$}@}, {@{some conditions on its spectrum}@} are {@{sufficient for sample continuity, but fail to be necessary}@}. {@{A necessary and sufficient condition, sometimes called Dudley–Fernique theorem}@}, involves {@{the function $\sigma$ defined by $$\sigma (h)={\sqrt { {\mathbb {E} }\left[\left(X(t+h)-X(t)\right)^{2}\right]} }$$}@} \(the right-hand side does not {@{depend on $t$ due to stationarity}@}\). {@{Continuity of $X$ in probability}@} is equivalent to {@{continuity of $\sigma$ at $0$}@}. When {@{convergence of $\sigma (h)$ to $0$ \(as $h\to 0$\) is too slow}@}, {@{sample continuity of $X$ may fail}@}. {@{Convergence of the following integrals}@} matters: {@{$$I(\sigma )=\int _{0}^{1}{\frac {\sigma (h)}{h{\sqrt {\log(1/h)} } } }\,dh=\int _{0}^{\infty }2\sigma (e^{-x^{2} })\,dx,$$}@} these two integrals being {@{equal according to [integration by substitution](integration%20by%20substitution.md) $h=e^{-x^{2} }$, $x={\sqrt {\log(1/h)} }$}@}. {@{The first integrand}@} need not {@{be bounded as $h\to 0+$}@}, thus the integral may {@{converge \($I(\sigma )<\infty$\) or diverge \($I(\sigma )=\infty$\)}@}. Taking for example {@{$\sigma (e^{-x^{2} })={\tfrac {1}{x^{a} } }$ for large $x$, that is, $\sigma (h)=(\log(1/h))^{-a/2}$ for small $h$}@}, one obtains {@{$I(\sigma )<\infty$ when $a>1$, and $I(\sigma )=\infty$ when $0<a\leq 1$}@}. In these two cases the function $\sigma$ is {@{increasing on $[0,\infty )$, but generally it is not}@}. Moreover, the condition <p> &emsp; \(\*\)   there exists {@{$\varepsilon >0$ such that $\sigma$ is monotone on $[0,\varepsilon ]$}@} <p> does not follow from {@{continuity of $\sigma$ and the evident relations $\sigma (h)\geq 0$ \(for all $h$\) and $\sigma (0)=0$}@}. <!--SR:!2026-02-19,15,290!2026-02-22,18,325!2026-02-17,16,290!2026-03-20,44,290!2026-02-21,17,308!2026-04-15,68,336!2026-03-27,51,316!2026-03-28,52,321!2026-03-31,55,325!2026-05-05,85,350!2026-02-21,18,324!2026-03-30,54,325!2026-02-18,17,308!2026-02-19,18,325!2026-02-21,17,330!2026-05-01,81,341!2026-02-16,12,270!2026-02-19,15,308!2026-02-21,18,325!2026-02-16,12,270!2026-03-30,50,308-->

> __Theorem 1__—Let $\sigma$ be {@{continuous and satisfy [\(\*\)](#(*)) (annotation: $\sigma$ is monotone on $[0, \varepsilon]$)}@}. Then {@{the condition $I(\sigma )<\infty$}@} is {@{necessary and sufficient for sample continuity of $X$}@}. <!--SR:!2026-02-19,18,330!2026-02-19,15,290!2026-05-01,81,341-->

{@{Some history}@}.<sup>[\[18\]](#^ref-18)</sup><sup>:&hairsp;424&hairsp;</sup> {@{Sufficiency}@} was announced by {@{[Xavier Fernique](Xavier%20Fernique.md) in 1964}@}, but the first proof was {@{published by [Richard M. Dudley](Richard%20M.%20Dudley.md) in 1967}@}.<sup>[\[17\]](#^ref-17)</sup><sup>:&hairsp;Theorem 7.1&hairsp;</sup> {@{Necessity}@} was proved by {@{Michael B. Marcus and [Lawrence Shepp](Lawrence%20Shepp.md) in 1970}@}.<sup>[\[19\]](#^ref-19)</sup><sup>:&hairsp;380&hairsp;</sup> <!--SR:!2026-02-20,16,308!2026-02-22,18,325!2026-02-17,16,290!2026-02-20,16,290!2026-02-21,17,330!2026-02-27,18,350-->

There exist {@{sample continuous processes $X$ such that $I(\sigma )=\infty$}@}; they {@{violate condition [\(\*\)](#(*)) (annotation: $\sigma$ is monotone on $[0, \varepsilon]$)}@}. {@{An example found by Marcus and Shepp}@} <sup>[\[19\]](#^ref-19)</sup><sup>:&hairsp;387&hairsp;</sup> is {@{a random [lacunary Fourier series](lacunary%20function.md#lacunary%20trigonometric%20series)}@} {@{$$X_{t}=\sum _{n=1}^{\infty }c_{n}(\xi _{n}\cos \lambda _{n}t+\eta _{n}\sin \lambda _{n}t),$$}@} where $\xi _{1},\eta _{1},\xi _{2},\eta _{2},\dots$ are {@{independent random variables with [standard normal distribution](normal%20distribution.md#standard%20normal%20distribution)}@}; frequencies {@{$0<\lambda _{1}<\lambda _{2}<\dots$ are a fast growing sequence}@}; and coefficients {@{$c_{n}>0$ satisfy $\sum _{n}c_{n}<\infty$}@}. The latter relation implies {@{$${\mathbb {E} }\sum _{n}c_{n}(|\xi _{n}|+|\eta _{n}|)=\sum _{n}c_{n}{\mathbb {E} }[|\xi _{n}|+|\eta _{n}|]={\text{const} }\cdot \sum _{n}c_{n}<\infty ,$$}@} whence {@{$\sum _{n}c_{n}(|\xi _{n}|+|\eta _{n}|)<\infty$ almost surely}@} (annotation: by applying {@{a corollary of Fatou's lemma}@} on {@{the partial sums as more terms are included}@}), which ensures {@{uniform convergence of the Fourier series almost surely (annotation: by direct application of the Weierstrass M-test)}@}, and {@{sample continuity of $X$}@}. <!--SR:!2026-02-21,18,321!2026-02-21,18,329!2026-03-20,45,290!2026-04-20,72,336!2026-05-02,82,341!2026-02-21,17,308!2026-04-23,74,328!2026-02-17,16,290!2026-02-21,17,316!2026-02-21,17,308!2026-04-04,57,310!2026-02-18,14,290!2026-02-17,13,310!2026-02-22,18,321-->

> {@{![Autocorrelation of a random lacunary Fourier series](../../archives/Wikimedia%20Commons/Autocorrelation%20of%20a%20random%20lacunary%20Fourier%20series.svg)}@}
>
> {@{Autocorrelation}@} of {@{a random lacunary Fourier series}@} <!--SR:!2026-04-14,66,310!2026-05-01,81,341!2026-05-04,84,345-->

Its {@{autocovariation function}@} {@{$${\mathbb {E} }[X_{t}X_{t+h}]=\sum _{n=1}^{\infty }c_{n}^{2}\cos \lambda _{n}h$$}@} is {@{nowhere monotone \(see the picture\)}@}, as well as {@{the corresponding function $\sigma$}@}, {@{$$\sigma (h)={\sqrt {2{\mathbb {E} }[X_{t}X_{t}]-2{\mathbb {E} }[X_{t}X_{t+h}]} }=2{\sqrt {\sum _{n=1}^{\infty }c_{n}^{2}\sin ^{2}{\frac {\lambda _{n}h}{2} } } }.$$}@} <!--SR:!2026-04-14,67,328!2026-02-18,14,290!2026-05-02,82,341!2026-02-22,18,321!2026-03-24,38,305-->

## Brownian motion as the integral of Gaussian processes

{@{A [Wiener process](Wiener%20process.md) \(also known as Brownian motion\)}@} is {@{the integral of a [white noise generalized Gaussian process](white%20noise.md#continuous-time%20white%20noise)}@}. It is {@{not [stationary](stationary%20process.md), but it has [stationary increments](stationary%20increments.md)}@}. <!--SR:!2026-02-19,15,290!2026-02-22,18,325!2026-02-21,17,321-->

{@{The [Ornstein–Uhlenbeck process](Ornstein–Uhlenbeck%20process.md)}@} is {@{a [stationary](stationary%20process.md) Gaussian process}@}. <!--SR:!2026-04-26,77,336!2026-02-19,15,290-->

{@{The [Brownian bridge](Brownian%20bridge.md)}@} is \(like {@{the Ornstein–Uhlenbeck process}@}\) an example of {@{a Gaussian process whose increments are not [independent](statistical%20independence.md)}@}. <!--SR:!2026-04-24,75,328!2026-04-13,65,310!2026-02-21,18,321-->

{@{The [fractional Brownian motion](fractional%20Brownian%20motion.md)}@} is {@{a Gaussian process whose covariance function is a generalisation of that of the Wiener process}@}. <!--SR:!2026-02-19,15,290!2026-02-19,18,325-->

## RKHS structure and Gaussian process

Let $f$ be {@{a mean-zero Gaussian process $\left\{X_{t};t\in T\right\}$ with a non-negative definite covariance function $K$}@} and let $R$ be {@{a symmetric and positive semidefinite function}@}. Then, there exists {@{a Gaussian process $X$ which has the covariance $R$}@}. (annotation: This is {@{unrelated to $f$ and $K$}@}.) Moreover, {@{the [reproducing kernel Hilbert space](Reproducing%20kernel%20Hilbert%20space.md) \(RKHS\) associated to $R$}@} (annotation: denoted {@{$H_X$}@}, a Hilbert space such that {@{$\langle f(\,\cdot\,), R(\,\cdot\,, t) \rangle_{H_X} = f(t)$ for all $f \in H_X$ and $t$}@}; {@{the functions in $H_X$ and its inner product}@} may be {@{complex to write down}@}) coincides with {@{the [Cameron–Martin theorem](Cameron–Martin%20theorem.md) associated space $R(H)$ of $X$}@}, and {@{all the spaces $R(H)$, $H_{X}$, and ${\mathcal {H} }(K)$}@} (annotation: i.e. {@{the RKHS associated to $K$; similar construction to $H_X$}@}) are {@{isometric}@}.<sup>[\[20\]](#^ref-20)</sup> From now on, let ${\mathcal {H} }(R)$ be {@{a [reproducing kernel Hilbert space](Reproducing%20kernel%20Hilbert%20space.md) with positive definite kernel $R$}@}. <!--SR:!2026-02-19,16,290!2026-02-20,17,308!2026-04-23,74,328!2026-02-20,17,325!2026-04-19,71,328!2026-05-03,83,341!2026-03-19,32,270!2026-02-18,14,290!2026-04-13,66,328!2026-02-21,17,325!2026-02-22,18,330!2026-02-21,17,324!2026-02-18,17,316!2026-02-21,18,321-->

{@{Driscoll's zero-one law}@} is a result characterizing {@{the sample functions generated by a Gaussian process}@}: {@{$$\lim _{n\to \infty }\operatorname {tr} [K_{n}R_{n}^{-1}]<\infty ,$$}@} where {@{$K_{n}$ and $R_{n}$}@} are {@{the covariance matrices of all possible pairs of $n$ points}@}, implies {@{$$\Pr[f\in {\mathcal {H} }(R)]=1.$$}@} (annotation: Intuitively, this means that {@{almost all sample paths of the Gaussian process $f$ lie in the Hilbert space ${\mathcal {H} }(R)$}@} under the condition that can be interpreted as {@{the "size" of the covariance $K$ being "small" compared to $R$}@}. {@{The trace $\operatorname {tr} [K_{n}R_{n}^{-1}]$}@} can be seen as {@{the sum of the relative sizes of the eigenvalues of $K_{n}$ compared to those of $R_{n}$}@}.) <!--SR:!2026-02-21,17,325!2026-04-13,66,328!2026-02-19,15,308!2026-02-20,16,316!2026-02-22,18,321!2026-02-18,14,290!2026-02-22,18,325!2026-02-19,15,308!2026-02-18,14,290!2026-05-02,82,341-->

Moreover, {@{$$\lim _{n\to \infty }\operatorname {tr} [K_{n}R_{n}^{-1}]=\infty$$}@} implies <sup>[\[21\]](#^ref-21)</sup> {@{$$\Pr[f\in {\mathcal {H} }(R)]=0.$$}@} (annotation: Intuitively, this means that {@{almost all sample paths of the Gaussian process $f$ lie outside of the Hilbert space ${\mathcal {H} }(R)$}@} under the condition that can be interpreted as {@{the "size" of the covariance $K$ being "large" compared to $R$}@}. {@{The trace $\operatorname {tr} [K_{n}R_{n}^{-1}]$}@} can be seen as {@{the sum of the relative sizes of the eigenvalues of $K_{n}$ compared to those of $R_{n}$}@}.) <!--SR:!2026-02-21,17,316!2026-02-21,17,325!2026-02-16,12,270!2026-04-04,57,310!2026-02-19,18,330!2026-02-21,17,308-->

This has {@{significant implications when $K=R$}@}, as {@{$$\lim _{n\to \infty }\operatorname {tr} [R_{n}R_{n}^{-1}]=\lim _{n\to \infty }\operatorname {tr} [I]=\lim _{n\to \infty }n=\infty .$$}@} As such, {@{almost all sample paths of a mean-zero Gaussian process with positive definite kernel $K$}@} will lie {@{outside of the Hilbert space ${\mathcal {H} }(K)$}@}.  (annotation: In essence, {@{a Gaussian process}@} almost never produces {@{functions as smooth as those in its own RKHS}@}. {@{The RKHS}@} encodes {@{the kernel's ideal smoothness}@}; that is, {@{the perfectly regular, optimally smooth functions}@} {@{the kernel prefers in theory}@}, while {@{actual GP sample paths}@} are {@{much rougher and lie outside that space with probability 1}@}.) <!--SR:!2026-02-20,16,308!2026-02-18,15,290!2026-02-18,17,324!2026-02-19,15,290!2026-02-26,17,350!2026-02-26,17,350!2026-02-28,19,350!2026-02-27,18,350!2026-02-27,18,350!2026-02-26,17,350!2026-02-27,18,350!2026-02-28,19,350-->

## linearly constrained Gaussian processes

For {@{many applications of interest}@} {@{some pre-existing knowledge about the system at hand}@} is already given. Consider e.g. the case where {@{the output of the Gaussian process}@} corresponds to {@{a magnetic field}@}; here, {@{the real magnetic field}@} is {@{bound by Maxwell's equations}@} and a way to incorporate {@{this constraint into the Gaussian process formalism}@} would be {@{desirable as this would likely improve the accuracy of the algorithm}@}. <!--SR:!2026-02-20,16,290!2026-02-19,15,290!2026-02-21,17,308!2026-02-20,17,316!2026-04-20,72,336!2026-05-04,84,345!2026-02-22,18,329!2026-02-19,15,290-->

A method on how to incorporate {@{linear constraints into Gaussian processes}@} already exists:<sup>[\[22\]](#^ref-22)</sup> <!--SR:!2026-02-18,17,316-->

Consider {@{the \(vector valued\) output function $f(x)$ which is known to obey the linear constraint}@} \(i.e. ${\mathcal {F} }_{X}$ is {@{a linear operator}@}\) {@{$${\mathcal {F} }_{X}(f(x))=0.$$}@} Then {@{the constraint ${\mathcal {F} }_{X}$}@} can be {@{fulfilled by choosing $f(x)={\mathcal {G} }_{X}(g(x))$}@}, where {@{$g(x)\sim {\mathcal {GP} }(\mu _{g},K_{g})$ is modelled as a Gaussian process}@}, and finding {@{${\mathcal {G} }_{X}$ such that $${\mathcal {F} }_{X}({\mathcal {G} }_{X}(g))=0\qquad \forall g.$$}@} Given {@{${\mathcal {G} }_{X}$ and using the fact that Gaussian processes are closed under linear transformations}@}, {@{the Gaussian process for $f$ obeying constraint ${\mathcal {F} }_{X}$}@} becomes {@{$$f(x)={\mathcal {G} }_{X}g\sim {\mathcal {GP} }({\mathcal {G} }_{X}\mu _{g},{\mathcal {G} }_{X}K_{g}{\mathcal {G} }_{X'}^{\mathsf {T} }).$$}@} Hence, {@{linear constraints}@} can be {@{encoded into the mean and covariance function of a Gaussian process}@}. <!--SR:!2026-02-20,16,308!2026-02-21,18,325!2026-02-19,15,290!2026-05-03,83,341!2026-02-21,18,325!2026-02-22,18,330!2026-02-20,16,308!2026-02-19,18,329!2026-02-19,15,290!2026-03-28,49,316!2026-04-07,52,316!2026-02-20,16,290-->

## applications

> {@{![An example of Gaussian Process Regression \(prediction\) compared with other regression models.](../../archives/Wikimedia%20Commons/Regressions%20sine%20demo.svg)}@}
>
> An example of {@{Gaussian Process Regression \(prediction\)}@} compared with {@{other regression models}@}.<sup>[\[23\]](#^ref-23)</sup> <!--SR:!2026-02-20,17,321!2026-03-19,44,290!2026-02-22,18,330-->

A Gaussian process can be used as {@{a [prior probability distribution](prior%20probability%20distribution.md)}@} over {@{[functions](function%20(mathematics).md) in [Bayesian inference](Bayesian%20inference.md)}@}.<sup>[\[7\]](#^ref-7)</sup><sup>[\[24\]](#^ref-24)</sup> Given any set of {@{_N_ points in the desired domain of the functions}@}, take {@{a [multivariate Gaussian](multivariate%20Gaussian.md) whose covariance [matrix](matrix%20(mathematics).md) parameter}@} is {@{the [Gram matrix](Gram%20matrix.md) (annotation: i.e. the matrix of inner products between all pairs of _N_ points) of those _N_ points}@} with {@{some desired [kernel](stochastic%20kernel.md), and [sample](sampling%20(mathematics).md)}@} from that Gaussian. For solution of {@{the multi-output prediction problem}@}, {@{Gaussian process regression for vector-valued function}@} was developed. In this method, {@{a 'big' covariance}@} is constructed, which describes {@{the correlations between all the input and output variables}@} taken in {@{_N_ points in the desired domain}@}.<sup>[\[25\]](#^ref-25)</sup> This approach was elaborated in detail for the {@{matrix-valued Gaussian processes}@} and generalised to {@{processes with 'heavier tails' like [Student-t processes](Student's%20t-distribution.md#Student's%20t-process)}@}.<sup>[\[26\]](#^ref-26)</sup> <!--SR:!2026-04-25,76,336!2026-02-17,16,290!2026-02-20,16,316!2026-02-21,17,325!2026-02-22,18,325!2026-04-26,77,336!2026-02-21,17,316!2026-05-05,85,349!2026-04-04,57,310!2026-02-22,18,325!2026-02-20,16,321!2026-05-04,84,345!2026-04-24,75,328-->

Inference of {@{continuous values with a Gaussian process prior}@} is known as {@{Gaussian process regression, or [kriging](kriging.md)}@}; extending Gaussian process regression to {@{[multiple target variables](kernel%20methods%20for%20vector%20output.md)}@} is known as {@{_cokriging_}@}.<sup>[\[27\]](#^ref-27)</sup> Gaussian processes are thus useful as {@{a powerful non-linear multivariate [interpolation](interpolation.md) tool}@}. Kriging is also used to extend {@{Gaussian process in the case of mixed integer inputs}@}.<sup>[\[28\]](#^ref-28)</sup> <!--SR:!2026-04-26,77,336!2026-05-05,85,350!2026-02-19,16,290!2026-04-24,75,328!2026-02-22,18,325!2026-02-16,12,270-->

Gaussian processes are also commonly used to tackle {@{numerical analysis problems}@} such as {@{numerical integration, solving differential equations, or optimisation}@} in the field of {@{[probabilistic numerics](probabilistic%20numerics.md)}@}. <!--SR:!2026-05-02,82,344!2026-02-19,15,290!2026-02-19,15,290-->

Gaussian processes can also be used in the context of {@{mixture of experts models}@}, for example.<sup>[\[29\]](#^ref-29)</sup><sup>[\[30\]](#^ref-30)</sup> {@{The underlying rationale of such a learning framework}@} consists in the assumption that {@{a given mapping}@} cannot be {@{well captured by a single Gaussian process model}@}. Instead, the observation space is {@{divided into subsets}@}, each of which is {@{characterized by a different mapping function}@}; each of these is {@{learned via a different Gaussian process component in the postulated mixture}@}. <!--SR:!2026-04-24,75,328!2026-02-20,16,308!2026-02-18,14,290!2026-05-01,81,345!2026-02-18,15,290!2026-02-20,16,308!2026-04-04,57,310-->

### Gaussian process prediction, or Kriging

- Further information: ::@:: [Kriging](kriging.md) <!--SR:!2026-02-18,14,290!2026-02-22,18,329-->

> {@{![Gaussian Process Regression \(prediction\) with a squared exponential kernel. Left plot are draws from the prior function distribution. Middle are draws from the posterior.](../../archives/Wikimedia%20Commons/Gaussian%20Process%20Regression.png)}@}
>
> {@{Gaussian Process Regression \(prediction\)}@} with {@{a squared exponential kernel}@}. Left plot are {@{draws from the prior function distribution}@}. Middle are {@{draws from the posterior}@}. Right is {@{mean prediction with one standard deviation shaded}@}. <!--SR:!2026-02-22,18,324!2026-02-21,18,329!2026-02-18,15,290!2026-02-20,16,308!2026-04-04,57,310!2026-02-20,16,308-->

When concerned with {@{a general Gaussian process regression problem \(Kriging\)}@}, it is assumed that for {@{a Gaussian process $f$ observed at coordinates $x$}@}, {@{the vector of values ⁠$f(x)$}@}⁠ is just {@{one sample from a multivariate Gaussian distribution}@} of {@{dimension equal to number of observed coordinates ⁠$n$}@}⁠. Therefore, under the assumption of {@{a zero-mean distribution}@}, {@{⁠$f(x')\sim N(0,K(\theta ,x,x'))$}@}⁠, where {@{⁠$K(\theta ,x,x')$}@}⁠ is {@{the covariance matrix between all possible pairs ⁠$(x,x')$⁠ for a given set of hyperparameters _θ_}@}.<sup>[\[7\]](#^ref-7)</sup> As such {@{the log marginal likelihood}@} is: {@{$$\log p(f(x')\mid \theta ,x)=-{\frac {1}{2} }\left(f(x)^{\mathsf {T} }K(\theta ,x,x')^{-1}f(x')+\log \det(K(\theta ,x,x'))+n\log 2\pi \right)$$}@} and maximizing {@{this marginal likelihood towards _θ_}@} provides {@{the complete specification of the Gaussian process _f_}@}. One can briefly note at this point that {@{the first term corresponds}@} to {@{a penalty term for a model's failure to fit observed values}@} and {@{the second term}@} to {@{a penalty term that increases proportionally to a model's complexity}@}. Having {@{specified _θ_}@}, making {@{predictions about unobserved values ⁠$f(x^{*})$⁠ at coordinates _x_\*}@} is then only a matter of drawing {@{samples from the predictive distribution $p(y^{*}\mid x^{*},f(x),x)=N(y^{*}\mid A,B)$}@} where {@{the posterior mean estimate _A_}@} is defined as {@{$$A=K(\theta ,x^{*},x)K(\theta ,x,x')^{-1}f(x)$$}@} (annotation: They come from taking {@{conditional distributions on a multivariate normal distribution consisting of the seen and unseen points}@}. {@{The prior mean}@} is {@{zero, and thus does not appear in the expression}@}. {@{The posterior mean at $x^*$}@} is computed as {@{a weighted sum of observed values $f(x)$}@}, where the weights come from {@{the kernel similarities $K(\theta, x^*, x)$}@} and are corrected by {@{the inverse covariance $K(\theta, x, x')^{-1}$}@} to properly {@{account for correlations among training points}@}, ensuring the prediction reflects {@{both proximity and redundancy}@}.) and {@{the posterior variance estimate _B_}@} is defined as: {@{$$B=K(\theta ,x^{*},x^{*})-K(\theta ,x^{*},x)K(\theta ,x,x')^{-1}K(\theta ,x^{*},x)^{\mathsf {T} }$$}@} (annotation: They come from taking {@{conditional distributions on a multivariate normal distribution consisting of the seen and unseen points}@}. {@{The posterior variance at $x^*$}@} starts from {@{the prior uncertainty $K(\theta, x^*, x^*)$}@} and subtracts {@{the uncertainty explained by the training data through their correlation with $x^*$}@}; {@{the closer and more correlated $x^*$}@} is to observed points, the larger {@{the subtraction and the smaller the remaining uncertainty}@}.) where {@{⁠$K(\theta ,x^{*},x)$}@}⁠ is {@{the covariance between the new coordinate of estimation _x_\* and all other observed coordinates _x_}@} for {@{a given hyperparameter vector _θ_}@}, {@{⁠$K(\theta ,x,x')$⁠ and ⁠$f(x)$}@}⁠ are {@{defined as before}@} and {@{⁠$K(\theta ,x^{*},x^{*})$⁠}@} is {@{the variance at point _x_\* as dictated by _θ_}@}. It is important to note that practically {@{the posterior mean estimate of ⁠$f(x^{*})$⁠ \(the "point estimate"\)}@} is just {@{a linear combination of the observations ⁠$f(x)$ (annotation: when prior mean is zero)}@}⁠; in {@{a similar manner}@} {@{the variance of ⁠$f(x^{*})$}@}⁠ is actually {@{independent of the observations ⁠$f(x)$}@} (annotation: they only {@{depend on the input points $x$}@})⁠. {@{A known bottleneck}@} in Gaussian process prediction is that {@{the computational complexity of inference and likelihood evaluation}@} is {@{cubic in the number of points \|_x_\|}@}, and as such can become {@{unfeasible for larger data sets}@}.<sup>[\[6\]](#^ref-6)</sup><sup>[\[31\]](#^ref-31)</sup> Works on {@{sparse Gaussian processes}@}, that usually are based on the idea of building {@{a _representative set_ for the given process _f_}@}, try to {@{circumvent this issue}@}.<sup>[\[32\]](#^ref-32)</sup><sup>[\[33\]](#^ref-33)</sup><sup>[\[34\]](#^ref-34)</sup> {@{The [kriging](kriging.md) method}@} can be used in {@{the latent level of a [nonlinear mixed-effects model](nonlinear%20mixed-effects%20model.md)}@} for {@{a spatial functional prediction}@}: this technique is called {@{the latent kriging}@}.<sup>[\[35\]](#^ref-35)</sup> Other classes of {@{scalable Gaussian process for analyzing massive datasets}@} have emerged from {@{the [Vecchia approximation](Vecchia%20approximation.md) and Nearest Neighbor Gaussian Processes \(NNGP\)}@}.<sup>[\[36\]](#^ref-36)</sup><sup>[\[31\]](#^ref-31)</sup> <!--SR:!2026-04-04,57,310!2026-02-21,18,325!2026-04-22,73,328!2026-02-21,18,325!2026-02-21,17,316!2026-02-20,17,308!2026-02-18,14,290!2026-02-18,17,325!2026-02-19,18,325!2026-03-27,51,316!2026-03-11,26,276!2026-04-15,67,310!2026-02-21,18,329!2026-02-22,18,325!2026-05-05,85,349!2026-02-20,17,324!2026-05-04,84,345!2026-02-22,18,325!2026-02-21,17,308!2026-04-22,73,328!2026-02-20,17,325!2026-02-19,15,290!2026-02-21,17,316!2026-02-18,17,308!2026-02-22,18,325!2026-02-20,16,316!2026-04-04,57,310!2026-02-19,15,290!2026-03-29,53,325!2026-02-19,15,308!2026-02-22,18,321!2026-02-20,17,308!2026-02-16,12,296!2026-02-19,15,316!2026-02-18,14,290!2026-02-20,16,290!2026-02-21,17,308!2026-02-18,15,290!2026-03-31,54,310!2026-02-21,17,316!2026-02-21,17,330!2026-04-23,74,328!2026-02-20,16,325!2026-02-20,17,308!2026-02-20,17,321!2026-02-22,18,321!2026-02-21,18,321!2026-03-12,29,305!2026-02-18,15,290!2026-02-20,16,308!2026-02-21,18,325!2026-02-16,15,290!2026-05-03,83,341!2026-02-22,18,325!2026-02-21,18,321!2026-02-17,13,305!2026-02-18,14,290!2026-04-21,73,336!2026-02-19,16,290!2026-02-21,17,316!2026-02-21,17,308!2026-02-19,15,308!2026-02-20,17,316!2026-04-14,67,328!2026-04-04,57,310-->

Often, {@{the covariance}@} has {@{the form $K(\theta ,x,x')={\frac {1}{\sigma ^{2} } }{\tilde {K} }(\theta ,x,x')$}@}, where {@{$\sigma ^{2}$ is a scaling parameter}@}. Examples are {@{the Matérn class covariance functions}@}. If {@{this scaling parameter $\sigma ^{2}$}@} is either {@{known or unknown \(i.e. must be marginalized\)}@}, then {@{the posterior probability, $p(\theta \mid D)$}@}, i.e. the probability for {@{the hyperparameters $\theta$ given a set of data pairs $D$ of observations of $x$ and $f(x)$}@}, admits {@{an analytical expression}@}.<sup>[\[37\]](#^ref-37)</sup> <!--SR:!2026-02-22,18,321!2026-04-06,56,321!2026-04-04,57,310!2026-02-18,14,290!2026-02-22,18,325!2026-02-20,16,290!2026-02-22,18,325!2026-02-19,15,290!2026-02-21,18,325-->

### Bayesian neural networks as Gaussian processes

- Further information: [Neural network Gaussian process](neural%20network%20Gaussian%20process.md)

{@{Bayesian neural networks}@} are {@{a particular type of [Bayesian network](Bayesian%20network.md)}@} that results from treating {@{[deep learning](deep%20learning.md) and [artificial neural network](artificial%20neural%20network.md) models probabilistically}@}, and assigning {@{a [prior distribution](prior%20probability.md) to their [parameters](statistical%20parameter.md)}@}. {@{Computation in artificial neural networks}@} is usually organized into {@{sequential layers of [artificial neurons](artificial%20neuron.md)}@}. {@{The number of neurons}@} in a layer is called {@{the layer width}@}. As {@{layer width grows large}@}, {@{many Bayesian neural networks}@} reduce to {@{a Gaussian process with a [closed form](closed-form%20expression.md) compositional kernel}@}. This Gaussian process is called {@{the Neural Network Gaussian Process \(NNGP\)}@} \(not to be confused with {@{the Nearest Neighbor Gaussian Process}@} <sup>[\[36\]](#^ref-36)</sup>\).<sup>[\[7\]](#^ref-7)</sup><sup>[\[38\]](#^ref-38)</sup><sup>[\[39\]](#^ref-39)</sup> It allows {@{predictions from Bayesian neural networks}@} to be {@{more efficiently evaluated}@}, and provides {@{an analytic tool}@} to understand {@{[deep learning](deep%20learning.md) models}@}. <!--SR:!2026-02-20,16,308!2026-04-24,75,328!2026-04-04,57,310!2026-02-22,18,329!2026-02-18,15,290!2026-04-20,72,336!2026-02-20,17,308!2026-05-01,81,341!2026-02-20,16,325!2026-04-19,71,328!2026-02-19,15,308!2026-02-22,18,325!2026-04-24,75,328!2026-04-19,71,328!2026-02-20,16,290!2026-02-18,17,316!2026-05-05,85,349-->

### physical applications

Gaussian processes have found {@{increasing applications in many domains of the natural sciences}@} due to their {@{statistical modelling properties}@}. {@{[Molecular property](molecular%20property.md) prediction}@} has employed {@{these process models in small molecular datasets}@} due to their {@{inference capabilities and computational costs}@}.<sup>[\[40\]](#^ref-40)</sup><sup>[\[41\]](#^ref-41)</sup> They are also being increasingly used as {@{surrogate models}@} for {@{force field optimization}@}.<sup>[\[42\]](#^ref-42)</sup> <!--SR:!2026-04-16,69,336!2026-02-19,16,290!2026-02-16,15,290!2026-02-20,16,316!2026-04-21,73,336!2026-02-20,16,330!2026-04-12,64,310-->

#### astrophysics

Gaussian processes have also found {@{extensive use in [astrophysical](astrophysics.md) and astronomical settings}@}. Gaussian processes can model {@{correlated noise}@}, a specific type of {@{non-Gaussian noise dependent on some underlying unknown distribution correlated with observed values}@}. {@{This type of noise}@} is often {@{present in astronomical signals}@} as {@{instrumental systematics or as intrinsic to the observed object as a result of physical processes}@}. {@{Correlated noise}@} is often a consideration for {@{exoplanet [transit events](astronomical%20transit.md)}@}, and Gaussian processes have been used to de-trend {@{these transit [light curves](light%20curve.md)}@} \(at timescales {@{greater than that of the transit}@}\) to allow detection of {@{weaker, more short-lived signals}@}.<sup>[\[43\]](#^ref-43)</sup> These processes have also been used to disentangle {@{planetary signals from stellar activity indicators}@} inside {@{[radial velocity](radial%20velocity.md) data}@}, another method of {@{exoplanet detection}@}. This is done by training {@{the Gaussian process model to optimize the hyperparameters of the kernel}@} until it accurately recreates {@{the noise components of the radial velocity data}@}, which ultimately allows it to determine {@{which signals are best defined as strictly periodic}@} \(which {@{the planet should be}@}\) and {@{which signals are best represented by the evolving, quasi-periodic kernel}@} \(which {@{the star should be}@}\).<sup>[\[44\]](#^ref-44)</sup> {@{Correlated noise produced by active regions on a star's [photosphere](photosphere.md)}@} \(as a result of {@{[magnetic field](stellar%20magnetic%20field.md) interactions}@}\) can be of {@{similar timescales as transit events}@}, and Gaussian process models which {@{handle sparsely sampled data}@} are used to confirm {@{exoplanet detections especially around young stars}@}.<sup>[\[45\]](#^ref-45)</sup><sup>[\[46\]](#^ref-46)</sup> <!--SR:!2026-02-18,14,290!2026-04-25,76,336!2026-02-22,18,325!2026-02-22,18,325!2026-02-17,16,290!2026-02-22,18,330!2026-05-04,84,345!2026-04-02,56,310!2026-02-19,18,321!2026-02-22,18,325!2026-04-19,71,328!2026-02-20,16,290!2026-02-21,17,321!2026-04-12,65,328!2026-02-20,16,308!2026-02-18,14,290!2026-04-04,57,310!2026-02-19,15,290!2026-04-22,73,328!2026-05-03,83,341!2026-04-12,64,310!2026-05-03,83,345!2026-02-20,16,321!2026-02-22,18,330!2026-02-19,15,308-->

{@{The variability of rotating, magnetically active Sun-like stars}@} can be modeled {@{fairly accurately using Gaussian processes}@}.<sup>[\[45\]](#^ref-45)</sup> {@{This quasi-periodic variability}@} is often represented by {@{a covariance function}@} given as<sup>[\[47\]](#^ref-47)</sup><sup>[\[48\]](#^ref-48)</sup> {@{$${\text{K} }_{\text{QP} }(x,x')=\alpha ^{2}\exp \left(-{\frac {d^{2} }{2\lambda _{1}^{2} } }-\Gamma \sin ^{2}\left[{\frac {\pi d}{\lambda _{2} } }\right]\right)$$}@} where parameter {@{$\alpha$ is amplitude}@}, {@{$\lambda _{1}$ is <!-- period -->decoherence timescale}@}, and {@{$\lambda _{2}$ is <!-- decoherence timescale -->period}@}. This covariance function allows for {@{the limited but feasible determination}@} of stellar periods as a result of {@{parameter <!-- $\lambda _{1}$ -->$\lambda_{2}$}@} but lacks {@{physical information about where these active regions are on the star observed}@}.<sup>[\[45\]](#^ref-45)</sup><sup>[\[49\]](#^ref-49)</sup> <!--SR:!2026-02-19,15,290!2026-02-21,17,316!2026-02-19,15,308!2026-05-03,83,344!2026-02-16,12,296!2026-02-21,17,324!2026-05-04,84,345!2026-02-22,18,329!2026-02-22,18,325!2026-02-19,15,290!2026-02-19,15,290-->

Gaussian processes are also used in the analysis of {@{individual and populations of [active galactic nuclei](active%20galactic%20nucleus.md) \(AGNs\)}@} due to their {@{stochastic variability in the optical and radio parts of the [electromagnetic spectrum](electromagnetic%20spectrum.md)}@}.<sup>[\[45\]](#^ref-45)</sup> {@{Damped random walk kernels}@} in particular have previously been used to identify {@{the extent of [broad-line emission regions](extended%20emission-line%20region.md) around [supermassive black holes](supermassive%20black%20hole.md)}@} using {@{[reverberation mapping](reverberation%20mapping.md)}@}, and these kernels can also be used to characterize {@{light curve variations for large AGN populations}@}.<sup>[\[50\]](#^ref-50)</sup><sup>[\[51\]](#^ref-51)</sup> <!--SR:!2026-02-19,16,308!2026-05-02,82,341!2026-02-19,15,308!2026-02-22,18,324!2026-02-18,14,290!2026-02-18,15,290-->

Other astrophysical applications of Gaussian processes include models for [pulsar](pulsar.md) {@{timing and dispersion measure}@}, {@{[gravitational wave](gravitational%20wave.md) structure and detector uncertainty}@} \(notably in {@{the [LIGO-Virgo-KAGRA](LIGO.md) collaboration}@}\), {@{transient classification, and quasi-periodic oscillations}@}.<sup>[\[45\]](#^ref-45)</sup><sup>[\[52\]](#^ref-52)</sup><sup>[\[53\]](#^ref-53)</sup><sup>[\[54\]](#^ref-54)</sup><sup>[\[55\]](#^ref-55)</sup> <!--SR:!2026-05-03,83,341!2026-02-22,18,330!2026-02-18,17,330!2026-02-21,18,325-->

## computational issues

- See also: ::@:: [Gaussian process approximations](Gaussian%20process%20approximations.md) <!--SR:!2026-05-04,84,345!2026-02-19,15,290-->

In {@{practical applications}@}, Gaussian process models are often evaluated on {@{a grid leading to multivariate normal distributions}@}. Using these models for {@{prediction or parameter estimation using maximum likelihood}@} requires evaluating {@{a multivariate Gaussian density}@}, which involves calculating {@{the determinant and the inverse of the covariance matrix}@}. {@{Both of these operations}@} have {@{cubic computational complexity}@} which means that even for {@{grids of modest sizes, both operations can have a prohibitive computational cost}@}. This drawback led to the development of {@{multiple [approximation methods](Gaussian%20process%20approximations.md)}@}.<sup>[\[31\]](#^ref-31)</sup> <!--SR:!2026-02-18,14,290!2026-02-20,16,316!2026-02-20,16,308!2026-04-23,74,328!2026-02-22,18,325!2026-02-20,16,308!2026-02-22,18,325!2026-02-22,18,325!2026-02-21,18,325-->

## see also

- [Bayes linear statistics](Bayes%20linear%20statistics.md)
- [Bayesian interpretation of regularization](Bayesian%20interpretation%20of%20regularization.md)
- [Kriging](kriging.md)
- [Gaussian free field](Gaussian%20free%20field.md)
- [Gauss–Markov process](Gauss–Markov%20process.md)
- [Gradient-enhanced kriging](gradient-enhanced%20kriging.md) \(GEK\)
- [Student's t-process](Student's%20t-distribution.md#Student's%20t-process)

## references

This text incorporates [content](https://en.wikipedia.org/wiki/Gaussian_process) from [Wikipedia](Wikipedia.md) available under the [CC BY-SA 4.0](https://creativecommons.org/licenses/by-sa/4.0/) license.

1. <a id="CITEREFMacKay2003"></a> [MacKay, David J.C.](David%20J.C.%20MacKay.md) \(2003\). [_Information Theory, Inference, and Learning Algorithms_](http://www.inference.phy.cam.ac.uk/itprnn/book.pdf) \(PDF\). [Cambridge University Press](Cambridge%20University%20Press.md). p. 540. [ISBN](ISBN%20(identifier).md) [9780521642989](https://en.wikipedia.org/wiki/Special:BookSources/9780521642989). The probability distribution of a function $y(\mathbf {x} )$ is a Gaussian processes if for any finite selection of points $\mathbf {x} ^{(1)},\mathbf {x} ^{(2)},\ldots ,\mathbf {x} ^{(N)}$, the density $P(y(\mathbf {x} ^{(1)}),y(\mathbf {x} ^{(2)}),\ldots ,y(\mathbf {x} ^{(N)}))$ is a Gaussian <a id="^ref-1"></a>^ref-1
2. <a id="CITEREFDudley1989"></a> Dudley, R.M. \(1989\). _Real Analysis and Probability_. Wadsworth and Brooks/Cole. [ISBN](ISBN%20(identifier).md) [0-534-10050-3](https://en.wikipedia.org/wiki/Special:BookSources/0-534-10050-3). <a id="^ref-2"></a>^ref-2
3. <a id="CITEREFAmos Lapidoth2017"></a> Amos Lapidoth \(8 February 2017\). [_A Foundation in Digital Communication_](https://books.google.com/books?id=6oTuDQAAQBAJ&q=independence). Cambridge University Press. [ISBN](ISBN%20(identifier).md) [978-1-107-17732-1](https://en.wikipedia.org/wiki/Special:BookSources/978-1-107-17732-1). <a id="^ref-3"></a>^ref-3
4. <a id="CITEREFKacSiegert1947"></a> Kac, M.; Siegert, A.J.F \(1947\). ["An Explicit Representation of a Stationary Gaussian Process"](https://doi.org/10.1214%2Faoms%2F1177730391). _The Annals of Mathematical Statistics_. __18__ \(3\): 438–442. [doi](doi%20(identifier).md):[10.1214/aoms/1177730391](https://doi.org/10.1214%2Faoms%2F1177730391). <a id="^ref-4"></a>^ref-4
5. <a id="CITEREFBishop2006"></a> Bishop, C.M. \(2006\). _Pattern Recognition and Machine Learning_. [Springer](Springer%20Science+Business%20Media.md). [ISBN](ISBN%20(identifier).md) [978-0-387-31073-2](https://en.wikipedia.org/wiki/Special:BookSources/978-0-387-31073-2). <a id="^ref-5"></a>^ref-5
6. <a id="CITEREFBarber2012"></a> Barber, David \(2012\). [_Bayesian Reasoning and Machine Learning_](http://web4.cs.ucl.ac.uk/staff/D.Barber/pmwiki/pmwiki.php?n=Brml.HomePage). [Cambridge University Press](Cambridge%20University%20Press.md). [ISBN](ISBN%20(identifier).md) [978-0-521-51814-7](https://en.wikipedia.org/wiki/Special:BookSources/978-0-521-51814-7). <a id="^ref-6"></a>^ref-6
7. <a id="CITEREFRasmussenWilliams, C.K.I2006"></a> Rasmussen, C.E.; Williams, C.K.I \(2006\). [_Gaussian Processes for Machine Learning_](http://www.gaussianprocess.org/gpml/). [MIT Press](MIT%20Press.md). [ISBN](ISBN%20(identifier).md) [978-0-262-18253-9](https://en.wikipedia.org/wiki/Special:BookSources/978-0-262-18253-9). <a id="^ref-7"></a>^ref-7
8. <a id="CITEREFGrimmettDavid Stirzaker2001"></a> Grimmett, Geoffrey; David Stirzaker \(2001\). _Probability and Random Processes_. [Oxford University Press](Oxford%20University%20Press.md). [ISBN](ISBN%20(identifier).md) [978-0198572220](https://en.wikipedia.org/wiki/Special:BookSources/978-0198572220). <a id="^ref-8"></a>^ref-8
9. <a id="CITEREFSeeger2004"></a> Seeger, Matthias \(2004\). "Gaussian Processes for Machine Learning". _International Journal of Neural Systems_. __14__ \(2\): 69–104. [CiteSeerX](CiteSeerX%20(identifier).md) [10.1.1.71.1079](https://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.71.1079). [doi](doi%20(identifier).md):[10.1142/s0129065704001899](https://doi.org/10.1142%2Fs0129065704001899). [PMID](PMID%20(identifier).md#PubMed%20identifier) [15112367](https://pubmed.ncbi.nlm.nih.gov/15112367). [S2CID](S2CID%20(identifier).md#S2CID) [52807317](https://api.semanticscholar.org/CorpusID:52807317). <a id="^ref-9"></a>^ref-9
10. <a id="CITEREFDudley1975"></a> [Dudley, R. M.](Richard%20M.%20Dudley.md) \(1975\). ["The Gaussian process and how to approach it"](https://www.mathunion.org/fileadmin/ICM/Proceedings/ICM1974.2/ICM1974.2.ocr.pdf) \(PDF\). _Proceedings of the International Congress of Mathematicians_. Vol. 2. pp. 143–146. <a id="^ref-10"></a>^ref-10
11. <a id="CITEREFBanerjeeGelfand2003"></a> Banerjee, Sudipto; Gelfand, Alan E. \(2003\). ["On smoothness properties of spatial processes"](https://doi.org/10.1016/S0047-259X(02)00016-7). _Journal of Multivariate Analysis_. __84__ \(1\): 85–100. [doi](doi%20(identifier).md):[10.1016/S0047-259X\(02\)00016-7](https://doi.org/10.1016%2FS0047-259X%2802%2900016-7). <a id="^ref-11"></a>^ref-11
12. <a id="CITEREFDudley2010"></a> [Dudley, R. M.](Richard%20M.%20Dudley.md) \(2010\). ["Sample Functions of the Gaussian Process"](http://projecteuclid.org/euclid.aop/1176997026). _Selected Works of R.M. Dudley_. Vol. 1. pp. 66–103. [doi](doi%20(identifier).md):[10.1007/978-1-4419-5821-1\_13](https://doi.org/10.1007%2F978-1-4419-5821-1_13). [ISBN](ISBN%20(identifier).md) [978-1-4419-5820-4](https://en.wikipedia.org/wiki/Special:BookSources/978-1-4419-5820-4). `{{[cite book](https://en.wikipedia.org/wiki/Template:Cite%20book)}}`: `|journal=` ignored \([help](https://en.wikipedia.org/wiki/Help:CS1%20errors#periodical_ignored)\) <a id="^ref-12"></a>^ref-12
13. <a id="CITEREFTalagrand2014"></a> [Talagrand, Michel](Michel%20Talagrand.md) \(2014\). [_Upper and lower bounds for stochastic processes: modern methods and classical problems_](https://www.springer.com/gp/book/9783642540745). Ergebnisse der Mathematik und ihrer Grenzgebiete. 3. Folge / A Series of Modern Surveys in Mathematics. Springer, Heidelberg. [ISBN](ISBN%20(identifier).md) [978-3-642-54074-5](https://en.wikipedia.org/wiki/Special:BookSources/978-3-642-54074-5). <a id="^ref-13"></a>^ref-13
14. <a id="CITEREFLedoux1996"></a> Ledoux, Michel \(1996\), "Isoperimetry and Gaussian analysis", in Dobrushin, Roland; Groeneboom, Piet; Ledoux, Michel \(eds.\), _Lectures on Probability Theory and Statistics: Ecole d'Eté de Probabilités de Saint-Flour XXIV–1994_, Lecture Notes in Mathematics, vol. 1648, Berlin: Springer, pp. 165–294, [doi](doi%20(identifier).md):[10.1007/BFb0095676](https://doi.org/10.1007%2FBFb0095676), [ISBN](ISBN%20(identifier).md) [978-3-540-62055-6](https://en.wikipedia.org/wiki/Special:BookSources/978-3-540-62055-6), [MR](MR%20(identifier).md) [1600888](https://mathscinet.ams.org/mathscinet-getitem?mr=1600888) <a id="^ref-14"></a>^ref-14
15. <a id="CITEREFAdler1990"></a> Adler, Robert J. \(1990\). _An Introduction to Continuity, Extrema, and Related Topics for General Gaussian Processes_. Vol. 12. Hayward, California: Institute of Mathematical Statistics. [ISBN](ISBN%20(identifier).md) [0-940600-17-X](https://en.wikipedia.org/wiki/Special:BookSources/0-940600-17-X). [JSTOR](JSTOR%20(identifier).md#content) [4355563](https://www.jstor.org/stable/4355563). [MR](MR%20(identifier).md) [1088478](https://mathscinet.ams.org/mathscinet-getitem?mr=1088478). `{{[cite book](https://en.wikipedia.org/wiki/Template:Cite%20book)}}`: `|journal=` ignored \([help](https://en.wikipedia.org/wiki/Help:CS1%20errors#periodical_ignored)\) <a id="^ref-15"></a>^ref-15
16. <a id="CITEREFBerman1992"></a> Berman, Simeon M. \(1992\). "Review of: Adler 1990 'An introduction to continuity...'". _Mathematical Reviews_. [MR](MR%20(identifier).md) [1088478](https://mathscinet.ams.org/mathscinet-getitem?mr=1088478). <a id="^ref-16"></a>^ref-16
17. <a id="CITEREFDudley1967"></a> [Dudley, R. M.](Richard%20M.%20Dudley.md) \(1967\). ["The sizes of compact subsets of Hilbert space and continuity of Gaussian processes"](https://doi.org/10.1016%2F0022-1236%2867%2990017-1). _Journal of Functional Analysis_. __1__ \(3\): 290–330. [doi](doi%20(identifier).md):[10.1016/0022-1236\(67\)90017-1](https://doi.org/10.1016%2F0022-1236%2867%2990017-1). <a id="^ref-17"></a>^ref-17
18. <a id="CITEREFMarcusShepp1972"></a> Marcus, M.B.; [Shepp, Lawrence A.](Lawrence%20Shepp.md) \(1972\). ["Sample behavior of Gaussian processes"](https://projecteuclid.org/euclid.bsmsp/1200514231). _Proceedings of the sixth Berkeley symposium on mathematical statistics and probability, vol. II: probability theory_. Vol. 6. Univ. California, Berkeley. pp. 423–441. <a id="^ref-18"></a>^ref-18
19. <a id="CITEREFMarcusShepp1970"></a> Marcus, Michael B.; [Shepp, Lawrence A.](Lawrence%20Shepp.md) \(1970\). ["Continuity of Gaussian processes"](https://doi.org/10.1090%2Fs0002-9947-1970-0264749-1). _[Transactions of the American Mathematical Society](Transactions%20of%20the%20American%20Mathematical%20Society.md)_. __151__ \(2\): 377–391. [doi](doi%20(identifier).md):[10.1090/s0002-9947-1970-0264749-1](https://doi.org/10.1090%2Fs0002-9947-1970-0264749-1). [JSTOR](JSTOR%20(identifier).md#content) [1995502](https://www.jstor.org/stable/1995502). <a id="^ref-19"></a>^ref-19
20. <a id="CITEREFAzmoodehSottinenViitasaariYazigi2014"></a> Azmoodeh, Ehsan; Sottinen, Tommi; Viitasaari, Lauri; Yazigi, Adil \(2014\). "Necessary and sufficient conditions for Hölder continuity of Gaussian processes". _Statistics & Probability Letters_. __94__: 230–235. [arXiv](ArXiv%20(identifier).md):[1403.2215](https://arxiv.org/abs/1403.2215). [doi](doi%20(identifier).md):[10.1016/j.spl.2014.07.030](https://doi.org/10.1016%2Fj.spl.2014.07.030). <a id="^ref-20"></a>^ref-20
21. <a id="CITEREFDriscoll1973"></a> Driscoll, Michael F. \(1973\). ["The reproducing kernel Hilbert space structure of the sample paths of a Gaussian process"](https://doi.org/10.1007%2FBF00534894). _Zeitschrift für Wahrscheinlichkeitstheorie und Verwandte Gebiete_. __26__ \(4\): 309–316. [doi](doi%20(identifier).md):[10.1007/BF00534894](https://doi.org/10.1007%2FBF00534894). [ISSN](ISSN%20(identifier).md) [0044-3719](https://search.worldcat.org/issn/0044-3719). [S2CID](S2CID%20(identifier).md#S2CID) [123348980](https://api.semanticscholar.org/CorpusID:123348980). <a id="^ref-21"></a>^ref-21
22. <a id="CITEREFJidlingWahlströmWillsSchön2017"></a> Jidling, Carl; Wahlström, Niklas; Wills, Adrian; Schön, Thomas B. \(2017-09-19\). "Linearly constrained Gaussian processes". [arXiv](ArXiv%20(identifier).md):[1703.00787](https://arxiv.org/abs/1703.00787) \[[stat.ML](https://arxiv.org/archive/stat.ML)\]. <a id="^ref-22"></a>^ref-22
23. The documentation for [scikit-learn](scikit-learn.md) also has similar [examples](http://scikit-learn.org/stable/auto_examples/gaussian_process/plot_compare_gpr_krr.html). <a id="^ref-23"></a>^ref-23
24. <a id="CITEREFLiuPrincipe, J.C.Haykin, S.2010"></a> Liu, W.; Principe, J.C.; Haykin, S. \(2010\). [_Kernel Adaptive Filtering: A Comprehensive Introduction_](https://web.archive.org/web/20160304042652/http://www.cnel.ufl.edu/~weifeng/publication.htm). [John Wiley](John%20Wiley%20&%20Sons.md). [ISBN](ISBN%20(identifier).md) [978-0-470-44753-6](https://en.wikipedia.org/wiki/Special:BookSources/978-0-470-44753-6). Archived from [the original](http://www.cnel.ufl.edu/~weifeng/publication.htm) on 2016-03-04. Retrieved 2010-03-26. <a id="^ref-24"></a>^ref-24
25. <a id="CITEREFÁlvarezRosascoLawrence2012"></a> Álvarez, Mauricio A.; Rosasco, Lorenzo; Lawrence, Neil D. \(2012\). ["Kernels for vector-valued functions: A review"](http://eprints.whiterose.ac.uk/114503/1/1106.6251v2.pdf) \(PDF\). _Foundations and Trends in Machine Learning_. __4__ \(3\): 195–266. [doi](doi%20(identifier).md):[10.1561/2200000036](https://doi.org/10.1561%2F2200000036). [S2CID](S2CID%20(identifier).md#S2CID) [456491](https://api.semanticscholar.org/CorpusID:456491). <a id="^ref-25"></a>^ref-25
26. <a id="CITEREFChenWangGorban2019"></a> Chen, Zexun; Wang, Bo; Gorban, Alexander N. \(2019\). ["Multivariate Gaussian and Student-t process regression for multi-output prediction"](https://doi.org/10.1007%2Fs00521-019-04687-8). _Neural Computing and Applications_. __32__ \(8\): 3005–3028. [arXiv](ArXiv%20(identifier).md):[1703.04455](https://arxiv.org/abs/1703.04455). [doi](doi%20(identifier).md):[10.1007/s00521-019-04687-8](https://doi.org/10.1007%2Fs00521-019-04687-8). <a id="^ref-26"></a>^ref-26
27. <a id="CITEREFStein1999"></a> Stein, M.L. \(1999\). _Interpolation of Spatial Data: Some Theory for Kriging_. [Springer](Springer%20Science+Business%20Media.md). <a id="^ref-27"></a>^ref-27
28. <a id="CITEREFSavesDiouaneBartoliLefebvre2023"></a> Saves, Paul; Diouane, Youssef; Bartoli, Nathalie; Lefebvre, Thierry; Morlier, Joseph \(2023\). "A mixed-categorical correlation kernel for Gaussian process". _Neurocomputing_. __550__ 126472. [arXiv](ArXiv%20(identifier).md):[2211.08262](https://arxiv.org/abs/2211.08262). [doi](doi%20(identifier).md):[10.1016/j.neucom.2023.126472](https://doi.org/10.1016%2Fj.neucom.2023.126472). <a id="^ref-28"></a>^ref-28
29. <a id="CITEREFPlataniosChatzis2014"></a> Platanios, Emmanouil A.; Chatzis, Sotirios P. \(2014\). "Gaussian Process-Mixture Conditional Heteroscedasticity". _IEEE Transactions on Pattern Analysis and Machine Intelligence_. __36__ \(5\): 888–900. [Bibcode](bibcode%20(identifier).md):[2014ITPAM..36..888P](https://ui.adsabs.harvard.edu/abs/2014ITPAM..36..888P). [doi](doi%20(identifier).md):[10.1109/TPAMI.2013.183](https://doi.org/10.1109%2FTPAMI.2013.183). [PMID](PMID%20(identifier).md#PubMed%20identifier) [26353224](https://pubmed.ncbi.nlm.nih.gov/26353224). [S2CID](S2CID%20(identifier).md#S2CID) [10424638](https://api.semanticscholar.org/CorpusID:10424638). <a id="^ref-29"></a>^ref-29
30. <a id="CITEREFChatzis2013"></a> Chatzis, Sotirios P. \(2013\). "A latent variable Gaussian process model with Pitman–Yor process priors for multiclass classification". _Neurocomputing_. __120__: 482–489. [doi](doi%20(identifier).md):[10.1016/j.neucom.2013.04.029](https://doi.org/10.1016%2Fj.neucom.2013.04.029). <a id="^ref-30"></a>^ref-30
31. <a id="CITEREFBanerjee2017"></a> Banerjee, Sudipto \(2017\). ["High-dimensional Bayesian Geostatistics"](https://doi.org/10.1214/17-BA1056R). _Bayesian Analysis_. __12__ \(2\): 583–614. [doi](doi%20(identifier).md):[10.1214/17-BA1056R](https://doi.org/10.1214%2F17-BA1056R). [PMC](PMC%20(identifier).md#PMCID) [5790125](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5790125). [PMID](PMID%20(identifier).md#PubMed%20identifier) [29391920](https://pubmed.ncbi.nlm.nih.gov/29391920). <a id="^ref-31"></a>^ref-31
32. <a id="CITEREFSmolaSchoellkopf2000"></a> Smola, A.J.; Schoellkopf, B. \(2000\). "Sparse greedy matrix approximation for machine learning". _Proceedings of the Seventeenth International Conference on Machine Learning_: 911–918. [CiteSeerX](CiteSeerX%20(identifier).md) [10.1.1.43.3153](https://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.43.3153). <a id="^ref-32"></a>^ref-32
33. <a id="CITEREFCsatoOpper2002"></a> Csato, L.; Opper, M. \(2002\). "Sparse on-line Gaussian processes". _Neural Computation_. __14__ \(3\): 641–668. [CiteSeerX](CiteSeerX%20(identifier).md) [10.1.1.335.9713](https://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.335.9713). [doi](doi%20(identifier).md):[10.1162/089976602317250933](https://doi.org/10.1162%2F089976602317250933). [PMID](PMID%20(identifier).md#PubMed%20identifier) [11860686](https://pubmed.ncbi.nlm.nih.gov/11860686). [S2CID](S2CID%20(identifier).md#S2CID) [11375333](https://api.semanticscholar.org/CorpusID:11375333). <a id="^ref-33"></a>^ref-33
34. <a id="CITEREFBanerjeeGelfandFinleySang2008"></a> Banerjee, Sudipto; Gelfand, Alan E.; Finley, Andrew O.; Sang, Huiyan \(2008\). ["Gaussian Predictive Process Models for large spatial datasets"](https://doi.org/10.1111/j.1467-9868.2008.00663.x). _Journal of the Royal Statistical Society, Series B \(Statistical Methodology\)_. __70__ \(4\): 825–848. [doi](doi%20(identifier).md):[10.1111/j.1467-9868.2008.00663.x](https://doi.org/10.1111%2Fj.1467-9868.2008.00663.x). [PMC](PMC%20(identifier).md#PMCID) [2741335](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2741335). [PMID](PMID%20(identifier).md#PubMed%20identifier) [19750209](https://pubmed.ncbi.nlm.nih.gov/19750209). <a id="^ref-34"></a>^ref-34
35. <a id="CITEREFLeeMallick2021"></a> Lee, Se Yoon; Mallick, Bani \(2021\). ["Bayesian Hierarchical Modeling: Application Towards Production Results in the Eagle Ford Shale of South Texas"](https://doi.org/10.1007%2Fs13571-020-00245-8). _Sankhya B_. __84__: 1–43. [doi](doi%20(identifier).md):[10.1007/s13571-020-00245-8](https://doi.org/10.1007%2Fs13571-020-00245-8). <a id="^ref-35"></a>^ref-35
36. <a id="CITEREFDattaBanerjeeFinleyGelfand2016"></a> Datta, Abhirup; Banerjee, Sudipto; Finley, Andrew; Gelfand, Alan \(2016\). ["Hierarchical Nearest-Neighbor Gaussian Process Models for Large Spatial Data"](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5927603). _Journal of the American Statistical Association_. __111__ \(514\): 800–812. [doi](doi%20(identifier).md):[10.1080/01621459.2015.1044091](https://doi.org/10.1080%2F01621459.2015.1044091). [PMC](PMC%20(identifier).md#PMCID) [5927603](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5927603). [PMID](PMID%20(identifier).md#PubMed%20identifier) [29720777](https://pubmed.ncbi.nlm.nih.gov/29720777). <a id="^ref-36"></a>^ref-36
37. <a id="CITEREFRanftlMelitoBadeliReinbacher-Köstinger2019"></a> Ranftl, Sascha; Melito, Gian Marco; Badeli, Vahid; Reinbacher-Köstinger, Alice; Ellermann, Katrin; von der Linden, Wolfgang \(2019-12-31\). ["Bayesian Uncertainty Quantification with Multi-Fidelity Data and Gaussian Processes for Impedance Cardiography of Aortic Dissection"](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7516489). _Entropy_. __22__ \(1\): 58. [Bibcode](bibcode%20(identifier).md):[2019Entrp..22...58R](https://ui.adsabs.harvard.edu/abs/2019Entrp..22...58R). [doi](doi%20(identifier).md):[10.3390/e22010058](https://doi.org/10.3390%2Fe22010058). [ISSN](ISSN%20(identifier).md) [1099-4300](https://search.worldcat.org/issn/1099-4300). [PMC](PMC%20(identifier).md#PMCID) [7516489](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7516489). [PMID](PMID%20(identifier).md#PubMed%20identifier) [33285833](https://pubmed.ncbi.nlm.nih.gov/33285833). <a id="^ref-37"></a>^ref-37
38. <a id="CITEREFNovakXiaoHronLee2020"></a> Novak, Roman; Xiao, Lechao; Hron, Jiri; Lee, Jaehoon; Alemi, Alexander A.; Sohl-Dickstein, Jascha; Schoenholz, Samuel S. \(2020\). "Neural Tangents: Fast and Easy Infinite Neural Networks in Python". _International Conference on Learning Representations_. [arXiv](ArXiv%20(identifier).md):[1912.02803](https://arxiv.org/abs/1912.02803). <a id="^ref-38"></a>^ref-38
39. <a id="CITEREFNeal2012"></a> Neal, Radford M. \(2012\). _Bayesian Learning for Neural Networks_. Springer Science and Business Media. <a id="^ref-39"></a>^ref-39
40. <a id="CITEREFMossGriffiths2020"></a> Moss, Henry B.; Griffiths, Ryan-Rhys \(2020\), [_Gaussian Process Molecule Property Prediction with FlowMO_](https://arxiv.org/abs/2010.01118), [arXiv](ArXiv%20(identifier).md):[2010.01118](https://arxiv.org/abs/2010.01118), retrieved 2025-09-06 <a id="^ref-40"></a>^ref-40
41. <a id="CITEREFGriffiths2022"></a> Griffiths, Ryan-Rhys \(2022\). _Applications of Gaussian Processes at Extreme Lengthscales: From Molecules to Black Holes_ \(PhD thesis\). University of Cambridge. [arXiv](ArXiv%20(identifier).md):[2303.14291](https://arxiv.org/abs/2303.14291). [doi](doi%20(identifier).md):[10.17863/CAM.93643](https://doi.org/10.17863%2FCAM.93643). <a id="^ref-41"></a>^ref-41
42. <a id="CITEREFShanksSullivanShazedHoepfner2024"></a> Shanks, B. L.; Sullivan, H. W.; Shazed, A. R.; Hoepfner, M. P. \(2024\). ["Accelerated Bayesian Inference for Molecular Simulations using Local Gaussian Process Surrogate Models"](https://pubs.acs.org/doi/full/10.1021/acs.jctc.3c01358). _Journal of Chemical Theory and Computation_. __20__ \(9\): 3798–3808. [arXiv](ArXiv%20(identifier).md):[2310.19108](https://arxiv.org/abs/2310.19108). [doi](doi%20(identifier).md):[10.1021/acs.jctc.3c01358](https://doi.org/10.1021%2Facs.jctc.3c01358). [PMID](PMID%20(identifier).md#PubMed%20identifier) [38551198](https://pubmed.ncbi.nlm.nih.gov/38551198). <a id="^ref-42"></a>^ref-42
43. <a id="CITEREFMorrisBobraAgolLee2020"></a> Morris, Brett M; Bobra, Monica G; Agol, Eric; Lee, Yu Jin; Hawley, Suzanne L \(2020-04-21\). ["The stellar variability noise floor for transiting exoplanet photometry with PLATO"](https://academic.oup.com/mnras/article/493/4/5489/5780234). _Monthly Notices of the Royal Astronomical Society_. __493__ \(4\): 5489–5498. [arXiv](ArXiv%20(identifier).md):[2002.08072](https://arxiv.org/abs/2002.08072). [doi](doi%20(identifier).md):[10.1093/mnras/staa618](https://doi.org/10.1093%2Fmnras%2Fstaa618). [ISSN](ISSN%20(identifier).md) [0035-8711](https://search.worldcat.org/issn/0035-8711). <a id="^ref-43"></a>^ref-43
44. <a id="CITEREFRajpaulAigrainOsborneReece2015"></a> Rajpaul, V.; Aigrain, S.; Osborne, M. A.; Reece, S.; Roberts, S. \(2015-09-21\). ["A Gaussian process framework for modelling stellar activity signals in radial velocity data"](https://doi.org/10.1093%2Fmnras%2Fstv1428). _Monthly Notices of the Royal Astronomical Society_. __452__ \(3\): 2269–2291. [arXiv](ArXiv%20(identifier).md):[1506.07304](https://arxiv.org/abs/1506.07304). [doi](doi%20(identifier).md):[10.1093/mnras/stv1428](https://doi.org/10.1093%2Fmnras%2Fstv1428). [ISSN](ISSN%20(identifier).md) [0035-8711](https://search.worldcat.org/issn/0035-8711). <a id="^ref-44"></a>^ref-44
45. <a id="CITEREFAigrainForeman-Mackey2023"></a> Aigrain, Suzanne; Foreman-Mackey, Daniel \(2023\). ["Gaussian Process Regression for Astronomical Time Series"](https://doi.org/10.1146/annurev-astro-052920-103508). _Annual Review of Astronomy and Astrophysics_. __61__: 350–359. [arXiv](ArXiv%20(identifier).md):[2209.08940](https://arxiv.org/abs/2209.08940). [Bibcode](bibcode%20(identifier).md):[2023ARA&A..61..329A](https://ui.adsabs.harvard.edu/abs/2023ARA&A..61..329A). [doi](doi%20(identifier).md):[10.1146/annurev-astro-052920-103508](https://doi.org/10.1146%2Fannurev-astro-052920-103508). <a id="^ref-45"></a>^ref-45
46. <a id="CITEREFBarragánAigrainKubyshkinaGandolfi2019"></a> Barragán, O; Aigrain, S; Kubyshkina, D; Gandolfi, D; Livingston, J; Fridlund, M C V; Fossati, L; Korth, J; Parviainen, H; Malavolta, L; Palle, E; Deeg, H J; Nowak, G; Rajpaul, V M; Zicher, N \(2019-11-21\). ["Radial velocity confirmation of K2-100b: a young, highly irradiated, and low-density transiting hot Neptune"](https://academic.oup.com/mnras/article/490/1/698/5569669). _Monthly Notices of the Royal Astronomical Society_. __490__ \(1\): 698–708. [arXiv](ArXiv%20(identifier).md):[1909.05252](https://arxiv.org/abs/1909.05252). [doi](doi%20(identifier).md):[10.1093/mnras/stz2569](https://doi.org/10.1093%2Fmnras%2Fstz2569). [ISSN](ISSN%20(identifier).md) [0035-8711](https://search.worldcat.org/issn/0035-8711). <a id="^ref-46"></a>^ref-46
47. <a id="CITEREFHaywoodCollier CameronQuelozBarros2014"></a> Haywood, R. D.; Collier Cameron, A.; Queloz, D.; Barros, S. C. C.; Deleuil, M.; Fares, R.; Gillon, M.; Lanza, A. F.; Lovis, C.; Moutou, C.; Pepe, F.; Pollacco, D.; Santerne, A.; Ségransan, D.; Unruh, Y. C. \(2014-09-21\). ["Planets and stellar activity: hide and seek in the CoRoT-7 system★"](http://academic.oup.com/mnras/article/443/3/2517/1750443/Planets-and-stellar-activity-hide-and-seek-in-the). _Monthly Notices of the Royal Astronomical Society_. __443__ \(3\): 2517–2531. [arXiv](ArXiv%20(identifier).md):[1407.1044](https://arxiv.org/abs/1407.1044). [doi](doi%20(identifier).md):[10.1093/mnras/stu1320](https://doi.org/10.1093%2Fmnras%2Fstu1320). [ISSN](ISSN%20(identifier).md) [1365-2966](https://search.worldcat.org/issn/1365-2966). <a id="^ref-47"></a>^ref-47
48. <a id="CITEREFAigrainPontZucker2012"></a> Aigrain, S.; Pont, F.; Zucker, S. \(2012-02-01\). ["A simple method to estimate radial velocity variations due to stellar activity using photometry"](https://doi.org/10.1111%2Fj.1365-2966.2011.19960.x). _Monthly Notices of the Royal Astronomical Society_. __419__ \(4\): 3147–3158. [arXiv](ArXiv%20(identifier).md):[1110.1034](https://arxiv.org/abs/1110.1034). [Bibcode](bibcode%20(identifier).md):[2012MNRAS.419.3147A](https://ui.adsabs.harvard.edu/abs/2012MNRAS.419.3147A). [doi](doi%20(identifier).md):[10.1111/j.1365-2966.2011.19960.x](https://doi.org/10.1111%2Fj.1365-2966.2011.19960.x). [ISSN](ISSN%20(identifier).md) [0035-8711](https://search.worldcat.org/issn/0035-8711). <a id="^ref-48"></a>^ref-48
49. <a id="CITEREFNicholsonAigrain2022"></a> Nicholson, B A; Aigrain, S \(2022-08-18\). ["Quasi-periodic Gaussian processes for stellar activity: From physical to kernel parameters"](https://academic.oup.com/mnras/article/515/4/5251/6651396). _Monthly Notices of the Royal Astronomical Society_. __515__ \(4\): 5251–5266. [doi](doi%20(identifier).md):[10.1093/mnras/stac2097](https://doi.org/10.1093%2Fmnras%2Fstac2097). [ISSN](ISSN%20(identifier).md) [0035-8711](https://search.worldcat.org/issn/0035-8711). <a id="^ref-49"></a>^ref-49
50. <a id="CITEREFKozłowskiKochanekUdalskiWyrzykowski2010"></a> Kozłowski, Szymon; Kochanek, Christopher S.; Udalski, A.; Wyrzykowski, ł.; Soszyński, I.; Szymański, M. K.; Kubiak, M.; Pietrzyński, G.; Szewczyk, O.; Ulaczyk, K.; Poleski, R.; The OGLE Collaboration \(2010-01-10\). ["Quantifying Quasar Variability as Part of a General Approach to Classifying Continuously Varying Sources"](https://iopscience.iop.org/article/10.1088/0004-637X/708/2/927). _The Astrophysical Journal_. __708__ \(2\): 927–945. [arXiv](ArXiv%20(identifier).md):[0909.1326](https://arxiv.org/abs/0909.1326). [Bibcode](bibcode%20(identifier).md):[2010ApJ...708..927K](https://ui.adsabs.harvard.edu/abs/2010ApJ...708..927K). [doi](doi%20(identifier).md):[10.1088/0004-637X/708/2/927](https://doi.org/10.1088%2F0004-637X%2F708%2F2%2F927). [ISSN](ISSN%20(identifier).md) [0004-637X](https://search.worldcat.org/issn/0004-637X). <a id="^ref-50"></a>^ref-50
51. <a id="CITEREFMacLeodIvezićKochanekKozłowski2010"></a> MacLeod, C. L.; Ivezić, ž.; Kochanek, C. S.; Kozłowski, S.; Kelly, B.; Bullock, E.; Kimball, A.; Sesar, B.; Westman, D.; Brooks, K.; Gibson, R.; Becker, A. C.; de Vries, W. H. \(2010-10-01\). ["Modeling the Time Variability of SDSS Stripe 82 Quasars as a Damped Random Walk"](https://iopscience.iop.org/article/10.1088/0004-637X/721/2/1014). _The Astrophysical Journal_. __721__ \(2\): 1014–1033. [arXiv](ArXiv%20(identifier).md):[1004.0276](https://arxiv.org/abs/1004.0276). [Bibcode](bibcode%20(identifier).md):[2010ApJ...721.1014M](https://ui.adsabs.harvard.edu/abs/2010ApJ...721.1014M). [doi](doi%20(identifier).md):[10.1088/0004-637X/721/2/1014](https://doi.org/10.1088%2F0004-637X%2F721%2F2%2F1014). [ISSN](ISSN%20(identifier).md) [0004-637X](https://search.worldcat.org/issn/0004-637X). <a id="^ref-51"></a>^ref-51
52. <a id="CITEREFAbbottAbbottAbrahamAcernese2020"></a> Abbott, R.; Abbott, T. D.; Abraham, S.; Acernese, F.; Ackley, K.; Adams, C.; Adhikari, R. X.; Adya, V. B.; Affeldt, C.; Agathos, M.; Agatsuma, K.; Aggarwal, N.; Aguiar, O. D.; Aich, A.; Aiello, L. \(2020-06-01\). ["GW190814: Gravitational Waves from the Coalescence of a 23 Solar Mass Black Hole with a 2.6 Solar Mass Compact Object"](https://doi.org/10.3847%2F2041-8213%2Fab960f). _The Astrophysical Journal Letters_. __896__ \(2\): L44. [arXiv](ArXiv%20(identifier).md):[2006.12611](https://arxiv.org/abs/2006.12611). [Bibcode](bibcode%20(identifier).md):[2020ApJ...896L..44A](https://ui.adsabs.harvard.edu/abs/2020ApJ...896L..44A). [doi](doi%20(identifier).md):[10.3847/2041-8213/ab960f](https://doi.org/10.3847%2F2041-8213%2Fab960f). [ISSN](ISSN%20(identifier).md) [2041-8205](https://search.worldcat.org/issn/2041-8205). <a id="^ref-52"></a>^ref-52
53. <a id="CITEREFLochnerMcEwenPeirisLahav2016"></a> Lochner, Michelle; McEwen, Jason D.; Peiris, Hiranya V.; Lahav, Ofer; Winter, Max K. \(2016-08-01\). ["Photometric Supernova Classification with Machine Learning"](https://doi.org/10.3847%2F0067-0049%2F225%2F2%2F31). _The Astrophysical Journal Supplement Series_. __225__ \(2\): 31. [arXiv](ArXiv%20(identifier).md):[1603.00882](https://arxiv.org/abs/1603.00882). [Bibcode](bibcode%20(identifier).md):[2016ApJS..225...31L](https://ui.adsabs.harvard.edu/abs/2016ApJS..225...31L). [doi](doi%20(identifier).md):[10.3847/0067-0049/225/2/31](https://doi.org/10.3847%2F0067-0049%2F225%2F2%2F31). [ISSN](ISSN%20(identifier).md) [0067-0049](https://search.worldcat.org/issn/0067-0049). <a id="^ref-53"></a>^ref-53
54. <a id="CITEREFYangYanZhangDai2021"></a> Yang, Shenbang; Yan, Dahai; Zhang, Pengfei; Dai, Benzhong; Zhang, Li \(2021-02-01\). ["Gaussian Process Modeling Fermi-LAT γ-Ray Blazar Variability: A Sample of Blazars with γ-Ray Quasi-periodicities"](https://doi.org/10.3847%2F1538-4357%2Fabcbff). _The Astrophysical Journal_. __907__ \(2\): 105. [arXiv](ArXiv%20(identifier).md):[2011.10186](https://arxiv.org/abs/2011.10186). [Bibcode](bibcode%20(identifier).md):[2021ApJ...907..105Y](https://ui.adsabs.harvard.edu/abs/2021ApJ...907..105Y). [doi](doi%20(identifier).md):[10.3847/1538-4357/abcbff](https://doi.org/10.3847%2F1538-4357%2Fabcbff). [ISSN](ISSN%20(identifier).md) [0004-637X](https://search.worldcat.org/issn/0004-637X). <a id="^ref-54"></a>^ref-54
55. <a id="CITEREFvan HaasterenVallisneri2014"></a> van Haasteren, Rutger; Vallisneri, Michele \(2014-11-11\). ["New advances in the Gaussian-process approach to pulsar-timing data analysis"](https://link.aps.org/doi/10.1103/PhysRevD.90.104012). _Physical Review D_. __90__ \(10\) 104012. [arXiv](ArXiv%20(identifier).md):[1407.1838](https://arxiv.org/abs/1407.1838). [Bibcode](bibcode%20(identifier).md):[2014PhRvD..90j4012V](https://ui.adsabs.harvard.edu/abs/2014PhRvD..90j4012V). [doi](doi%20(identifier).md):[10.1103/PhysRevD.90.104012](https://doi.org/10.1103%2FPhysRevD.90.104012). [ISSN](ISSN%20(identifier).md) [1550-7998](https://search.worldcat.org/issn/1550-7998). <a id="^ref-55"></a>^ref-55

## external links

> ![Wikibooks logo](../../archives/Wikimedia%20Commons/Wikibooks-logo-en-noslogan.svg) Wikibooks has a book on the topic of: ___[Gaussian process](https://en.wikibooks.org/wiki/Gaussian%20process)___

### literature

- [The Gaussian Processes Web Site, including the text of Rasmussen and Williams' Gaussian Processes for Machine Learning](https://gaussianprocess.org/)
- <a id="CITEREFEbden2015"></a> Ebden, Mark \(2015\). "Gaussian Processes: A Quick Introduction". [arXiv](ArXiv%20(identifier).md):[1505.02965](https://arxiv.org/abs/1505.02965) \[[math.ST](https://arxiv.org/archive/math.ST)\].
- [A Review of Gaussian Random Fields and Correlation Functions](http://publications.nr.no/917_Rapport.pdf)
- [Efficient Reinforcement Learning using Gaussian Processes](https://web.archive.org/web/20180826005000/https://pdfs.semanticscholar.org/c9f2/1b84149991f4d547b3f0f625f710750ad8d9.pdf)

### software

- Further information: [Comparison of Gaussian process software](Comparison%20of%20Gaussian%20process%20software.md)

- [GPML: A comprehensive Matlab toolbox for GP regression and classification](http://www.gaussianprocess.org/gpml/code/matlab/doc/)
- [STK: a Small \(Matlab/Octave\) Toolbox for Kriging and GP modeling](https://sourceforge.net/projects/kriging)
- [Kriging module in UQLab framework \(Matlab\)](http://www.uqlab.com/)
- [CODES Toolbox: implementations of Kriging, variational kriging and multi-fidelity models \(Matlab\)](http://codes.arizona.edu/toolbox/)<sup>\[_[permanent dead link](https://en.wikipedia.org/wiki/Wikipedia:Link%20rot)_\]</sup>
- [Matlab/Octave function for stationary Gaussian fields](http://au.mathworks.com/matlabcentral/fileexchange/38880:)<sup>\[_[permanent dead link](https://en.wikipedia.org/wiki/Wikipedia:Link%20rot)_\]</sup>
- [Yelp MOE – A black box optimization engine using Gaussian process learning](https://github.com/Yelp/MOE)
- [ooDACE](http://www.sumo.intec.ugent.be/ooDACE) [Archived](https://web.archive.org/web/20200809021046/http://sumo.intec.ugent.be/ooDACE) 2020-08-09 at the [Wayback Machine](Wayback%20Machine.md) – A flexible object-oriented Kriging Matlab toolbox.
- [GPstuff – Gaussian process toolbox for Matlab and Octave](https://web.archive.org/web/20141009045756/http://becs.aalto.fi/en/research/bayes/gpstuff/)
- [GPy – A Gaussian processes framework in Python](https://github.com/SheffieldML/GPy)
- [GSTools - A geostatistical toolbox, including Gaussian process regression, written in Python](https://github.com/GeoStat-Framework/GSTools)
- [Interactive Gaussian process regression demo](http://www.tmpl.fi/gp/)
- [Basic Gaussian process library written in C++11](https://github.com/ChristophJud/GPR)
- [scikit-learn](http://scikit-learn.org/) – A machine learning library for Python which includes Gaussian process regression and classification
- [SAMBO Optimization](https://sambo-optimization.github.io/) library for Python supports sequential optimization driven by Gaussian process regressor from [scikit-learn](scikit-learn.md).
- [\[1\]](https://github.com/modsim/KriKit) - The Kriging toolKit \(KriKit\) is developed at the Institute of Bio- and Geosciences 1 \(IBG-1\) of Forschungszentrum Jülich \(FZJ\)

### video tutorials

- [Gaussian Process Basics by David MacKay](http://videolectures.net/gpip06_mackay_gpb)
- [Learning with Gaussian Processes by Carl Edward Rasmussen](http://videolectures.net/epsrcws08_rasmussen_lgp)
- [Bayesian inference and Gaussian processes by Carl Edward Rasmussen](http://videolectures.net/mlss07_rasmussen_bigp)

|                                                                                                                                                      | <!-- - [v](https://en.wikipedia.org/wiki/Template:Stochastic%20processes) <br/> - [t](https://en.wikipedia.org/wiki/Template%20talk:Stochastic%20processes) <br/> - [e](https://en.wikipedia.org/wiki/Special:EditPage/Template%3AStochastic%20processes) <br/> --> [Stochastic processes](stochastic%20process.md)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          |
| ---------------------------------------------------------------------------------------------------------------------------------------------------: | ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
|                                                                         __[Discrete time](discrete-time%20stochastic%20process.md#classifications)__ | - [Bernoulli process](Bernoulli%20process.md) <br/> - [Branching process](branching%20process.md) <br/> - [Chinese restaurant process](Chinese%20restaurant%20process.md) <br/> - [Galton–Watson process](Galton–Watson%20process.md) <br/> - [Independent and identically distributed random variables](independent%20and%20identically%20distributed%20random%20variables.md) <br/> - [Markov chain](Markov%20chain.md) <br/> - [Moran process](Moran%20process.md) <br/> - [Random walk](random%20walk.md)  <br/> &nbsp;&nbsp;&nbsp;&nbsp;- [Loop-erased](loop-erased%20random%20walk.md) <br/> &nbsp;&nbsp;&nbsp;&nbsp;- [Self-avoiding](self-avoiding%20walk.md) <br/> &nbsp;&nbsp;&nbsp;&nbsp;- [Biased](biased%20random%20walk%20on%20a%20graph.md) <br/> &nbsp;&nbsp;&nbsp;&nbsp;- [Maximal entropy](maximal%20entropy%20random%20walk.md)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           |
|                                                                                     __[Continuous time](continuous-time%20stochastic%20process.md)__ | - [Additive process](additive%20process.md) <br/> - [Airy process](airy%20process.md) <br/> - [Bessel process](Bessel%20process.md) <br/> - [Birth–death process](birth–death%20process.md)  <br/> &nbsp;&nbsp;&nbsp;&nbsp;- [pure birth](birth%20process.md) <br/> - [Brownian motion](Wiener%20process.md)  <br/> &nbsp;&nbsp;&nbsp;&nbsp;- [Bridge](Brownian%20bridge.md) <br/> &nbsp;&nbsp;&nbsp;&nbsp;- [Dyson](Dyson%20Brownian%20motion.md) <br/> &nbsp;&nbsp;&nbsp;&nbsp;- [Excursion](Brownian%20excursion.md) <br/> &nbsp;&nbsp;&nbsp;&nbsp;- [Fractional](fractional%20Brownian%20motion.md) <br/> &nbsp;&nbsp;&nbsp;&nbsp;- [Geometric](geometric%20Brownian%20motion.md) <br/> &nbsp;&nbsp;&nbsp;&nbsp;- [Meander](Brownian%20meander.md) <br/> - [Cauchy process](Cauchy%20process.md) <br/> - [Contact process](contact%20process%20(mathematics).md) <br/> - [Continuous-time random walk](continuous-time%20random%20walk.md) <br/> - [Cox process](Cox%20process.md) <br/> - [Diffusion process](diffusion%20process.md) <br/> - [Empirical process](empirical%20process.md) <br/> - [Feller process](Feller%20process.md) <br/> - [Fleming–Viot process](Fleming–Viot%20process.md) <br/> - [Gamma process](gamma%20process.md) <br/> - [Geometric process](geometric%20process.md) <br/> - [Hawkes process](Hawkes%20process.md) <br/> - [Hunt process](Hunt%20process.md) <br/> - [Interacting particle systems](interacting%20particle%20system.md) <br/> - [Itô diffusion](Itô%20diffusion.md) <br/> - [Itô process](Itô%20process.md#Itô%20processes) <br/> - [Jump diffusion](jump%20diffusion.md) <br/> - [Jump process](jump%20process.md) <br/> - [Lévy process](Lévy%20process.md) <br/> - [Local time](local%20time%20(mathematics).md) <br/> - [Markov additive process](Markov%20additive%20process.md) <br/> - [McKean–Vlasov process](McKean–Vlasov%20process.md) <br/> - [Ornstein–Uhlenbeck process](Ornstein–Uhlenbeck%20process.md) <br/> - [Poisson process](Poisson%20point%20process.md)  <br/> &nbsp;&nbsp;&nbsp;&nbsp;- [Compound](compound%20Poisson%20process.md) <br/> &nbsp;&nbsp;&nbsp;&nbsp;- [Non-homogeneous](non-homogeneous%20Poisson%20process.md) <br/> - [Quasimartingale](quasimartingale.md) <br/> - [Schramm–Loewner evolution](Schramm–Loewner%20evolution.md) <br/> - [Semimartingale](semimartingale.md) <br/> - [Sigma-martingale](sigma-martingale.md) <br/> - [Stable process](stable%20process.md) <br/> - [Superprocess](superprocess.md) <br/> - [Telegraph process](telegraph%20process.md) <br/> - [Variance gamma process](variance%20gamma%20process.md) <br/> - [Wiener process](Wiener%20process.md) <br/> - [Wiener sausage](Wiener%20sausage.md) |
|                                                                                                                                             __Both__ | - [Branching process](branching%20process.md) <br/> - [Gaussian process](Gaussian%20process.md) <br/> - [Hidden Markov model \(HMM\)](hidden%20Markov%20model.md) <br/> - [Markov process](Markov%20process.md) <br/> - [Martingale](martingale%20(probability%20theory).md)  <br/> &nbsp;&nbsp;&nbsp;&nbsp;- [Differences](martingale%20difference%20sequence.md) <br/> &nbsp;&nbsp;&nbsp;&nbsp;- [Local](local%20martingale.md) <br/> &nbsp;&nbsp;&nbsp;&nbsp;- [Sub-](submartingale.md) <br/> &nbsp;&nbsp;&nbsp;&nbsp;- [Super-](supermartingale.md) <br/> - [Random dynamical system](random%20dynamical%20system.md) <br/> - [Regenerative process](regenerative%20process.md) <br/> - [Renewal process](renewal%20process.md) <br/> - [Stochastic chains with memory of variable length](stochastic%20chains%20with%20memory%20of%20variable%20length.md) <br/> - [White noise](white%20noise.md)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      |
|                                                                                                                                 __Fields and other__ | - [Dirichlet process](Dirichlet%20process.md) <br/> - [Gaussian random field](Gaussian%20random%20field.md) <br/> - [Gibbs measure](Gibbs%20measure.md) <br/> - [Hopfield model](Hopfield%20model.md) <br/> - [Ising model](Ising%20model.md)  <br/> &nbsp;&nbsp;&nbsp;&nbsp;- [Potts model](Potts%20model.md) <br/> &nbsp;&nbsp;&nbsp;&nbsp;- [Boolean network](Boolean%20network.md) <br/> - [Markov random field](Markov%20random%20field.md) <br/> - [Percolation](percolation%20theory.md) <br/> - [Pitman–Yor process](Pitman–Yor%20process.md) <br/> - [Point process](point%20process.md)  <br/> &nbsp;&nbsp;&nbsp;&nbsp;- [Cox](point%20process.md#Cox%20point%20process) <br/> &nbsp;&nbsp;&nbsp;&nbsp;- [Determinantal](determinantal%20point%20process.md) <br/> &nbsp;&nbsp;&nbsp;&nbsp;- [Poisson](Poisson%20point%20process.md) <br/> - [Random field](random%20field.md) <br/> - [Random graph](random%20graph.md)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           |
|                                                                                                           __[Time series models](time%20series.md)__ | - [Autoregressive conditional heteroskedasticity \(ARCH\) model](autoregressive%20conditional%20heteroskedasticity.md) <br/> - [Autoregressive integrated moving average \(ARIMA\) model](autoregressive%20integrated%20moving%20average.md) <br/> - [Autoregressive \(AR\) model](autoregressive%20model.md) <br/> - [Autoregressive moving-average \(ARMA\) model](autoregressive%20moving-average%20model.md) <br/> - [Generalized autoregressive conditional heteroskedasticity \(GARCH\) model](autoregressive%20conditional%20heteroskedasticity.md) <br/> - [Moving-average \(MA\) model](moving-average%20model.md)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  |
|                                                                                                   __[Financial models](asset%20pricing%20model.md)__ | - [Binomial options pricing model](binomial%20options%20pricing%20model.md) <br/> - [Black–Derman–Toy](Black–Derman–Toy%20model.md) <br/> - [Black–Karasinski](Black–Karasinski%20model.md) <br/> - [Black–Scholes](Black–Scholes%20model.md) <br/> - [Chan–Karolyi–Longstaff–Sanders \(CKLS\)](Chan–Karolyi–Longstaff–Sanders%20process.md) <br/> - [Chen](Chen%20model.md) <br/> - [Constant elasticity of variance \(CEV\)](constant%20elasticity%20of%20variance%20model.md) <br/> - [Cox–Ingersoll–Ross \(CIR\)](Cox–Ingersoll–Ross%20model.md) <br/> - [Garman–Kohlhagen](Garman–Kohlhagen%20model.md#Garman–Kohlhagen%20model) <br/> - [Heath–Jarrow–Morton \(HJM\)](Heath–Jarrow–Morton%20framework.md) <br/> - [Heston](Heston%20model.md) <br/> - [Ho–Lee](Ho–Lee%20model.md) <br/> - [Hull–White](Hull–White%20model.md) <br/> - [Korn-Kreer-Lenssen](Korn–Kreer–Lenssen%20model.md) <br/> - [LIBOR market](LIBOR%20market%20model.md) <br/> - [Rendleman–Bartter](Rendleman–Bartter%20model.md) <br/> - [SABR volatility](SABR%20volatility%20model.md) <br/> - [Vašíček](Vasicek%20model.md) <br/> - [Wilkie](Wilkie%20investment%20model.md)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   |
|                                                                                                   __[Actuarial models](actuarial%20mathematics.md)__ | - [Bühlmann](Bühlmann%20model.md) <br/> - [Cramér–Lundberg](Cramér–Lundberg%20model.md) <br/> - [Risk process](risk%20process.md) <br/> - [Sparre–Anderson](Sparre–Anderson%20model.md#Sparre%20Andersen%20model)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            |
|                                                                                                           __[Queueing models](queueing%20model.md)__ | - [Bulk](bulk%20queue.md) <br/> - [Fluid](fluid%20queue.md) <br/> - [Generalized queueing network](G-network.md) <br/> - [M/G/1](M_G_1%20queue.md) <br/> - [M/M/1](M_M_1%20queue.md) <br/> - [M/M/c](M_M_c%20queue.md)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       |
|                                                                                                                                       __Properties__ | - [Càdlàg paths](càdlàg.md) <br/> - [Continuous](continuous%20stochastic%20process.md) <br/> - [Continuous paths](sample-continuous%20process.md) <br/> - [Ergodic](ergodicity.md) <br/> - [Exchangeable](exchangeable%20random%20variables.md) <br/> - [Feller-continuous](Feller-continuous%20process.md) <br/> - [Gauss–Markov](Gauss–Markov%20process.md) <br/> - [Markov](Markov%20property.md) <br/> - [Mixing](mixing%20(mathematics).md) <br/> - [Piecewise-deterministic](piecewise-deterministic%20Markov%20process.md) <br/> - [Predictable](predictable%20process.md) <br/> - [Progressively measurable](progressively%20measurable%20process.md) <br/> - [Self-similar](self-similar%20process.md) <br/> - [Stationary](stationary%20process.md) <br/> - [Time-reversible](time%20reversibility.md)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             |
|                                                                                                                                   __Limit theorems__ | - [Central limit theorem](central%20limit%20theorem.md) <br/> - [Donsker's theorem](Donsker's%20theorem.md) <br/> - [Doob's martingale convergence theorems](Doob's%20martingale%20convergence%20theorems.md) <br/> - [Ergodic theorem](ergodic%20theorem.md) <br/> - [Fisher–Tippett–Gnedenko theorem](Fisher–Tippett–Gnedenko%20theorem.md) <br/> - [Large deviation principle](large%20deviation%20principle.md) <br/> - [Law of large numbers \(weak/strong\)](law%20of%20large%20numbers.md) <br/> - [Law of the iterated logarithm](law%20of%20the%20iterated%20logarithm.md) <br/> - [Maximal ergodic theorem](maximal%20ergodic%20theorem.md) <br/> - [Sanov's theorem](Sanov's%20theorem.md) <br/> - [Zero–one laws](zero–one%20law.md) \([Blumenthal](Blumenthal's%20zero–one%20law.md), [Borel–Cantelli](Borel–Cantelli%20lemma.md), [Engelbert–Schmidt](Engelbert–Schmidt%20zero–one%20law.md), [Hewitt–Savage](Hewitt–Savage%20zero–one%20law.md), [Kolmogorov](Kolmogorov's%20zero–one%20law.md), [Lévy](Lévy's%20zero–one%20law.md#convergence%20of%20conditional%20expectations%20Lévy's%20zero-one%20law)\)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 |
|                                                              __[Inequalities](list%20of%20inequalities.md#probability%20theory%20and%20statistics)__ | - [Burkholder–Davis–Gundy](Burkholder–Davis–Gundy%20inequalities.md#martingales) <br/> - [Doob's martingale](Doob's%20martingale%20inequality.md) <br/> - [Doob's upcrossing](Doob's%20upcrossing%20inequality.md#Doob's%20upcrossing%20inequality) <br/> - [Kunita–Watanabe](Kunita–Watanabe%20inequality.md) <br/> - [Marcinkiewicz–Zygmund](Marcinkiewicz–Zygmund%20inequality.md)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        |
|                                                                                                                                            __Tools__ | - [Cameron–Martin formula](Cameron–Martin%20formula.md) <br/> - [Convergence of random variables](convergence%20of%20random%20variables.md) <br/> - [Doléans-Dade exponential](Doléans-Dade%20exponential.md) <br/> - [Doob decomposition theorem](Doob%20decomposition%20theorem.md) <br/> - [Doob–Meyer decomposition theorem](Doob–Meyer%20decomposition%20theorem.md) <br/> - [Doob's optional stopping theorem](Doob's%20optional%20stopping%20theorem.md) <br/> - [Dynkin's formula](Dynkin's%20formula.md) <br/> - [Feynman–Kac formula](Feynman–Kac%20formula.md) <br/> - [Filtration](filtration%20(probability%20theory).md) <br/> - [Girsanov theorem](Girsanov%20theorem.md) <br/> - [Infinitesimal generator](infinitesimal%20generator%20(stochastic%20processes).md) <br/> - [Itô integral](Itô%20integral.md) <br/> - [Itô's lemma](Itô's%20lemma.md) <br/> - [Karhunen–Loève theorem](Karhunen–Loève%20theorem.md) <br/> - [Kolmogorov continuity theorem](Kolmogorov%20continuity%20theorem.md) <br/> - [Kolmogorov extension theorem](Kolmogorov%20extension%20theorem.md) <br/> - [Lévy–Prokhorov metric](Lévy–Prokhorov%20metric.md) <br/> - [Malliavin calculus](Malliavin%20calculus.md) <br/> - [Martingale representation theorem](martingale%20representation%20theorem.md) <br/> - [Optional stopping theorem](optional%20stopping%20theorem.md) <br/> - [Prokhorov's theorem](Prokhorov's%20theorem.md) <br/> - [Quadratic variation](quadratic%20variation.md) <br/> - [Reflection principle](reflection%20principle%20(Wiener%20process).md) <br/> - [Skorokhod integral](Skorokhod%20integral.md) <br/> - [Skorokhod's representation theorem](Skorokhod's%20representation%20theorem.md) <br/> - [Skorokhod space](Skorokhod%20space.md#Skorokhod%20space) <br/> - [Snell envelope](Snell%20envelope.md) <br/> - [Stochastic differential equation](stochastic%20differential%20equation.md)  <br/> &nbsp;&nbsp;&nbsp;&nbsp;- [Tanaka](Tanaka%20equation.md) <br/> - [Stopping time](stopping%20time.md) <br/> - [Stratonovich integral](Stratonovich%20integral.md) <br/> - [Uniform integrability](uniform%20integrability.md) <br/> - [Usual hypotheses](usual%20hypotheses.md#augmented%20filtration) <br/> - [Wiener space](Wiener%20space.md)  <br/> &nbsp;&nbsp;&nbsp;&nbsp;- [Classical](classical%20Wiener%20space.md) <br/> &nbsp;&nbsp;&nbsp;&nbsp;- [Abstract](abstract%20Wiener%20space.md)                                                                                                                                                                                                                                                                                     |
|                                                                                                                                      __Disciplines__ | - [Actuarial mathematics](actuarial%20mathematics.md) <br/> - [Control theory](stochastic%20control.md) <br/> - [Econometrics](econometrics.md) <br/> - [Ergodic theory](ergodic%20theory.md) <br/> - [Extreme value theory \(EVT\)](extreme%20value%20theory.md) <br/> - [Large deviations theory](large%20deviations%20theory.md) <br/> - [Mathematical finance](mathematical%20finance.md) <br/> - [Mathematical statistics](mathematical%20statistics.md) <br/> - [Probability theory](probability%20theory.md) <br/> - [Queueing theory](queueing%20theory.md) <br/> - [Renewal theory](renewal%20theory.md) <br/> - [Ruin theory](ruin%20theory.md) <br/> - [Signal processing](signal%20processing.md) <br/> - [Statistics](statistics.md) <br/> - [Stochastic analysis](stochastic%20analysis.md) <br/> - [Time series analysis](time%20series%20analysis.md) <br/> - [Machine learning](machine%20learning.md)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      |
| - [List of topics](list%20of%20stochastic%20processes%20topics.md) <br/> - [Category](https://en.wikipedia.org/wiki/Category:Stochastic%20processes) |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |

|              | [Authority control databases](https://en.wikipedia.org/wiki/Help:Authority%20control) [![Edit this at Wikidata](../../archives/Wikimedia%20Commons/OOjs%20UI%20icon%20edit-ltr-progressive.svg)](https://www.wikidata.org/wiki/Q1496376#identifiers)                                                                               |
| -----------: | ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| __National__ | - [United States](https://id.loc.gov/authorities/sh85053558) <br/> - [France](https://catalogue.bnf.fr/ark:/12148/cb119469389) <br/> - [BnF data](https://data.bnf.fr/ark:/12148/cb119469389) <br/> - [Japan](https://id.ndl.go.jp/auth/ndlna/01180243) <br/> - [Israel](https://www.nli.org.il/en/authorities/987007560462305171) |
|    __Other__ | - [Yale LUX](https://lux.collections.yale.edu/view/concept/77408187-bb16-4ebe-ae4a-6a6fc1ae7ef5)                                                                                                                                                                                                                                   |

> [Categories](https://en.wikipedia.org/wiki/Help:Category):
>
> - [Stochastic processes](https://en.wikipedia.org/wiki/Category:Stochastic%20processes)
> - [Kernel methods for machine learning](https://en.wikipedia.org/wiki/Category:Kernel%20methods%20for%20machine%20learning)
> - [Nonparametric Bayesian statistics](https://en.wikipedia.org/wiki/Category:Nonparametric%20Bayesian%20statistics)
> - [Normal distribution](https://en.wikipedia.org/wiki/Category:Normal%20distribution)
