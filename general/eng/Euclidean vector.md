---
aliases:
  - Euclidean vector
  - Euclidean vectors
  - geometric vector
  - geometric vectors
  - spatial vector
  - spatial vectors
  - vector
  - vectors
tags:
  - flashcard/active/general/eng/Euclidean_vector
  - language/in/English
---

# Euclidean vector

- For {@{mathematical vectors in general}@}, see {@{[Vector \(mathematics and physics\)](vector%20(mathematics%20and%20physics).md)}@}. For other uses, see [Vector \(disambiguation\)](vector%20(disambiguation).md). <!--SR:!2026-02-11,281,332!2026-06-03,375,359-->

> {@{![A vector pointing from _A_ to _B_](../../archives/Wikimedia%20Commons/Vector%20from%20A%20to%20B.svg)}@}
>
> {@{A vector pointing from _A_ to _B_}@} <!--SR:!2026-03-04,289,332!2026-06-19,390,359-->

In {@{[mathematics](mathematics.md), [physics](physics.md), and [engineering](engineering.md)}@}, {@{a __Euclidean vector__ or simply a __vector__ \(sometimes called a __geometric vector__<sup>[\[1\]](#^ref-1)</sup> or __spatial vector__<sup>[\[2\]](#^ref-2)</sup>\)}@} is {@{a geometric object that has [magnitude](magnitude%20(mathematics).md) \(or [length](Euclidean%20norm.md#Euclidean%20norm)\) and [direction](direction%20(geometry).md)}@}. Euclidean vectors can be {@{added and scaled to form a [vector space](vector%20space.md)}@}. {@{A _[vector quantity](vector%20quantity.md)_}@} is {@{a vector-valued [physical quantity](physical%20quantity.md)}@}, including {@{[units of measurement](units%20of%20measurement.md) and possibly a [support](support%20(mathematics).md)}@}, formulated as {@{a _[directed line segment](directed%20line%20segment.md#directed%20line%20segment)_}@}. A vector is frequently depicted graphically as {@{an arrow connecting an _initial point_ _A_ with a _terminal point_ _B_}@},<sup>[\[3\]](#^ref-3)</sup> and denoted by {@{${\stackrel {\longrightarrow }{AB} }$}@}. <!--SR:!2026-05-19,360,359!2026-04-25,341,352!2026-06-12,384,359!2026-05-19,361,359!2026-01-11,256,332!2026-05-23,364,359!2026-02-14,282,332!2026-02-13,282,332!2026-01-12,257,332!2026-03-11,296,332-->

A vector is {@{what is needed to "carry" the point _A_ to the point _B_}@}; {@{the Latin word _vector_}@} means {@{"carrier"}@}.<sup>[\[4\]](#^ref-4)</sup> It was first used by {@{18th century astronomers investigating planetary revolution around the Sun}@}.<sup>[\[5\]](#^ref-5)</sup> {@{The magnitude of the vector}@} is {@{the distance between the two points}@}, and the direction refers to {@{the direction of [displacement](displacement%20(geometry).md) from _A_ to _B_}@}. {@{Many [algebraic operations](algebraic%20operation.md) on [real numbers](real%20number.md)}@} such as {@{[addition](addition.md), [subtraction](subtraction.md), [multiplication](multiplication.md), and [negation](additive%20inverse.md)}@} have {@{close analogues for vectors}@},<sup>[\[6\]](#^ref-6)</sup> operations which {@{obey the familiar algebraic laws of [commutativity](commutativity.md), [associativity](associativity.md), and [distributivity](distributivity.md)}@}. {@{These operations and associated laws}@} qualify [Euclidean](Euclidean%20space.md) vectors as an example of {@{the more generalized concept of vectors defined simply as elements of a [vector space](vector%20space.md)}@}. <!--SR:!2026-06-18,389,359!2026-01-10,256,332!2026-05-01,347,352!2027-02-23,566,332!2026-01-10,256,332!2026-06-09,380,359!2026-05-30,371,359!2026-05-06,352,352!2026-05-05,351,352!2026-05-14,355,352!2026-02-08,278,332!2026-05-05,349,352!2026-03-01,286,332-->

Vectors play {@{an important role in [physics](physics.md)}@}: {@{the [velocity](velocity.md) and [acceleration](acceleration.md) of a moving object and the [forces](force.md) acting on it}@} can {@{all be described with vectors}@}.<sup>[\[7\]](#^ref-7)</sup> {@{Many other physical quantities}@} can be {@{usefully thought of as vectors}@}. Although {@{most of them do not represent distances}@} \(except, for example, {@{[position](position%20(vector).md) or [displacement](displacement%20(vector).md)}@}\), {@{their magnitude and direction}@} can still be {@{represented by the length and direction of an arrow}@}. {@{The mathematical representation of a physical vector}@} depends on {@{the [coordinate system](coordinate%20system.md) used to describe it}@}. Other vector-like objects that {@{describe [physical quantities](physical%20quantities.md)}@} and {@{transform in a similar way under changes of the coordinate system}@} include {@{[pseudovectors](pseudovector.md) and [tensors](tensor.md)}@}.<sup>[\[8\]](#^ref-8)</sup> <!--SR:!2026-02-02,275,332!2026-02-01,274,332!2026-01-17,262,332!2026-04-19,335,352!2026-06-14,385,359!2026-05-16,357,359!2026-05-23,364,359!2026-01-16,261,332!2026-01-29,272,332!2026-01-31,274,332!2026-03-05,285,332!2026-05-16,357,359!2026-03-06,291,332!2026-05-05,346,352-->

## history

The vector concept, as it is known today, is the result of a gradual development over a period of more than 200 years. About a dozen people contributed significantly to its development.<sup>[\[9\]](#^ref-9)</sup> In 1835, [Giusto Bellavitis](Giusto%20Bellavitis.md) abstracted the basic idea when he established the concept of [equipollence](equipollence%20(geometry).md). Working in a Euclidean plane, he made equipollent any pair of [parallel](parallel%20(geometry).md) line segments of the same length and orientation. Essentially, he realized an [equivalence relation](equivalence%20relation.md) on the pairs of points \(bipoints\) in the plane, and thus erected the first space of vectors in the plane.<sup>[\[9\]](#^ref-9)</sup><sup>:&hairsp;52–4&hairsp;</sup> The term _vector_ was introduced by [William Rowan Hamilton](William%20Rowan%20Hamilton.md) as part of a [quaternion](quaternion.md), which is a sum _q_ = _s_ + _v_ of a [real number](real%20number.md) _s_ \(also called _scalar_\) and a 3-dimensional _vector_. Like Bellavitis, Hamilton viewed vectors as representative of [classes](equivalence%20class.md) of equipollent directed segments. As [complex numbers](complex%20number.md) use an [imaginary unit](imaginary%20unit.md) to complement the [real line](real%20line.md), Hamilton considered the vector _v_ to be the _imaginary part_ of a quaternion:<sup>[\[10\]](#^ref-10)</sup>

> The algebraically imaginary part, being geometrically constructed by a straight line, or radius vector, which has, in general, for each determined quaternion, a determined length and determined direction in space, may be called the vector part, or simply the vector of the quaternion.

Several other mathematicians developed vector-like systems in the middle of the nineteenth century, including [Augustin Cauchy](Augustin%20Cauchy.md), [Hermann Grassmann](Hermann%20Grassmann.md), [August Möbius](August%20Möbius.md), [Comte de Saint-Venant](Comte%20de%20Saint-Venant.md), and [Matthew O'Brien](Matthew%20O'Brien%20(mathematician).md). Grassmann's 1840 work _Theorie der Ebbe und Flut_ \(Theory of the Ebb and Flow\) was the first system of spatial analysis that is similar to today's system, and had ideas corresponding to the cross product, scalar product and vector differentiation. Grassmann's work was largely neglected until the 1870s.<sup>[\[9\]](#^ref-9)</sup> [Peter Guthrie Tait](Peter%20Guthrie%20Tait.md) carried the quaternion standard after Hamilton. His 1867 _Elementary Treatise of Quaternions_ included extensive treatment of the nabla or [del operator](del.md) ∇. In 1878, _[Elements of Dynamic](Elements%20of%20Dynamic.md)_ was published by [William Kingdon Clifford](William%20Kingdon%20Clifford.md). Clifford simplified the quaternion study by isolating the [dot product](dot%20product.md) and [cross product](cross%20product.md) of two vectors from the complete quaternion product. This approach made vector calculations available to engineers—and others working in three dimensions and skeptical of the fourth.

[Josiah Willard Gibbs](Josiah%20Willard%20Gibbs.md), who was exposed to quaternions through [James Clerk Maxwell](James%20Clerk%20Maxwell.md)'s _Treatise on Electricity and Magnetism_, separated off their vector part for independent treatment. The first half of Gibbs's _Elements of Vector Analysis_, published in 1881, presents what is essentially the modern system of vector analysis.<sup>[\[9\]](#^ref-9)</sup><sup>[\[6\]](#^ref-6)</sup> In 1901, [Edwin Bidwell Wilson](Edwin%20Bidwell%20Wilson.md) published _[Vector Analysis](Vector%20Analysis.md)_, adapted from Gibbs's lectures, which banished any mention of quaternions in the development of vector calculus.

## overview

In {@{[physics](physics.md) and [engineering](engineering.md)}@}, a vector is typically regarded as {@{a geometric entity characterized by a [magnitude](magnitude%20(mathematics).md) and a [relative direction](relative%20direction.md)}@}. It is formally defined as {@{a [directed line segment](directed%20line%20segment.md#directed%20line%20segment), or arrow, in a [Euclidean space](Euclidean%20space.md)}@}.<sup>[\[11\]](#^ref-11)</sup> In {@{[pure mathematics](pure%20mathematics.md)}@}, a [vector](vector%20(mathematics).md) is defined {@{more generally as any element of a [vector space](vector%20space.md)}@}. In this context, vectors are {@{abstract entities which may or may not be characterized by a magnitude and a direction}@}. This generalized definition implies that {@{the above-mentioned geometric entities are a special kind of abstract vectors}@}, as they are {@{elements of a special kind of vector space called [Euclidean space](Euclidean%20space.md)}@}. This particular article is about {@{vectors strictly defined as arrows in Euclidean space}@}. When it becomes {@{necessary to distinguish these special vectors from vectors as defined in pure mathematics}@}, they are sometimes referred to as {@{___geometric___, ___spatial___, or ___Euclidean___ vectors}@}. <!--SR:!2026-05-28,369,359!2026-05-09,355,352!2026-05-18,362,359!2026-05-09,350,352!2026-02-14,282,332!2026-05-06,347,352!2026-05-07,353,352!2026-05-14,355,352!2025-11-11,193,312!2026-02-13,282,332!2026-02-09,277,332-->

A Euclidean vector may possess {@{a definite _initial point_ and _terminal point_}@}; {@{such a condition may be emphasized}@} calling the result {@{a ___bound vector___}@}.<sup>[\[12\]](#^ref-12)</sup> When {@{only the magnitude and direction of the vector matter, and the particular initial or terminal points are of no importance}@}, the vector is called {@{a ___free vector___}@}. {@{The distinction between bound and free vectors}@} is especially {@{relevant in mechanics}@}, where {@{a [force](force.md) applied to a body has a point of contact}@} \(see {@{[resultant force](resultant%20force.md) and [couple](couple%20(mechanics).md)}@}\). <!--SR:!2026-02-11,280,332!2026-01-02,251,332!2026-05-22,364,359!2026-04-15,331,352!2026-05-05,349,352!2026-05-14,356,359!2026-03-12,292,332!2025-12-16,230,332!2026-06-13,384,359-->

Two arrows ${\stackrel {\,\longrightarrow }{AB} }$ and ${\stackrel {\,\longrightarrow }{A'B'} }$ in space {@{represent the same free vector}@} if {@{they have the same magnitude and direction}@}: that is, they are {@{[equipollent](equipollence%20(geometry).md) if the quadrilateral _ABB′A′_ is a [parallelogram](parallelogram.md)}@}. If {@{the Euclidean space is equipped with a choice of [origin](origin%20(mathematics).md)}@}, then a free vector is equivalent to {@{the bound vector of the same magnitude and direction whose initial point is the origin}@}. <!--SR:!2026-06-02,374,359!2026-06-13,384,359!2026-02-19,287,332!2026-03-16,296,332!2026-02-09,279,332-->

{@{The term _vector_}@} also has {@{generalizations to higher dimensions}@}, and to {@{more formal approaches with much wider applications}@}. <!--SR:!2026-05-18,359,359!2026-05-01,342,352!2026-01-10,255,332-->

### further information

In {@{classical [Euclidean geometry](Euclidean%20geometry.md) \(i.e., [synthetic geometry](synthetic%20geometry.md)\)}@}, vectors were {@{introduced \(during the 19th century\) as [equivalence classes](equivalence%20class.md) under [equipollence](equipollence%20(geometry).md), of [ordered pairs](ordered%20pair.md) of points}@}; {@{two pairs \(_A_, _B_\) and \(_C_, _D_\) being equipollent}@} if {@{the points _A_, _B_, _D_, _C_, in this order, form a [parallelogram](parallelogram.md)}@}. Such an equivalence class is called {@{a _vector_, more precisely, a Euclidean vector}@}.<sup>[\[13\]](#^ref-13)</sup> {@{The equivalence class of \(_A_, _B_\)}@} is often denoted {@{${\overrightarrow {AB} }$}@}. <!--SR:!2026-01-16,261,332!2026-05-08,354,352!2026-05-12,353,352!2026-01-01,250,332!2026-01-14,259,332!2026-05-02,348,352!2026-02-17,285,332-->

A Euclidean vector is thus {@{an equivalence class of directed segments with the same magnitude \(e.g., the length of the [line segment](line%20segment.md) \(_A_, _B_\)\)}@} and {@{same direction \(e.g., the direction from _A_ to _B_\)}@}.<sup>[\[14\]](#^ref-14)</sup> In {@{physics}@}, Euclidean vectors are used to {@{represent physical quantities that have both magnitude and direction}@}, but {@{are not located at a specific place}@}, in contrast to {@{[scalars](scalar%20(mathematics).md), which have no direction}@}.<sup>[\[7\]](#^ref-7)</sup> For example, {@{[velocity](velocity.md), [forces](force.md) and [acceleration](acceleration.md)}@} are represented by vectors. <!--SR:!2026-05-07,348,352!2026-05-02,348,352!2026-01-31,274,332!2025-12-24,242,332!2026-05-14,355,352!2026-01-31,274,332!2026-05-29,370,359-->

In {@{modern geometry}@}, Euclidean spaces are often defined {@{from [linear algebra](linear%20algebra.md)}@}. More precisely, a Euclidean space _E_ is defined as {@{a set to which is associated an [inner product space](inner%20product%20space.md) of finite dimension over the reals ${\overrightarrow {E} }$ (annotation: we have the inner product operation)}@}, and {@{a [group action](group%20action%20(mathematics).md) of the [additive group](additive%20group.md) of ${\overrightarrow {E} }$, which is [free](free%20action.md#free) and [transitive](transitive%20action.md#transitivity%20properties) (annotation: we can add vectors intuitively)}@} \(See {@{[Affine space](affine%20space.md) for details of this construction}@}\). {@{The elements of ${\overrightarrow {E} }$}@} are called {@{[translations](translation%20(geometry).md)}@}. It has been proven that {@{the two definitions of Euclidean spaces are equivalent}@}, and that {@{the equivalence classes under equipollence may be identified with translations}@}. <!--SR:!2026-05-26,367,359!2026-05-08,354,352!2025-12-21,235,332!2025-11-20,197,312!2026-02-10,280,332!2026-05-05,351,352!2026-01-09,254,332!2026-04-19,335,352!2026-05-09,350,352-->

Sometimes, Euclidean vectors are {@{considered without reference to a Euclidean space}@}. In this case, a Euclidean vector is {@{an element of a normed vector space of finite dimension over the reals}@}, or, typically, {@{an element of the [real coordinate space](real%20coordinate%20space.md) $\mathbb {R} ^{n}$ equipped with the [dot product](dot%20product.md)}@}. This makes sense, as {@{the addition in such a vector space}@} {@{acts freely and transitively on the vector space itself}@}. That is, {@{$\mathbb {R} ^{n}$}@} is {@{a Euclidean space, with itself as an associated vector space, and the dot product as an inner product}@}. <!--SR:!2026-02-24,276,339!2026-05-04,350,352!2026-02-09,278,332!2026-05-02,348,352!2026-01-30,273,332!2025-12-25,243,332!2026-01-28,271,332-->

{@{The Euclidean space $\mathbb {R} ^{n}$}@} is often presented as {@{_the_ [standard Euclidean space](Standard%20Euclidean%20space.md#standard) of dimension _n_}@}. This is motivated by the fact that {@{every Euclidean space of dimension _n_ is [isomorphic](isomorphism.md) to the Euclidean space $\mathbb {R} ^{n}$}@}. More precisely, given {@{such a Euclidean space}@}, one may {@{choose any point _O_ as an [origin](origin%20(geometry).md)}@}. By {@{[Gram–Schmidt process](Gram–Schmidt%20process.md)}@}, one may also {@{find an [orthonormal basis](orthonormal%20basis.md) of the associated vector space}@} \(a basis such that {@{the inner product of two basis vectors is 0 if they are different and 1 if they are equal}@}\). This defines {@{[Cartesian coordinates](Cartesian%20coordinates.md) of any point _P_ of the space}@}, as {@{the coordinates on this basis of the vector ${\overrightarrow {OP} }$}@}. These choices define {@{an isomorphism of the given Euclidean space onto $\mathbb {R} ^{n}$}@}, by {@{mapping any point to the [_n_-tuple](tuple.md) of its Cartesian coordinates}@}, and {@{every vector to its [coordinate vector](coordinate%20vector.md)}@}. <!--SR:!2026-05-18,359,359!2026-05-03,349,352!2026-05-08,349,352!2026-01-08,253,332!2026-05-18,359,359!2026-03-13,298,332!2026-03-07,292,332!2026-02-12,281,332!2026-06-14,384,359!2026-05-17,358,359!2026-06-17,388,359!2026-02-11,279,332!2026-05-18,359,359-->

### examples in one dimension

Since {@{the physicist's concept of [force](force%20(physics).md)}@} has {@{a direction and a magnitude}@}, it may be {@{seen as a vector}@}. As an example, consider {@{a rightward force _F_ of 15 [newtons](newton%20(unit).md)}@}. If {@{the positive [axis](Cartesian%20coordinate%20system.md) is also directed rightward}@}, then _F_ is represented by {@{the vector 15 N}@}, and if {@{positive points leftward, then the vector for _F_ is −15 N}@}. In either case, {@{the magnitude of the vector is 15 N}@}. Likewise, {@{the vector representation of a displacement Δ<!-- markdown separator -->_s_ of 4 [meters](meter%20(unit).md)}@} would be {@{4 m or −4 m, depending on its direction}@}, and {@{its magnitude would be 4 m}@} regardless. <!--SR:!2026-01-09,254,332!2026-05-13,354,352!2026-05-07,349,352!2026-05-17,359,359!2026-05-09,350,352!2026-03-08,291,332!2026-05-14,355,352!2026-04-29,345,352!2026-03-12,292,332!2026-05-27,368,359!2026-01-09,254,332-->

### in physics and engineering

Vectors are {@{fundamental in the physical sciences}@}. They can be used to {@{represent any quantity that has magnitude, has direction, and which adheres to the rules of vector addition}@}. An example is {@{[velocity](velocity.md), the magnitude of which is [speed](speed.md)}@}. For instance, {@{the velocity _5 meters per second upward_}@} could be represented by {@{the vector \(0, 5\) \(in 2 dimensions with the positive _y_-axis as 'up'\)}@}. Another quantity represented by a vector is {@{[force](force.md)}@}, since {@{it has a magnitude and direction and follows the rules of vector addition}@}.<sup>[\[7\]](#^ref-7)</sup> Vectors also {@{describe many other physical quantities}@}, such as {@{linear displacement, [displacement](displacement%20(vector).md), linear acceleration, [angular acceleration](angular%20acceleration.md), [linear momentum](linear%20momentum.md), and [angular momentum](angular%20momentum.md)}@}. Other physical vectors, such as {@{the [electric](electric%20field.md) and [magnetic field](magnetic%20field.md)}@}, are represented as {@{a system of vectors at each point of a physical space}@}; that is, {@{a [vector field](vector%20field.md)}@}. Examples of {@{quantities that have magnitude and direction, but fail to follow the rules of vector addition}@}, are {@{angular displacement and electric current}@}. Consequently, {@{these are not vectors}@}. <!--SR:!2026-01-14,259,332!2026-02-12,282,332!2026-06-01,373,359!2026-03-15,300,332!2026-05-14,355,352!2026-01-18,262,339!2026-05-08,349,352!2026-04-14,325,352!2026-02-02,272,332!2026-05-25,366,359!2026-02-09,278,332!2026-04-23,339,352!2026-05-19,360,359!2026-01-10,255,332!2026-05-07,353,352-->

### In Cartesian space

In {@{the [Cartesian coordinate system](Cartesian%20coordinate%20system.md)}@}, {@{a bound vector}@} can be represented by {@{identifying the coordinates of its initial and terminal point}@}. For instance, {@{the points _A_ = \(1, 0, 0\) and _B_ = \(0, 1, 0\) in space}@} determine {@{the bound vector ${\overrightarrow {AB} }$ pointing from the point _x_ = 1 on the _x_-axis to the point _y_ = 1 on the _y_-axis}@}. <!--SR:!2026-03-12,297,332!2026-06-05,377,359!2026-04-30,346,352!2025-10-04,177,312!2026-01-03,252,332-->

In {@{Cartesian coordinates}@}, a free vector may be thought of {@{in terms of a corresponding bound vector}@}, in this sense, whose {@{initial point has the coordinates of the origin _O_ = \(0, 0, 0\)}@}. It is then {@{determined by the coordinates of that bound vector's terminal point}@}. Thus {@{the free vector represented by \(1, 0, 0\)}@} is {@{a vector of unit length—pointing along the direction of the positive _x_-axis}@}. <!--SR:!2026-02-05,278,332!2026-03-13,296,332!2026-03-11,291,332!2026-02-05,278,332!2026-05-28,369,359!2026-05-14,355,352-->

{@{This coordinate representation of free vectors}@} allows {@{their algebraic features to be expressed in a convenient numerical fashion}@}. For example, {@{the sum of the two \(free\) vectors \(1, 2, 3\) and \(−2, 0, 4\)}@} is {@{the \(free\) vector $$(1,2,3)+(-2,0,4)=(1-2,2+0,3+4)=(-1,2,7)\,.$$}@} <!--SR:!2026-05-06,352,352!2026-01-29,272,332!2026-03-17,298,332!2026-05-08,354,352-->

### Euclidean and affine vectors

In {@{the geometrical and physical settings}@}, it is sometimes possible to {@{associate, in a natural way, a _length_ or magnitude and a direction to vectors}@}. In addition, {@{the notion of direction}@} is strictly associated with {@{the notion of an _angle_ between two vectors}@}. If {@{the [dot product](dot%20product.md) of two vectors is defined}@}—{@{a scalar-valued product of two vectors}@}—then {@{it is also possible to define a length}@}; the dot product gives {@{a convenient algebraic characterization of both angle \(a function of the dot product between any two non-zero vectors\) and length \(the square root of the dot product of a vector by itself\)}@}. In {@{three dimensions}@}, it is further possible to {@{define the [cross product](cross%20product.md)}@}, which supplies {@{an algebraic characterization of the [area](area.md) and [orientation](orientation%20(geometry).md)}@} in {@{space of the [parallelogram](parallelogram.md) defined by two vectors \(used as sides of the parallelogram\)}@}. In {@{any dimension \(and, in particular, higher dimensions\)}@}, it is possible to {@{define the [exterior product](exterior%20product.md)}@}, which \(among other things\) supplies {@{an algebraic characterization of the area and orientation in space of the _n_-dimensional [parallelotope](parallelepiped.md#parallelotope) defined by _n_ vectors}@}. <!--SR:!2026-01-30,273,332!2026-05-09,350,352!2026-03-10,295,332!2026-06-16,387,359!2026-01-12,257,332!2026-05-17,358,359!2026-03-06,286,332!2026-02-10,280,332!2026-01-30,273,332!2026-05-04,350,352!2026-02-14,282,332!2026-05-16,357,359!2026-05-09,355,352!2026-03-10,291,332!2026-05-07,348,352-->

In {@{a [pseudo-Euclidean space](pseudo-Euclidean%20space.md)}@}, {@{a vector's squared length}@} can be {@{positive, negative, or zero}@}. An important example is {@{[Minkowski space](Minkowski%20space.md)}@} \(which is {@{important to our understanding of [special relativity](special%20relativity.md)}@}\). <!--SR:!2026-06-05,377,359!2026-05-21,362,359!2026-03-15,295,332!2026-02-12,282,332!2026-05-14,355,352-->

However, it is not {@{always possible or desirable to define the length of a vector}@}. {@{This more general type of spatial vector}@} is {@{the subject of [vector spaces](vector%20space.md) \(for free vectors\)}@} and {@{[affine spaces](affine%20space.md) \(for bound vectors, as each represented by an ordered pair of "points"\)}@}. One physical example comes from {@{[thermodynamics](thermodynamics.md)}@}, where {@{many quantities of interest}@} can be {@{considered vectors in a space with no notion of length or angle}@}.<sup>[\[15\]](#^ref-15)</sup> <!--SR:!2026-03-11,291,332!2026-01-12,257,332!2026-03-05,290,332!2026-03-13,298,332!2026-05-11,352,352!2026-05-29,370,359!2026-04-13,324,352-->

### generalizations

In {@{physics, as well as mathematics}@}, a vector is often {@{identified with a [tuple](tuple.md) of components, or list of numbers}@}, that {@{act as scalar coefficients for a set of [basis vectors](basis%20vector.md)}@}. When {@{the basis is transformed}@}, for example by {@{rotation or stretching}@}, then {@{the components of any vector in terms of that basis also transform in an opposite sense}@}. {@{The vector itself has not changed}@}, but {@{the basis has}@}, so {@{the components of the vector must change to compensate}@}. The vector is called {@{_covariant_ or _contravariant_}@}, depending on {@{how the transformation of the vector's components is related to the transformation of the basis}@}. In general, {@{contravariant vectors}@} are {@{"regular vectors" with units of distance \(such as a displacement\), or distance times some other unit \(such as velocity or acceleration\)}@}; {@{covariant vectors}@}, on the other hand, have {@{units of one-over-distance such as [gradient](gradient.md)}@}. If {@{you change units \(a special case of a [change of basis](change%20of%20basis.md)\) from meters to millimeters}@}, {@{a scale factor of 1/1000}@}, {@{a displacement of 1 m becomes 1000 mm}@}—{@{a contravariant change in numerical value}@}. In contrast, {@{a gradient of 1 [K](Kelvin.md)/m becomes 0.001 K/mm}@}—{@{a covariant change in value}@} \(for more, see {@{[covariance and contravariance of vectors](covariance%20and%20contravariance%20of%20vectors.md)}@}\). {@{[Tensors](tensor.md)}@} are {@{another type of quantity that behave in this way}@}; a vector is {@{one type of [tensor](tensor.md)}@}. <!--SR:!2026-02-09,279,332!2025-12-31,249,332!2026-03-15,300,332!2026-05-05,346,352!2026-05-14,355,352!2025-11-07,207,332!2026-05-06,352,352!2026-01-27,270,332!2026-03-03,288,332!2026-01-14,259,332!2026-01-15,260,332!2026-03-14,299,332!2025-12-27,245,332!2026-05-12,353,352!2026-05-06,352,352!2026-01-19,264,332!2026-05-21,362,359!2026-06-01,373,359!2026-02-07,277,332!2025-10-03,173,312!2026-05-27,368,359!2025-11-06,206,332!2026-06-13,327,312!2026-05-07,353,352!2026-02-05,278,332-->

In {@{pure [mathematics](mathematics.md)}@}, a vector is {@{any element of a [vector space](vector%20space.md) over some [field](field%20(mathematics).md)}@} and is often {@{represented as a [coordinate vector](coordinate%20vector.md)}@}. The vectors described in this article are {@{a very special case of this general definition}@}, because {@{they are contravariant with respect to the ambient space}@}. {@{Contravariance}@} captures {@{the physical intuition behind the idea that a vector has "magnitude and direction"}@}. <!--SR:!2026-05-08,349,352!2026-05-14,355,352!2026-05-02,348,352!2026-03-18,299,332!2026-05-14,355,352!2026-06-11,383,359!2026-05-16,357,359-->

## representations

- Further information: ::@:: [Vector representation](vector%20representation.md) <!--SR:!2026-01-15,260,332!2026-04-29,345,352-->

> ![Vector arrow pointing from A to B](../../archives/Wikimedia%20Commons/Vector%20from%20A%20to%20B.svg)

Vectors are usually {@{denoted in [lowercase](lowercase.md) boldface, as in $\mathbf {u}$<!-- markdown separator -->__,__ $\mathbf {v}$ and $\mathbf {w}$}@}, or in {@{lowercase italic boldface, as in ___a___}@}. \({@{[Uppercase](uppercase.md) letters}@} are typically {@{used to represent [matrices](matrix%20(mathematics).md)}@}.\) Other conventions include {@{${\vec {a} }$ or <u>_a_</u>, especially in handwriting}@}. Alternatively, some use {@{a [tilde](tilde.md) \(~\) or a wavy underline drawn beneath the symbol, e.g. ${\underset {^{\sim } }{a} }$}@}, which is {@{a convention for indicating boldface type}@}. If {@{the vector represents a directed [distance](distance.md) or [displacement](displacement%20(vector).md) from a point _A_ to a point _B_ \(see figure\)}@}, it can also be denoted as {@{${\stackrel {\longrightarrow }{AB} }$ or <u>_AB_</u>}@}. In {@{[German](German%20language.md) literature}@}, it was especially {@{common to represent vectors with small [fraktur](fraktur.md) letters such as ${\mathfrak {a} }$}@}. <!--SR:!2026-05-14,355,352!2026-02-05,278,332!2026-02-16,284,332!2026-05-05,351,352!2026-02-04,277,332!2026-03-12,297,332!2026-05-04,348,352!2026-04-08,320,352!2026-03-08,288,332!2026-03-04,284,332!2026-01-28,271,332-->

Vectors are usually {@{shown in graphs or other diagrams as arrows \(directed [line segments](line%20segment.md)\)}@}, as illustrated in the figure. Here, {@{the point _A_}@} is called {@{the _origin_, _tail_, _base_, or _initial point_}@}, and {@{the point _B_}@} is called {@{the _head_, _tip_, _endpoint_, _terminal point_ or _final point_}@}. {@{The length of the arrow}@} is {@{proportional to the vector's [magnitude](magnitude%20(mathematics).md)}@}, while {@{the direction in which the arrow points indicates the vector's direction}@}. <!--SR:!2026-03-13,298,332!2026-05-03,347,352!2026-03-03,288,332!2026-05-01,347,352!2026-06-09,381,359!2026-03-11,291,332!2026-03-16,296,332!2026-05-04,350,352-->

> ![The notations used to indicate that a vector is going into (left) or coming out of (right) the screen or a page](../../archives/Wikimedia%20Commons/Notation%20for%20vectors%20in%20or%20out%20of%20a%20plane.svg)

On {@{a two-dimensional diagram}@}, {@{a vector [perpendicular](perpendicular.md) to the [plane](plane%20(mathematics).md) of the diagram}@} is sometimes desired. These vectors are {@{commonly shown as small circles}@}. {@{A circle with a dot at its centre \(Unicode U+2299 ⊙\)}@} indicates {@{a vector pointing out of the front of the diagram, toward the viewer}@}. {@{A circle with a cross inscribed in it \(Unicode U+2297 ⊗\)}@} indicates {@{a vector pointing into and behind the diagram}@}. These can be thought of as {@{viewing the tip of an [arrow](arrow%20(weapon).md) head on}@} and {@{viewing the flights of an arrow from the back}@}. <!--SR:!2026-05-03,349,352!2026-05-07,353,352!2026-05-08,354,352!2026-04-15,331,352!2026-05-04,350,352!2026-09-26,452,332!2026-05-11,352,352!2026-03-15,300,332!2026-05-18,360,359-->

> {@{![A vector in the Cartesian plane, showing the position of a point _A_ with coordinates \(2, 3\).](../../archives/Wikimedia%20Commons/Position%20vector.svg)}@}
>
> {@{A vector in the Cartesian plane}@}, showing {@{the position of a point _A_ with coordinates \(2, 3\)}@}. <!--SR:!2026-06-11,382,359!2026-02-07,277,332!2026-05-04,348,352-->

<!-- markdownlint MD028 -->

> ![Vector in a cartesian coordinate system. __a__ = __a__<sub>_x_</sub> + __a__<sub>_y_</sub> + __a__<sub>_z_</sub>](../../archives/Wikimedia%20Commons/3D%20Vector.svg)

In order to {@{calculate with vectors}@}, {@{the graphical representation may be too cumbersome}@}. {@{Vectors in an _n_-dimensional Euclidean space}@} can be {@{represented as [coordinate vectors](coordinate%20vector.md) in a [Cartesian coordinate system](Cartesian%20coordinate%20system.md)}@}. {@{The endpoint of a vector}@} can be identified with {@{an ordered list of _n_ real numbers \(_n_-[tuple](tuple.md)\)}@}. These numbers are {@{the [coordinates](Cartesian%20coordinate.md) of the endpoint of the vector}@}, with respect to {@{a given [Cartesian coordinate system](Cartesian%20coordinate%20system.md)}@}, and are typically called {@{the _[scalar components](scalar%20component.md)_ \(or _scalar projections_\)}@} of {@{the vector on the axes of the coordinate system}@}. <!--SR:!2026-05-22,363,359!2026-05-12,353,352!2026-06-03,375,359!2026-05-18,359,359!2025-12-26,244,332!2026-05-02,348,352!2026-03-06,291,332!2026-01-11,256,332!2026-05-17,358,359!2026-05-06,347,352-->

As {@{an example in two dimensions \(see figure\)}@}, {@{the vector from the origin _O_ = \(0, 0\) to the point _A_ = \(2, 3\)}@} is simply written as {@{$$\mathbf {a} =(2,3).$$}@} {@{The notion that the tail of the vector coincides with the origin}@} is {@{implicit and easily understood}@}. Thus, {@{the more explicit notation ${\overrightarrow {OA} }$}@} is {@{usually deemed not necessary \(and is indeed rarely used\)}@}. In {@{_three dimensional_ Euclidean space \(or __R__<sup>3</sup>\)}@}, vectors are {@{identified with triples of scalar components}@}: {@{$$\mathbf {a} =(a_{1},a_{2},a_{3}).$$ also written, $$\mathbf {a} =(a_{x},a_{y},a_{z}).$$}@} This can be {@{generalised to _n-dimensional_ Euclidean space \(or __R__<sup>_n_</sup>\)}@}. {@{$$\mathbf {a} =(a_{1},a_{2},a_{3},\cdots ,a_{n-1},a_{n}).$$}@} These numbers are often {@{arranged into a [column vector](column%20vector.md) or [row vector](row%20vector.md)}@}, particularly when {@{dealing with [matrices](matrix%20(mathematics).md)}@}, as follows: {@{$$\mathbf {a} ={\begin{bmatrix}a_{1}\\a_{2}\\a_{3}\\\end{bmatrix} }=[a_{1}\ a_{2}\ a_{3}]^{\operatorname {T} }.$$}@} Another way to represent a vector in _n_-dimensions is to {@{introduce the [standard basis](standard%20basis.md) vectors}@}. For instance, in three dimensions, there are {@{three of them: $${\mathbf {e} }_{1}=(1,0,0),\ {\mathbf {e} }_{2}=(0,1,0),\ {\mathbf {e} }_{3}=(0,0,1).$$}@} These have the intuitive interpretation as {@{vectors of unit length pointing up the _x_-, _y_-, and _z_-axis of a [Cartesian coordinate system](Cartesian%20coordinate%20system.md), respectively}@}. In terms of these, {@{any vector __a__ in __R__<sup>3</sup> can be expressed in the form}@}: {@{$$\mathbf {a} =(a_{1},a_{2},a_{3})=a_{1}(1,0,0)+a_{2}(0,1,0)+a_{3}(0,0,1),\ {}$$ or $$\mathbf {a} =\mathbf {a} _{1}+\mathbf {a} _{2}+\mathbf {a} _{3}=a_{1}{\mathbf {e} }_{1}+a_{2}{\mathbf {e} }_{2}+a_{3}{\mathbf {e} }_{3},$$}@} where {@{__a__<sub>1</sub>, __a__<sub>2</sub>, __a__<sub>3</sub>}@} are called {@{the __[vector components](vector%20component.md#decomposition)__ \(or __vector projections__\) of __a__ on the basis vectors}@} or, equivalently, on {@{the corresponding Cartesian axes _x_, _y_, and _z_}@} \(see figure\), while {@{_a_<sub>1</sub>, _a_<sub>2</sub>, _a_<sub>3</sub> are the respective [scalar components](scalar%20component.md) \(or scalar projections\)}@}. <!--SR:!2026-05-09,350,352!2026-06-19,390,359!2026-06-16,387,359!2026-05-20,361,359!2026-04-21,332,352!2026-05-07,348,352!2026-05-14,355,352!2026-01-07,252,332!2026-02-18,286,332!2026-03-14,299,332!2026-02-08,278,332!2026-05-10,354,352!2026-03-15,300,332!2026-02-20,288,332!2025-12-22,240,332!2026-05-12,353,352!2026-05-13,354,352!2026-06-19,389,359!2026-03-03,283,332!2026-01-07,252,332!2026-05-09,350,352!2026-03-05,290,332!2026-01-13,258,332!2026-05-04,350,352-->

In {@{introductory physics textbooks}@}, {@{the standard basis vectors}@} are often {@{denoted $\mathbf {i} ,\mathbf {j} ,\mathbf {k}$ instead}@} \(or {@{$\mathbf {\hat {x} } ,\mathbf {\hat {y} } ,\mathbf {\hat {z} }$}@}, in which {@{the [hat symbol](hat%20symbol.md) $\mathbf {\hat {} }$ typically denotes [unit vectors](unit%20vector.md)}@}\). In this case, {@{the scalar and vector components}@} are denoted {@{respectively _a<sub>x</sub>_, _a<sub>y</sub>_, _a<sub>z</sub>_, and __a__<sub>_x_</sub>, __a__<sub>_y_</sub>, __a__<sub>_z_</sub>}@} \(note the difference in boldface\). Thus, {@{$$\mathbf {a} =\mathbf {a} _{x}+\mathbf {a} _{y}+\mathbf {a} _{z}=a_{x}{\mathbf {i} }+a_{y}{\mathbf {j} }+a_{z}{\mathbf {k} }.$$}@} {@{The notation __e__<sub>_i_</sub>}@} is compatible with {@{the [index notation](index%20notation.md) and the [summation convention](summation%20convention.md) commonly used in higher level mathematics, physics, and engineering}@}. <!--SR:!2026-05-14,355,352!2026-02-12,280,332!2026-05-07,349,352!2026-01-11,256,332!2026-02-12,282,332!2026-05-09,350,352!2026-05-07,348,352!2025-12-23,241,332!2026-05-11,355,352!2026-04-30,346,352-->

### decomposition or resolution

- Further information: ::@:: [Basis \(linear algebra\)](basis%20(linear%20algebra).md) <!--SR:!2026-03-07,292,332!2026-03-19,299,332-->

As {@{explained [above](#representations)}@}, a vector is often {@{described by a set of vector components that [add up](#addition%20and%20subtraction) to form the given vector}@}. Typically, these components are {@{the [projections](vector%20projection.md) of the vector on a set of mutually perpendicular reference axes \(basis vectors\)}@}. The vector is said to be {@{_decomposed_ or _resolved with respect to_ that set}@}. <!--SR:!2026-06-18,389,359!2026-01-11,256,332!2026-02-28,280,339!2026-03-15,300,332-->

> {@{![Illustration of tangential and normal components of a vector to a surface.](../../archives/Wikimedia%20Commons/Surface%20normal%20tangent.svg)}@}
>
> Illustration of {@{tangential and normal components of a vector to a surface}@}. <!--SR:!2026-05-09,350,352!2026-02-01,271,332-->

{@{The decomposition or resolution<sup>[\[16\]](#^ref-16)</sup> of a vector into components}@} is {@{not unique}@}, because {@{it depends on the choice of the axes on which the vector is projected}@}. <!--SR:!2026-05-22,363,359!2026-02-14,282,332!2026-03-11,296,332-->

Moreover, the use of {@{Cartesian unit vectors such as $\mathbf {\hat {x} } ,\mathbf {\hat {y} } ,\mathbf {\hat {z} }$}@} as {@{a [basis](basis%20(linear%20algebra).md) in which to represent a vector}@} is {@{not mandated}@}. Vectors can also be {@{expressed in terms of an arbitrary basis}@}, including {@{the unit vectors of a [cylindrical coordinate system](cylindrical%20coordinate%20system.md) \(${\boldsymbol {\hat {\rho } } },{\boldsymbol {\hat {\phi } } },\mathbf {\hat {z} }$\)}@} or {@{[spherical coordinate system](spherical%20coordinate%20system.md) \($\mathbf {\hat {r} } ,{\boldsymbol {\hat {\theta } } },{\boldsymbol {\hat {\phi } } }$\)}@}. {@{The latter two choices}@} are {@{more convenient for solving problems which possess cylindrical or spherical symmetry, respectively}@}. <!--SR:!2026-02-08,277,332!2026-02-07,277,332!2026-03-06,291,332!2026-02-08,277,332!2026-06-06,378,359!2026-05-16,358,359!2026-05-09,350,352!2026-01-28,252,332-->

{@{The choice of a basis}@} does not {@{affect the properties of a vector or its behaviour under transformations}@}. <!--SR:!2025-12-28,246,332!2026-05-19,360,359-->

A vector can also be {@{broken up with respect to "non-fixed" basis vectors}@} that {@{change their [orientation](orientation%20(geometry).md) as a function of time or space}@}. For example, {@{a vector in three-dimensional space}@} can be {@{decomposed with respect to two axes, respectively _normal_, and _tangent_ to a surface}@} \(see figure\). Moreover, {@{the _radial_ and _[tangential components](tangential%20component.md)_ of a vector}@} relate to {@{the _[radius](radius.md) of [rotation](rotation.md)_ of an object}@}. The former is {@{[parallel](parallel%20(geometry).md) to the radius}@} and {@{the latter is [orthogonal](perpendicular.md) to it}@}.<sup>[\[17\]](#^ref-17)</sup> <!--SR:!2026-03-06,291,332!2026-05-10,354,352!2026-05-08,349,352!2026-02-11,281,332!2026-01-16,261,332!2026-04-24,335,352!2025-10-26,195,312!2026-05-15,356,359-->

In these cases, {@{each of the components}@} may be {@{in turn decomposed with respect to a fixed coordinate system or basis set}@} \(e.g., {@{a _global_ coordinate system, or [inertial reference frame](inertial%20reference%20frame.md)}@}\). <!--SR:!2026-04-24,336,352!2026-06-19,390,359!2026-03-18,298,332-->

## properties and operations

- See also: ::@:: [Vector notation § Operations](vector%20notation.md#operations) <!--SR:!2026-06-07,378,359!2026-05-09,350,352-->

The following section uses {@{the [Cartesian coordinate system](Cartesian%20coordinate%20system.md) with basis vectors $${\mathbf {e} }_{1}=(1,0,0),\ {\mathbf {e} }_{2}=(0,1,0),\ {\mathbf {e} }_{3}=(0,0,1)$$}@} and assumes that {@{all vectors have the origin as a common base point}@}. A vector __a__ will be written as {@{$${\mathbf {a} }=a_{1}{\mathbf {e} }_{1}+a_{2}{\mathbf {e} }_{2}+a_{3}{\mathbf {e} }_{3}.$$}@} <!--SR:!2026-05-26,367,359!2026-05-17,361,359!2026-04-25,336,352-->

### equality

{@{Two vectors are said to be equal}@} if {@{they have the same magnitude and direction}@}. Equivalently {@{they will be equal if their coordinates are equal}@}. So {@{two vectors $${\mathbf {a} }=a_{1}{\mathbf {e} }_{1}+a_{2}{\mathbf {e} }_{2}+a_{3}{\mathbf {e} }_{3}$$ and $${\mathbf {b} }=b_{1}{\mathbf {e} }_{1}+b_{2}{\mathbf {e} }_{2}+b_{3}{\mathbf {e} }_{3}$$ are equal}@} if {@{$$a_{1}=b_{1},\quad a_{2}=b_{2},\quad a_{3}=b_{3}.\,$$}@} <!--SR:!2026-05-11,355,352!2026-03-02,287,332!2026-02-17,285,332!2026-05-02,348,352!2026-01-15,260,332-->

### opposite, parallel, and antiparallel vectors

{@{Two vectors are _opposite_}@} if {@{they have the same magnitude but [opposite direction](opposite%20direction%20(geometry).md)}@};<sup>[\[18\]](#^ref-18)</sup> so {@{two vectors $${\mathbf {a} }=a_{1}{\mathbf {e} }_{1}+a_{2}{\mathbf {e} }_{2}+a_{3}{\mathbf {e} }_{3}$$ and $${\mathbf {b} }=b_{1}{\mathbf {e} }_{1}+b_{2}{\mathbf {e} }_{2}+b_{3}{\mathbf {e} }_{3}$$ are opposite}@} if {@{$$a_{1}=-b_{1},\quad a_{2}=-b_{2},\quad a_{3}=-b_{3}.\,$$}@} <!--SR:!2026-05-28,369,359!2026-04-29,345,352!2026-05-31,372,359!2026-01-14,259,332-->

{@{Two vectors are _[equidirectional](equidirectional.md)_ \(or _codirectional_\)}@} if {@{they have the same direction but not necessarily the same magnitude}@}.<sup>[\[18\]](#^ref-18)</sup> {@{Two vectors are _parallel_}@} if {@{they have either the same or opposite direction, but not necessarily the same magnitude}@}; {@{two vectors are _antiparallel_}@} if {@{they have strictly opposite direction, but not necessarily the same magnitude}@}.<sup>[\[a\]](#^ref-a)</sup> <!--SR:!2026-02-08,277,332!2026-02-04,277,332!2026-03-20,300,332!2026-01-10,255,332!2026-05-14,355,352!2026-07-30,402,312-->

### addition and subtraction

- Further information: [Vector space](vector%20space.md)

{@{The sum of __a__ and __b__ of two vectors}@} may be {@{defined as $$\mathbf {a} +\mathbf {b} =(a_{1}+b_{1})\mathbf {e} _{1}+(a_{2}+b_{2})\mathbf {e} _{2}+(a_{3}+b_{3})\mathbf {e} _{3}.$$}@} The resulting vector is sometimes called {@{the __resultant vector__ of __a__ and __b__}@}. <!--SR:!2026-05-04,350,352!2026-04-10,321,352!2026-03-15,296,332-->

{@{The addition may be represented graphically}@} by {@{placing the tail of the arrow __b__ at the head of the arrow __a__}@}, and then {@{drawing an arrow from the tail of __a__ to the head of __b__}@}. {@{The new arrow drawn}@} represents {@{the vector __a__ + __b__}@}, as illustrated below:<sup>[\[7\]](#^ref-7)</sup> <p> &emsp; {@{![The addition of two vectors a and b](../../archives/Wikimedia%20Commons/Vector%20addition.svg)}@} <p> This addition method is sometimes called {@{the _parallelogram rule_}@} because {@{__a__ and __b__ form the sides of a [parallelogram](parallelogram.md) and __a__ + __b__ is one of the diagonals}@}. If {@{__a__ and __b__ are bound vectors that have the same base point}@}, this point will {@{also be the base point of __a__ + __b__}@}. One can check geometrically that {@{__a__ + __b__ = __b__ + __a__ and \(__a__ + __b__\) + __c__ = __a__ + \(__b__ + __c__\)}@}. <!--SR:!2026-01-13,258,332!2026-05-14,355,352!2026-02-11,281,332!2026-05-14,355,352!2026-01-13,258,332!2026-04-20,336,352!2026-05-14,355,352!2026-03-10,295,332!2026-05-01,347,352!2026-03-10,295,332!2026-04-24,340,352-->

{@{The difference of __a__ and __b__}@} is {@{$$\mathbf {a} -\mathbf {b} =(a_{1}-b_{1})\mathbf {e} _{1}+(a_{2}-b_{2})\mathbf {e} _{2}+(a_{3}-b_{3})\mathbf {e} _{3}.$$}@} Subtraction of two vectors can be {@{geometrically illustrated as follows}@}: to {@{subtract __b__ from __a__}@}, {@{place the tails of __a__ and __b__ at the same point}@}, and then {@{draw an arrow from the head of __b__ to the head of __a__}@}. This new arrow represents {@{the vector __\(-b\)__ + __a__, with __\(-b\)__ being the opposite of __b__}@}, see drawing. And {@{__\(-b\)__ + __a__ = __a__ − __b__}@}. <p> &emsp; {@{![The subtraction of two vectors a and b](../../archives/Wikimedia%20Commons/Vector%20subtraction.svg)}@} <!--SR:!2026-03-11,296,332!2026-05-03,349,352!2026-02-17,285,332!2026-03-12,292,332!2026-05-24,365,359!2026-05-23,364,359!2026-04-20,336,352!2026-05-01,347,352!2026-03-17,297,332-->

### scalar multiplication

- Main article: [Scalar multiplication](scalar%20multiplication.md)

> {@{![Scalar multiplication of a vector by a factor of 3 stretches the vector out.](../../archives/Wikimedia%20Commons/Scalar%20multiplication%20by%20r=3.svg)}@}
>
> {@{Scalar multiplication of a vector by a factor of 3}@} {@{stretches the vector out}@}. <!--SR:!2026-05-24,368,359!2026-02-13,281,332!2026-05-17,358,359-->

A vector may also be {@{multiplied, or re-_scaled_, by any [real number](real%20number.md) _r_}@}. In {@{the context of [conventional vector algebra](vector%20analysis.md)}@}, these real numbers are often called {@{__scalars__ \(from _scale_\) to distinguish them from vectors}@}. {@{The operation of multiplying a vector by a scalar}@} is called {@{_scalar multiplication_}@}. The resulting vector is {@{$$r\mathbf {a} =(ra_{1})\mathbf {e} _{1}+(ra_{2})\mathbf {e} _{2}+(ra_{3})\mathbf {e} _{3}.$$}@} Intuitively, {@{multiplying by a scalar _r_ stretches a vector out by a factor of _r_}@}. Geometrically, this can be visualized \(at least in {@{the case when _r_ is an integer}@}\) as {@{placing _r_ copies of the vector in a line where the endpoint of one vector is the initial point of the next vector}@}. <!--SR:!2026-05-03,349,352!2026-05-27,369,359!2026-03-10,295,332!2026-06-14,385,359!2026-03-14,299,332!2026-03-07,287,332!2025-12-29,247,332!2026-06-10,381,359!2026-03-01,286,332-->

If {@{_r_ is negative}@}, then {@{the vector changes direction: it flips around by an angle of 180°}@}. Two examples \(_r_ = −1 and _r_ = 2\) are given below: <!--SR:!2026-06-13,383,359!2026-01-08,253,332-->

> {@{![The scalar multiplications −<!-- markdown separator -->__a__ and 2<!-- markdown separator -->__a__ of a vector __a__](../../archives/Wikimedia%20Commons/Scalar%20multiplication%20of%20vectors2.svg)}@}
>
> {@{The scalar multiplications −<!-- markdown separator -->__a__ and 2<!-- markdown separator -->__a__ of a vector __a__}@} <!--SR:!2026-01-14,259,332!2026-05-02,348,352-->

Scalar multiplication is {@{[distributive](distributivity.md) over vector addition}@} in the following sense: {@{_r_\(__a__ + __b__\) = _r_<!-- markdown separator -->__a__+ _r_<!-- markdown separator -->__b__ for all vectors __a__ and __b__ and all scalars _r_}@}. One can also show that {@{__a__ − __b__ = __a__ + \(−1\)__b__}@}. <!--SR:!2026-01-15,260,332!2026-05-09,355,352!2026-01-18,263,332-->

### length

{@{The _[length](length.md)_, _[magnitude](magnitude%20(mathematics).md)_ or _[norm](norm%20(mathematics).md)_ of the vector __a__}@} is denoted by {@{‖<!-- markdown separator -->__a__<!-- markdown separator -->‖}@} or, {@{less commonly, \|__a__\|}@}, which is {@{not to be confused with the [absolute value](absolute%20value.md) \(a scalar "norm"\)}@}. <!--SR:!2026-06-07,379,359!2026-06-15,386,359!2026-05-15,356,359!2026-01-13,258,332-->

The length of the vector __a__ can be computed with {@{the _[Euclidean norm](Euclidean%20norm.md#Euclidean%20norm)_}@}, {@{$$\left\|\mathbf {a} \right\|={\sqrt {a_{1}^{2}+a_{2}^{2}+a_{3}^{2} } },$$}@} which is {@{a consequence of the [Pythagorean theorem](Pythagorean%20theorem.md)}@} since {@{the basis vectors __e__<sub>1</sub>, __e__<sub>2</sub>, __e__<sub>3</sub> are orthogonal unit vectors}@}. <!--SR:!2026-06-16,387,359!2026-01-30,273,332!2026-01-15,260,332!2026-03-15,300,332-->

This happens to be equal to {@{the square root of the [dot product](dot%20product.md), discussed below, of the vector with itself}@}: {@{$$\left\|\mathbf {a} \right\|={\sqrt {\mathbf {a} \cdot \mathbf {a} } }.$$}@} <!--SR:!2026-05-07,353,352!2026-06-19,390,359-->

#### unit vector

> {@{![The normalization of a vector __a__ into a unit vector __â__](../../archives/Wikimedia%20Commons/Vector%20normalization.svg)}@}
>
> {@{The normalization of a vector __a__ into a unit vector __â__}@} <!--SR:!2026-01-28,271,332!2026-02-09,279,332-->

- Main article: [Unit vector](unit%20vector.md)

{@{A _unit vector_}@} is {@{any vector with a length of one}@}; normally unit vectors are used {@{simply to indicate direction}@}. {@{A vector of arbitrary length}@} can be {@{divided by its length to create a unit vector}@}.<sup>[\[14\]](#^ref-14)</sup> This is known as {@{_normalizing_ a vector}@}. A unit vector is often indicated with {@{a hat as in __â__}@}. <!--SR:!2026-01-16,261,332!2026-06-13,384,359!2026-05-10,354,352!2026-06-14,385,359!2026-04-30,346,352!2026-02-12,282,332!2026-01-16,261,332-->

To {@{normalize a vector __a__ = \(_a_<sub>1</sub>, _a_<sub>2</sub>, _a_<sub>3</sub>\)}@}, {@{scale the vector by the reciprocal of its length ‖<!-- markdown separator -->__a__<!-- markdown separator -->‖}@}. That is: {@{$$\mathbf {\hat {a} } ={\frac {\mathbf {a} }{\left\|\mathbf {a} \right\|} }={\frac {a_{1} }{\left\|\mathbf {a} \right\|} }\mathbf {e} _{1}+{\frac {a_{2} }{\left\|\mathbf {a} \right\|} }\mathbf {e} _{2}+{\frac {a_{3} }{\left\|\mathbf {a} \right\|} }\mathbf {e} _{3}$$}@} <!--SR:!2026-03-16,296,332!2026-06-17,388,359!2026-06-12,384,359-->

#### zero vector

- Main article: [Zero vector](zero%20vector.md#additive%20identities)

{@{The _zero vector_}@} is {@{the vector with length zero}@}. Written out in coordinates, the vector is {@{\(0, 0, 0\)}@}, and it is commonly denoted {@{${\vec {0} }$, __0__, or simply 0}@}. Unlike {@{any other vector}@}, it has {@{an arbitrary or indeterminate direction, and cannot be normalized}@} \(that is, there is {@{no unit vector that is a multiple of the zero vector}@}\). {@{The sum of the zero vector with any vector __a__ is __a__}@} \(that is, {@{__0__ + __a__ = __a__}@}\). <!--SR:!2026-03-14,299,332!2026-05-06,352,352!2026-02-09,278,332!2026-01-14,259,332!2026-05-19,363,359!2026-03-10,295,332!2026-03-15,295,332!2026-05-26,367,359!2026-06-01,373,359-->

### dot product

- Main article: [Dot product](dot%20product.md)

{@{The _dot product_ of two vectors __a__ and __b__}@} \(sometimes called {@{the _[inner product](inner%20product%20space.md)_}@}, or, since {@{its result is a scalar, the _scalar product_}@}\) is denoted by {@{__a__ ∙ __b,__}@} and is defined as: {@{$$\mathbf {a} \cdot \mathbf {b} =\left\|\mathbf {a} \right\|\left\|\mathbf {b} \right\|\cos \theta ,$$}@} where {@{_θ_ is the measure of the [angle](angle.md) between __a__ and __b__}@} \(see {@{[trigonometric function](trigonometric%20function.md) for an explanation of cosine}@}\). Geometrically, this means that {@{__a__ and __b__ are drawn with a common start point}@}, and then {@{the length of __a__ is multiplied with the length of the component of __b__ that points in the same direction as __a__}@}. <!--SR:!2026-04-23,334,352!2026-02-13,282,332!2026-05-25,366,359!2026-05-25,366,359!2026-06-04,376,359!2026-06-16,387,359!2026-06-17,388,359!2026-05-13,354,352!2026-03-03,288,332-->

The dot product can also be defined as {@{the sum of the products of the components of each vector}@} as {@{$$\mathbf {a} \cdot \mathbf {b} =a_{1}b_{1}+a_{2}b_{2}+a_{3}b_{3}.$$}@} <!--SR:!2026-06-04,376,359!2026-06-08,379,359-->

### cross product

- Main article: [Cross product](cross%20product.md)

{@{The _cross product_ \(also called the _vector product_ or _outer product_\)}@} is {@{only meaningful in three or [seven](seven-dimensional%20cross%20product.md) dimensions}@}. The cross product differs from the dot product primarily in that {@{the result of the cross product of two vectors is a vector}@}. The cross product, denoted {@{__a__ × __b__}@}, is {@{a vector perpendicular to both __a__ and __b__}@} and is defined as {@{$$\mathbf {a} \times \mathbf {b} =\left\|\mathbf {a} \right\|\left\|\mathbf {b} \right\|\sin(\theta )\,\mathbf {n}$$}@} where {@{_θ_ is the measure of the angle between __a__ and __b__}@}, and {@{__n__ is a unit vector [perpendicular](perpendicular.md) to both __a__ and __b__ which completes a [right-handed](right-hand%20rule.md) system}@}. {@{The right-handedness constraint is necessary}@} because {@{there exist _two_ unit vectors that are perpendicular to both __a__ and __b__}@}, namely, {@{__n__ and \(−<!-- markdown separator -->__n__\)}@}. <!--SR:!2026-01-25,269,332!2026-02-04,277,332!2026-02-12,281,332!2026-02-08,277,332!2026-06-05,377,359!2026-06-11,382,359!2026-02-18,286,332!2026-05-03,349,352!2026-01-26,269,332!2026-05-09,350,352!2026-01-12,257,332-->

> {@{![An illustration of the cross product](../../archives/Wikimedia%20Commons/Cross%20product%20vector.svg)}@}
>
> An illustration of {@{the cross product}@} <!--SR:!2026-02-15,283,332!2026-03-06,291,332-->

The cross product __a__ × __b__ is defined so that {@{__a__, __b__, and __a__ × __b__ also becomes a right-handed system}@} \(although {@{__a__ and __b__ are not necessarily [orthogonal](orthogonal.md)}@}\). This is {@{the [right-hand rule](right-hand%20rule.md)}@}. <!--SR:!2025-11-17,198,312!2026-06-17,388,359!2026-05-06,347,352-->

{@{The length of __a__ × __b__}@} can be interpreted as {@{the area of the parallelogram having __a__ and __b__ as sides}@}. <!--SR:!2026-05-01,347,352!2026-06-17,388,359-->

The cross product can be written as {@{$${\mathbf {a} }\times {\mathbf {b} }=(a_{2}b_{3}-a_{3}b_{2}){\mathbf {e} }_{1}+(a_{3}b_{1}-a_{1}b_{3}){\mathbf {e} }_{2}+(a_{1}b_{2}-a_{2}b_{1}){\mathbf {e} }_{3}.$$}@} <!--SR:!2025-09-04,154,319-->

For {@{arbitrary choices of spatial orientation \(that is, allowing for left-handed as well as right-handed coordinate systems\)}@} the cross product of two vectors is {@{a [pseudovector](pseudovector.md) instead of a vector \(see below\)}@}. <!--SR:!2026-02-04,277,332!2026-03-19,299,332-->

### scalar triple product

- Main article: [Scalar triple product](triple%20product.md#scalar%20triple%20product)

{@{The _scalar triple product_ \(also called the _box product_ or _mixed triple product_\)}@} is {@{not really a new operator}@}, but {@{a way of applying the other two multiplication operators to three vectors}@}. The scalar triple product is sometimes denoted by {@{\(__a__ __b__ __c__\)}@} and defined as: {@{$$(\mathbf {a} \ \mathbf {b} \ \mathbf {c} )=\mathbf {a} \cdot (\mathbf {b} \times \mathbf {c} ).$$}@} <!--SR:!2026-02-11,280,332!2026-05-03,349,352!2026-02-11,280,332!2026-05-28,370,359!2026-05-06,347,352-->

It has {@{three primary uses}@}. First, {@{the absolute value of the box product}@} is {@{the volume of the [parallelepiped](parallelepiped.md) which has edges that are defined by the three vectors}@}. Second, the scalar triple product is {@{zero if and only if the three vectors are [linearly dependent](linear%20independence.md)}@}, which can be easily proved by {@{considering that in order for the three vectors to not make a volume, they must all lie in the same plane}@}. Third, the box product is {@{positive if and only if the three vectors __a__, __b__ and __c__ are right-handed}@}. <!--SR:!2026-05-09,350,352!2026-02-12,281,332!2026-05-15,357,359!2026-02-05,278,332!2026-06-17,387,359!2026-04-09,325,352-->

In {@{components \(_with respect to a right-handed orthonormal basis_\)}@}, if {@{the three vectors are thought of as rows \(or columns, but in the same order\)}@}, the scalar triple product is {@{simply the [determinant](determinant.md) of the 3-by-3 [matrix](matrix%20(mathematics).md) having the three vectors as rows}@} {@{$$(\mathbf {a} \ \mathbf {b} \ \mathbf {c} )={\begin{vmatrix}a_{1}&a_{2}&a_{3}\\b_{1}&b_{2}&b_{3}\\c_{1}&c_{2}&c_{3}\\\end{vmatrix} }$$}@} <!--SR:!2026-03-11,296,332!2026-02-19,287,332!2026-06-03,374,359!2025-11-08,208,339-->

The scalar triple product is {@{linear in all three entries and anti-symmetric}@} in the following sense: {@{$$(\mathbf {a} \ \mathbf {b} \ \mathbf {c} )=(\mathbf {c} \ \mathbf {a} \ \mathbf {b} )=(\mathbf {b} \ \mathbf {c} \ \mathbf {a} )=-(\mathbf {a} \ \mathbf {c} \ \mathbf {b} )=-(\mathbf {b} \ \mathbf {a} \ \mathbf {c} )=-(\mathbf {c} \ \mathbf {b} \ \mathbf {a} ).$$}@} <!--SR:!2026-05-29,370,359!2026-05-06,347,352-->

### conversion between multiple Cartesian bases

All examples thus far have {@{dealt with vectors expressed in terms of the same basis}@}, namely, {@{the _e_ basis {__e__<sub>1</sub>, __e__<sub>2</sub>, __e__<sub>3</sub>}<!-- markdown separator -->}@}. However, a vector can be {@{expressed in terms of any number of different bases that are not necessarily aligned with each other}@}, and {@{still remain the same vector}@}. In the _e_ basis, {@{a vector __a__ is expressed}@}, by definition, as {@{$$\mathbf {a} =p\mathbf {e} _{1}+q\mathbf {e} _{2}+r\mathbf {e} _{3}.$$}@} {@{The scalar components in the _e_ basis}@} are, by definition, {@{$${\begin{aligned}p&=\mathbf {a} \cdot \mathbf {e} _{1},\\q&=\mathbf {a} \cdot \mathbf {e} _{2},\\r&=\mathbf {a} \cdot \mathbf {e} _{3}.\end{aligned} }$$}@} In {@{another orthonormal basis _n_ = {__n__<sub>1</sub>, __n__<sub>2</sub>, __n__<sub>3</sub>} that is not necessarily aligned with _e_}@}, the vector __a__ is expressed as {@{$$\mathbf {a} =u\mathbf {n} _{1}+v\mathbf {n} _{2}+w\mathbf {n} _{3}$$}@} and {@{the scalar components in the _n_ basis}@} are, by definition, {@{$${\begin{aligned}u&=\mathbf {a} \cdot \mathbf {n} _{1},\\v&=\mathbf {a} \cdot \mathbf {n} _{2},\\w&=\mathbf {a} \cdot \mathbf {n} _{3}.\end{aligned} }$$}@} {@{The values of _p_, _q_, _r_, and _u_, _v_, _w_ relate to the unit vectors}@} in such a way that {@{the resulting vector sum is exactly the same physical vector __a__ in both cases}@}. It is common to {@{encounter vectors known in terms of different bases}@} \(for example, {@{one basis fixed to the Earth and a second basis fixed to a moving vehicle}@}\). In such a case it is {@{necessary to develop a method to convert between bases}@} so {@{the basic vector operations such as addition and subtraction can be performed}@}. One way to {@{express _u_, _v_, _w_ in terms of _p_, _q_, _r_}@} is to {@{use column matrices along with a [direction cosine matrix](direction%20cosine%20matrix.md#formalism%20alternatives) containing the information that relates the two bases}@}. Such an expression can be {@{formed by substitution of the above equations}@} to form {@{$${\begin{aligned}u&=(p\mathbf {e} _{1}+q\mathbf {e} _{2}+r\mathbf {e} _{3})\cdot \mathbf {n} _{1},\\v&=(p\mathbf {e} _{1}+q\mathbf {e} _{2}+r\mathbf {e} _{3})\cdot \mathbf {n} _{2},\\w&=(p\mathbf {e} _{1}+q\mathbf {e} _{2}+r\mathbf {e} _{3})\cdot \mathbf {n} _{3}.\end{aligned} }$$}@} {@{Distributing the dot-multiplication}@} gives {@{$${\begin{aligned}u&=p\mathbf {e} _{1}\cdot \mathbf {n} _{1}+q\mathbf {e} _{2}\cdot \mathbf {n} _{1}+r\mathbf {e} _{3}\cdot \mathbf {n} _{1},\\v&=p\mathbf {e} _{1}\cdot \mathbf {n} _{2}+q\mathbf {e} _{2}\cdot \mathbf {n} _{2}+r\mathbf {e} _{3}\cdot \mathbf {n} _{2},\\w&=p\mathbf {e} _{1}\cdot \mathbf {n} _{3}+q\mathbf {e} _{2}\cdot \mathbf {n} _{3}+r\mathbf {e} _{3}\cdot \mathbf {n} _{3}.\end{aligned} }$$}@} {@{Replacing each dot product with a unique scalar}@} gives {@{$${\begin{aligned}u&=c_{11}p+c_{12}q+c_{13}r,\\v&=c_{21}p+c_{22}q+c_{23}r,\\w&=c_{31}p+c_{32}q+c_{33}r,\end{aligned} }$$}@} and {@{these equations can be expressed as the single matrix equation}@} {@{$${\begin{bmatrix}u\\v\\w\\\end{bmatrix} }={\begin{bmatrix}c_{11}&c_{12}&c_{13}\\c_{21}&c_{22}&c_{23}\\c_{31}&c_{32}&c_{33}\end{bmatrix} }{\begin{bmatrix}p\\q\\r\end{bmatrix} }.$$}@} This matrix equation {@{relates the scalar components of __a__ in the _n_ basis \(_u_,_v_, and _w_\) with those in the _e_ basis \(_p_, _q_, and _r_\)}@}. {@{Each matrix element _c_<sub>_jk_</sub>}@} is {@{the [direction cosine](direction%20cosine.md#Cartesian%20coordinates) relating __n__<sub>_j_</sub> to __e__<sub>_k_</sub>}@}.<sup>[\[19\]](#^ref-19)</sup> The term _direction cosine_ refers to {@{the [cosine](cosine.md) of the angle between two unit vectors}@}, which is {@{also equal to their [dot product](#dot%20product)}@}.<sup>[\[19\]](#^ref-19)</sup> Therefore, {@{$${\begin{aligned}c_{11}&=\mathbf {n} _{1}\cdot \mathbf {e} _{1}\\c_{12}&=\mathbf {n} _{1}\cdot \mathbf {e} _{2}\\c_{13}&=\mathbf {n} _{1}\cdot \mathbf {e} _{3}\\c_{21}&=\mathbf {n} _{2}\cdot \mathbf {e} _{1}\\c_{22}&=\mathbf {n} _{2}\cdot \mathbf {e} _{2}\\c_{23}&=\mathbf {n} _{2}\cdot \mathbf {e} _{3}\\c_{31}&=\mathbf {n} _{3}\cdot \mathbf {e} _{1}\\c_{32}&=\mathbf {n} _{3}\cdot \mathbf {e} _{2}\\c_{33}&=\mathbf {n} _{3}\cdot \mathbf {e} _{3}\end{aligned} }$$}@} By referring collectively to {@{__e__<sub>1</sub>, __e__<sub>2</sub>, __e__<sub>3</sub> as the _e_ basis and to __n__<sub>1</sub>, __n__<sub>2</sub>, __n__<sub>3</sub> as the _n_ basis}@}, {@{the matrix containing all the _c_<sub>_jk_</sub>}@} is known as {@{the "[transformation matrix](transformation%20matrix.md) from _e_ to _n_"}@}, or {@{the "[rotation matrix](rotation%20matrix.md) from _e_ to _n_" \(because it can be imagined as the "rotation" of a vector from one basis to another}@}\), or {@{the "direction cosine matrix from _e_ to _n_"<sup>[\[19\]](#^ref-19)</sup> \(because it contains direction cosines\)}@}. The properties of a rotation matrix are such that {@{its [inverse](matrix%20inverse.md) is equal to its [transpose](matrix%20transpose.md)}@}. This means that {@{the "rotation matrix from _e_ to _n_" is the transpose of "rotation matrix from _n_ to _e_"}@}. <!--SR:!2026-03-14,299,332!2025-12-27,245,332!2026-05-20,361,359!2026-02-14,282,332!2026-05-11,352,352!2026-01-09,254,332!2026-03-07,292,332!2026-02-10,280,332!2026-05-03,349,352!2026-05-11,355,352!2026-02-04,274,332!2026-05-11,352,352!2026-06-18,389,359!2026-05-13,354,352!2026-05-23,364,359!2025-10-20,177,312!2026-01-20,265,332!2026-03-16,296,332!2026-03-13,298,332!2026-05-08,349,352!2026-05-09,355,352!2025-09-26,167,312!2026-01-16,261,332!2026-05-27,368,359!2026-06-06,377,359!2027-06-16,656,339!2026-05-06,350,352!2026-05-14,355,352!2026-01-29,272,332!2027-03-15,583,339!2025-10-29,182,312!2026-05-20,361,359!2026-06-02,374,359!2026-06-02,374,359!2026-05-14,355,352!2026-05-13,354,352!2026-02-10,278,332!2026-05-05,351,352!2026-06-18,389,359!2026-05-07,348,352!2026-01-11,256,332-->

The properties of a direction cosine matrix, C are:<sup>[\[20\]](#^ref-20)</sup>

- (annotation: direction cosine matrix) the determinant ::@:: is unity, \|C\| = 1; <!--SR:!2026-06-18,389,359!2026-06-09,353,312-->
- (annotation: direction cosine matrix) the inverse ::@:: is equal to the transpose; <!--SR:!2026-06-15,386,359!2026-01-09,255,332-->
- (annotation: direction cosine matrix) the rows and columns ::@:: are orthogonal unit vectors, therefore their dot products are zero. <!--SR:!2026-06-19,390,359!2026-05-08,354,352-->

The advantage of this method is that {@{a direction cosine matrix can usually be obtained independently}@} by {@{using [Euler angles](Euler%20angles.md) or a [quaternion](quaternion.md) to relate the two vector bases}@}, so the basis conversions can be {@{performed directly, without having to work out all the dot products described above}@}. <!--SR:!2026-03-12,297,332!2026-06-09,381,359!2026-03-15,295,332-->

By {@{applying several matrix multiplications in succession}@}, {@{any vector can be expressed in any basis}@} so long as {@{the set of direction cosines is known relating the successive bases}@}.<sup>[\[19\]](#^ref-19)</sup> <!--SR:!2026-03-02,287,332!2026-01-11,257,332!2025-12-28,246,332-->

### other dimensions

With {@{the exception of the cross and triple products}@}, the above formulae {@{generalise to two dimensions and higher dimensions}@}. For example, addition {@{generalises to two dimensions}@} as {@{$$(a_{1}{\mathbf {e} }_{1}+a_{2}{\mathbf {e} }_{2})+(b_{1}{\mathbf {e} }_{1}+b_{2}{\mathbf {e} }_{2})=(a_{1}+b_{1}){\mathbf {e} }_{1}+(a_{2}+b_{2}){\mathbf {e} }_{2},$$}@} and in {@{four dimensions}@} as {@{$${\begin{aligned}(a_{1}{\mathbf {e} }_{1}+a_{2}{\mathbf {e} }_{2}+a_{3}{\mathbf {e} }_{3}+a_{4}{\mathbf {e} }_{4})&+(b_{1}{\mathbf {e} }_{1}+b_{2}{\mathbf {e} }_{2}+b_{3}{\mathbf {e} }_{3}+b_{4}{\mathbf {e} }_{4})=\\(a_{1}+b_{1}){\mathbf {e} }_{1}+(a_{2}+b_{2}){\mathbf {e} }_{2}&+(a_{3}+b_{3}){\mathbf {e} }_{3}+(a_{4}+b_{4}){\mathbf {e} }_{4}.\end{aligned} }$$}@} <!--SR:!2026-01-07,252,332!2026-05-05,346,352!2026-01-10,255,330!2026-02-10,279,332!2026-02-17,285,332!2026-06-12,382,359-->

{@{The cross product}@} {@{does not readily generalise to other dimensions}@}, though {@{the closely related [exterior product](exterior%20algebra.md#areas%20in%20the%20plane) does}@}, whose {@{result is a [bivector](bivector.md)}@}. In {@{two dimensions}@} this is {@{simply a [pseudoscalar](pseudoscalar.md) $$(a_{1}{\mathbf {e} }_{1}+a_{2}{\mathbf {e} }_{2})\wedge (b_{1}{\mathbf {e} }_{1}+b_{2}{\mathbf {e} }_{2})=(a_{1}b_{2}-a_{2}b_{1})\mathbf {e} _{1}\mathbf {e} _{2}.$$}@} {@{A [seven-dimensional cross product](seven-dimensional%20cross%20product.md)}@} is {@{similar to the cross product in that its result is a vector orthogonal to the two arguments}@}; there is however {@{no natural way of selecting one of the possible such products}@}. <!--SR:!2026-05-10,354,352!2026-05-31,372,359!2026-01-28,271,332!2026-04-30,346,352!2025-09-03,153,319!2027-02-16,537,312!2026-02-03,276,332!2026-06-18,388,359!2026-07-05,400,364-->

## physics

- Main article: ::@:: [Vector quantity](vector%20quantity.md) <!--SR:!2026-05-23,367,359!2026-01-15,260,332-->

Vectors have {@{many uses in physics and other sciences}@}. <!--SR:!2026-05-09,355,352-->

### length and units

In {@{abstract vector spaces}@}, {@{the length of the arrow}@} depends on {@{a [dimensionless](dimensionless%20number.md) [scale](scale%20(measurement).md)}@}. If it represents, for example, {@{a force}@}, the "scale" is {@{of [physical dimension](dimensional%20analysis.md) length/force}@}. Thus there is {@{typically consistency in scale among quantities of the same dimension}@}, but otherwise {@{scale ratios may vary}@}; for example, if {@{"1 newton" and "5 m" are both represented with an arrow of 2 cm}@}, the scales are {@{1 m:50 N and 1:250 respectively}@}. {@{Equal length of vectors of different dimension}@} has {@{no particular significance}@} unless {@{there is some [proportionality constant](proportionality%20constant.md#direct%20proportionality) inherent in the system that the diagram represents}@}. Also {@{length of a unit vector \(of dimension length, not length/force, etc.\)}@} has {@{no coordinate-system-invariant significance}@}. <!--SR:!2026-02-03,276,332!2026-01-29,272,332!2025-12-29,247,332!2026-02-13,282,332!2026-01-10,256,332!2026-02-09,279,332!2026-03-07,292,332!2026-05-08,350,352!2026-04-08,319,352!2026-05-11,355,352!2026-03-14,295,332!2026-02-08,278,332!2026-06-03,375,359!2026-06-12,383,359-->

### vector-valued functions

- Main article: [Vector-valued function](vector-valued%20function.md)

Often in {@{areas of physics and mathematics}@}, {@{a vector evolves in time}@}, meaning that {@{it depends on a time parameter _t_}@}. For instance, if {@{__r__ represents the position vector of a particle}@}, then {@{__r__\(_t_\) gives a [parametric](parametric%20equation.md) representation of the trajectory of the particle}@}. Vector-valued functions can be {@{[differentiated](derivative.md) and [integrated](integral.md)}@} by {@{differentiating or integrating the components of the vector}@}, and {@{many of the familiar rules from [calculus](calculus.md) continue to hold}@} for {@{the derivative and integral of vector-valued functions}@}. <!--SR:!2026-06-20,390,359!2026-02-07,277,332!2026-03-10,295,332!2026-03-12,295,332!2026-02-11,281,332!2026-06-18,389,359!2026-02-14,282,332!2026-01-08,253,332!2026-03-13,298,332-->

### position, velocity and acceleration

{@{The position of a point __x__ = \(_x_<sub>1</sub>, _x_<sub>2</sub>, _x_<sub>3</sub>\) in three-dimensional space}@} can be represented as {@{a [position vector](position%20vector.md) whose base point is the origin}@} {@{$${\mathbf {x} }=x_{1}{\mathbf {e} }_{1}+x_{2}{\mathbf {e} }_{2}+x_{3}{\mathbf {e} }_{3}.$$}@} The position vector has {@{dimensions of [length](length.md)}@}. <!--SR:!2026-05-12,353,352!2026-04-28,344,352!2026-05-05,351,352!2026-05-14,355,352-->

Given {@{two points __x__ = \(_x_<sub>1</sub>, _x_<sub>2</sub>, _x_<sub>3</sub>\), __y__ = \(_y_<sub>1</sub>, _y_<sub>2</sub>, _y_<sub>3</sub>\)}@} {@{their [displacement](displacement%20(vector).md)}@} is {@{a vector $${\mathbf {y} }-{\mathbf {x} }=(y_{1}-x_{1}){\mathbf {e} }_{1}+(y_{2}-x_{2}){\mathbf {e} }_{2}+(y_{3}-x_{3}){\mathbf {e} }_{3}.$$}@} which {@{specifies the position of _y_ relative to _x_}@}. {@{The length of this vector}@} gives {@{the straight-line distance from _x_ to _y_}@}. Displacement has {@{the dimensions of length}@}. <!--SR:!2026-03-04,289,332!2026-02-03,276,332!2026-05-28,369,359!2026-05-22,363,359!2026-06-19,390,359!2026-05-04,350,352!2026-03-07,292,332-->

{@{The [velocity](velocity.md) __v__ of a point or particle}@} is {@{a vector}@}, its length gives {@{the [speed](speed.md)}@}. For {@{constant velocity}@} {@{the position at time _t_}@} will be {@{$${\mathbf {x} }_{t}=t{\mathbf {v} }+{\mathbf {x} }_{0},$$}@} where {@{__x__<sub>0</sub> is the position at time _t_ = 0}@}. Velocity is {@{the [time derivative](#ordinary%20derivative) of position}@}. Its dimensions are {@{length/time}@}. <!--SR:!2026-03-08,288,332!2026-01-12,257,332!2026-05-21,362,359!2026-02-03,273,332!2026-05-13,355,352!2026-03-11,296,332!2026-01-24,268,332!2026-05-11,352,352!2026-04-29,345,352-->

{@{[Acceleration](acceleration.md) __a__ of a point}@} is {@{vector which is the [time derivative](#ordinary%20derivative) of velocity}@}. Its dimensions are {@{length/time<sup>2</sup>}@}. <!--SR:!2026-02-16,284,332!2026-06-08,380,359!2026-05-15,356,359-->

### force, energy, work

{@{[Force](force.md)}@} is {@{a vector with dimensions of mass×length/time<sup>2</sup> \(N m s <sup>−2</sup>\)}@} and {@{[Newton's second law](Newton's%20second%20law.md#second%20law)}@} is {@{the scalar multiplication $${\mathbf {F} }=m{\mathbf {a} }$$}@} <!--SR:!2026-02-03,276,332!2026-02-05,278,332!2026-01-13,258,332!2026-02-20,288,332-->

{@{Work}@} is {@{the dot product of [force](force.md) and [displacement](displacement%20(vector).md)}@} {@{$$W={\mathbf {F} }\cdot ({\mathbf {x} }_{2}-{\mathbf {x} }_{1}).$$}@} <!--SR:!2026-05-15,356,359!2026-02-03,276,332!2026-02-10,280,332-->

## vectors, pseudovectors, and transformations

<!-- | ![](../../archives/Wikimedia%20Commons/Ambox%20important.svg) | hide__This section has multiple issues.__ Please help __[improve it](https://en.wikipedia.org/wiki/Special:EditPage/Euclidean%20vector)__ or discuss these issues on the __[talk page](https://en.wikipedia.org/wiki/Talk:Euclidean%20vector)__. _\([Learn how and when to remove these messages](https://en.wikipedia.org/wiki/Help:Maintenance%20template%20removal)\)_ <br/> | This section __does not [cite](https://en.wikipedia.org/wiki/Wikipedia:Citing%20sources) any [sources](https://en.wikipedia.org/wiki/Wikipedia:Verifiability)__. _\(December 2021\)_ | <p>  <p> | This section __may be too technical for most readers to understand__. _\(December 2021\)_ | | -->

{@{An alternative characterization}@} of Euclidean vectors, especially in {@{physics}@}, describes them as {@{lists of quantities which behave in a certain way under a [coordinate transformation](coordinate%20system.md)}@}. {@{A _contravariant vector_}@} is required to {@{have components that "transform opposite to the basis" under changes of [basis](basis%20(linear%20algebra).md)}@}. The vector itself {@{does not change when the basis is transformed}@}; instead, {@{the components of the vector make a change that cancels the change in the basis}@}. In other words, if {@{the reference axes \(and the basis derived from it\) were rotated in one direction}@}, {@{the component representation of the vector}@} would {@{rotate in the opposite way to generate the same final vector}@}. Similarly, if {@{the reference axes were stretched in one direction}@}, {@{the components of the vector would reduce in an exactly compensating way}@}. Mathematically, if {@{the basis undergoes a transformation described by an [invertible matrix](invertible%20matrix.md) _M_}@}, so that {@{a coordinate vector __x__ is transformed to __x__<!-- markdown separator -->′ = _M_<!-- markdown separator -->__x__}@}, then {@{a contravariant vector __v__}@} must be {@{similarly transformed via __v__<!-- markdown separator -->′ = _M_<sup>−1</sup>__v__}@}. This important requirement is {@{what distinguishes a contravariant vector from any other triple of physically meaningful quantities}@}. For example, if {@{_v_ consists of the _x_, _y_, and _z_-components of [velocity](velocity.md)}@}, then {@{_v_ is a contravariant vector}@}: if {@{the coordinates of space are stretched, rotated, or twisted}@}, then {@{the components of the velocity transform in the <!-- same -->opposite way}@}. On the other hand, for instance, {@{a triple consisting of the length, width, and height of a rectangular box}@} could {@{make up the three components of an abstract [vector](vector%20space.md)}@}, but {@{this vector would not be contravariant}@}, since {@{rotating the box does not change the box's length, width, and height}@}. Examples of contravariant vectors include {@{[displacement](displacement%20(vector).md), [velocity](velocity.md), [electric field](electric%20field.md), [momentum](momentum.md), [force](force.md), and [acceleration](acceleration.md)}@}. <!--SR:!2026-06-02,373,359!2026-01-25,269,332!2026-03-10,295,332!2026-05-05,346,352!2026-05-14,355,352!2026-02-08,278,332!2026-05-24,365,359!2026-05-09,355,352!2026-03-10,295,332!2026-05-29,370,359!2026-03-12,297,332!2026-06-04,376,359!2026-06-10,382,359!2026-05-26,368,359!2026-03-11,296,332!2026-05-24,365,359!2026-06-13,384,359!2026-03-01,286,332!2026-03-14,299,332!2026-05-19,360,359!2025-12-23,241,332!2026-02-04,277,332!2026-03-12,297,332!2026-04-09,320,352!2026-05-07,351,352!2026-06-06,342,292-->

In {@{the language of [differential geometry](differential%20geometry.md)}@}, the requirement that {@{the components of a vector transform according to the same matrix of the coordinate transition}@} is equivalent to defining a _contravariant vector_ to be {@{a [tensor](tensor.md) of [contravariant](covariance%20and%20contravariance%20of%20vectors.md) rank one}@}. Alternatively, a contravariant vector is defined to be {@{a [tangent vector](tangent%20space.md)}@}, and {@{the rules for transforming a contravariant vector}@} {@{follow from the [chain rule](chain%20rule.md)}@}. <!--SR:!2026-02-20,288,332!2026-06-12,383,359!2026-03-10,295,332!2026-04-16,332,352!2026-04-30,346,352!2026-02-18,286,332-->

{@{Some vectors transform like contravariant vectors}@}, except that {@{when they are reflected through a mirror}@}, they {@{flip and gain a minus sign}@}. {@{A transformation that switches right-handedness to left-handedness and vice versa like a mirror does}@} is said to {@{change the _[orientation](orientation%20(space).md)_ of space}@}. {@{A vector which gains a minus sign when the orientation of space changes}@} is called {@{a _[pseudovector](pseudovector.md)_ or an _axial vector_}@}. {@{Ordinary vectors}@} are sometimes called {@{_true vectors_ or _polar vectors_}@} to {@{distinguish them from pseudovectors}@}. Pseudovectors occur most frequently as {@{the [cross product](cross%20product.md) of two ordinary vectors}@}. <!--SR:!2026-03-11,296,332!2026-02-15,283,332!2026-05-13,354,352!2026-03-07,292,332!2026-05-06,350,352!2026-03-14,294,332!2026-01-31,274,332!2026-02-19,287,332!2026-06-15,386,359!2026-03-11,296,332!2026-01-24,268,332-->

One example of a pseudovector is {@{[angular velocity](angular%20velocity.md)}@}. Driving in {@{a [car](car.md), and looking forward}@}, each of the [wheels](wheel.md) has {@{an angular velocity vector pointing to the left}@}. If {@{the world is reflected in a mirror which switches the left and right side of the car}@}, {@{the _reflection_ of this angular velocity vector points to the right}@}, but {@{the actual angular velocity vector of the wheel still points to the left}@}, corresponding to {@{the minus sign}@}. Other examples of pseudovectors include {@{[magnetic field](magnetic%20field.md), [torque](torque.md), or more generally any cross product of two \(true\) vectors}@}. <!--SR:!2026-01-11,256,332!2026-05-04,350,352!2026-05-09,350,352!2026-01-06,252,332!2026-06-19,390,359!2026-02-10,279,332!2026-05-30,371,359!2026-03-15,295,332-->

{@{This distinction between vectors and pseudovectors}@} is {@{often ignored}@}, but {@{it becomes important in studying [symmetry](symmetry.md) properties}@}. <!--SR:!2026-01-27,251,332!2026-05-03,347,352!2026-03-20,300,332-->

## see also

- [Affine space](affine%20space.md), ::@:: which distinguishes between vectors and [points](point%20(geometry).md) <!--SR:!2026-03-12,292,332!2026-05-11,355,352-->
- [Banach space](Banach%20space.md)
- [Clifford algebra](Clifford%20algebra.md)
- [Complex number](complex%20number.md)
- [Coordinate system](coordinate%20system.md)
- [Covariance and contravariance of vectors](covariance%20and%20contravariance%20of%20vectors.md)
- [Four-vector](four-vector.md), ::@:: a non-Euclidean vector in Minkowski space \(i.e. four-dimensional spacetime\), important in [relativity](theory%20of%20relativity.md) <!--SR:!2026-06-08,380,359!2026-05-08,352,352-->
- [Function space](function%20space.md)
- [Grassmann](Grassmann.md)'s _Ausdehnungslehre_
- [Hilbert space](Hilbert%20space.md)
- [Normal vector](normal%20vector.md)
- [Null vector](null%20vector.md)
- [Parity \(physics\)](parity%20(physics).md)
- [Position \(geometry\)](position%20(geometry).md)
- [Pseudovector](pseudovector.md)
- [Quaternion](quaternion.md)
- [Tangential and normal components](tangential%20and%20normal%20components.md) \(of a vector\)
- [Tensor](tensor.md)
- [Unit vector](unit%20vector.md)
- [Vector bundle](vector%20bundle.md)
- [Vector calculus](vector%20calculus.md)
- [Vector notation](vector%20notation.md)
- [Vector-valued function](vector-valued%20function.md)

## notes

1. a. "Can be brought to the same straight line by means of parallel displacement".<sup>[\[18\]](#^ref-18)</sup> <a id="^ref-a"></a>^ref-a

<!-- list separator -->

1. [Ivanov 2001](#CITEREFIvanov2001) <a id="^ref-1"></a>^ref-1
2. [Heinbockel 2001](#CITEREFHeinbockel2001) <a id="^ref-2"></a>^ref-2
3. [Itô 1993](#CITEREFIt%C3%B41993), p. 1678; [Pedoe 1988](#CITEREFPedoe1988) <a id="^ref-3"></a>^ref-3
4. Latin: vectus, [perfect participle](perfect%20participle.md) of vehere, "to carry"/ _veho_ = "I carry". For historical development of the word _vector_, see <a id="CITEREFReference-OED-vector n."></a> ["vector _n._"](https://www.oed.com/search/dictionary/?q=vector+%27%27n.%27%27). _[Oxford English Dictionary](Oxford%20English%20Dictionary.md)_ \(Online ed.\). [Oxford University Press](Oxford%20University%20Press.md). \(Subscription or [participating institution membership](https://www.oed.com/public/login/loggingin#withyourlibrary) required.\) and <a id="CITEREFJeff Miller"></a> Jeff Miller. ["Earliest Known Uses of Some of the Words of Mathematics"](http://jeff560.tripod.com/v.html). Retrieved 2007-05-25. <a id="^ref-4"></a>^ref-4
5. _The Oxford English Dictionary_ \(2nd. ed.\). London: Clarendon Press. 2001. [ISBN](ISBN%20(identifier).md) [9780195219425](https://en.wikipedia.org/wiki/Special:BookSources/9780195219425). <a id="^ref-5"></a>^ref-5
6. ["vector \| Definition & Facts"](https://www.britannica.com/science/vector-mathematics). _Encyclopedia Britannica_. Retrieved 2020-08-19. <a id="^ref-6"></a>^ref-6
7. ["Vectors"](https://www.mathsisfun.com/algebra/vectors.html). _<www.mathsisfun.com>_. Retrieved 2020-08-19. <a id="^ref-7"></a>^ref-7
8. <a id="CITEREFWeisstein"></a> Weisstein, Eric W. ["Vector"](https://mathworld.wolfram.com/Vector.html). _mathworld.wolfram.com_. Retrieved 2020-08-19. <a id="^ref-8"></a>^ref-8
9. [Michael J. Crowe](Michael%20J.%20Crowe.md), [A History of Vector Analysis](A%20History%20of%20Vector%20Analysis.md); see also his ["lecture notes"](https://web.archive.org/web/20040126161844/http://www.nku.edu/~curtin/crowe_oresme.pdf) \(PDF\). Archived from [the original](http://www.nku.edu/~curtin/crowe_oresme.pdf) \(PDF\) on January 26, 2004. Retrieved 2010-09-04. on the subject. <a id="^ref-9"></a>^ref-9
10. W. R. Hamilton \(1846\) _London, Edinburgh & Dublin Philosophical Magazine_ 3rd series 29 27 <a id="^ref-10"></a>^ref-10
11. [Itô 1993](#CITEREFIt%C3%B41993), p. 1678 <a id="^ref-11"></a>^ref-11
12. Formerly known as _located vector_. See [Lang 1986](#CITEREFLang1986), p. 9. <a id="^ref-12"></a>^ref-12
13. In some old texts, the pair \(_A_, _B_\) is called a _bound vector_, and its equivalence class is called a _free vector_. <a id="^ref-13"></a>^ref-13
14. ["1.1: Vectors"](https://math.libretexts.org/Bookshelves/Calculus/Supplemental_Modules_(Calculus)/Vector_Calculus/1%3A_Vector_Basics/1.1%3A_Vectors). _Mathematics LibreTexts_. 2013-11-07. Retrieved 2020-08-19. <a id="^ref-14"></a>^ref-14
15. [Thermodynamics and Differential Forms](http://www.av8n.com/physics/thermo-forms.htm) <a id="^ref-15"></a>^ref-15
16. [Gibbs, J.W.](Josiah%20Willard%20Gibbs.md) \(1901\). _Vector Analysis: A Text-book for the Use of Students of Mathematics and Physics, Founded upon the Lectures of J. Willard Gibbs_, by E.B. Wilson, Chares Scribner's Sons, New York, p. 15: "Any vector __r__ coplanar with two non-collinear vectors __a__ and __b__ may be resolved into two components parallel to __a__ and __b__ respectively. This resolution may be accomplished by constructing the parallelogram ..." <a id="^ref-16"></a>^ref-16
17. ["U. Guelph Physics Dept., "Torque and Angular Acceleration""](https://web.archive.org/web/20070122155954/http://www.physics.uoguelph.ca/tutorials/torque/Q.torque.intro.angacc.html). Archived from [the original](http://www.physics.uoguelph.ca/tutorials/torque/Q.torque.intro.angacc.html) on 2007-01-22. Retrieved 2007-01-05. <a id="^ref-17"></a>^ref-17
18. <a id="CITEREFHarrisStöcker1998"></a> Harris, John W.; Stöcker, Horst \(1998\). [_Handbook of mathematics and computational science_](https://books.google.com/books?id=DnKLkOb_YfIC&pg=PA332). Birkhäuser. Chapter 6, p. 332. [ISBN](ISBN%20(identifier).md) [0-387-94746-9](https://en.wikipedia.org/wiki/Special:BookSources/0-387-94746-9). <a id="^ref-18"></a>^ref-18
19. [Kane & Levinson 1996](#CITEREFKaneLevinson1996), pp. 20–22 <a id="^ref-19"></a>^ref-19
20. <a id="CITEREFRogers2007"></a> Rogers, Robert M. \(2007\). _Applied mathematics in integrated navigation systems_ \(3rd ed.\). Reston, Va.: American Institute of Aeronautics and Astronautics. [ISBN](ISBN%20(identifier).md) [9781563479274](https://en.wikipedia.org/wiki/Special:BookSources/9781563479274). [OCLC](OCLC%20(identifier).md#OCLC) [652389481](https://search.worldcat.org/oclc/652389481). <a id="^ref-20"></a>^ref-20

## references

This text incorporates [content](https://en.wikipedia.org/wiki/Euclidean_vector) from [Wikipedia](Wikipedia.md) available under the [CC BY-SA 4.0](https://creativecommons.org/licenses/by-sa/4.0/) license.

### mathematical treatments

- <a id="CITEREFApostol1967"></a> [Apostol, Tom](Tom%20Apostol.md) \(1967\). [_Calculus_](https://archive.org/details/calculus01apos). Vol. 1: One-Variable Calculus with an Introduction to Linear Algebra. Wiley. [ISBN](ISBN%20(identifier).md) [978-0-471-00005-1](https://en.wikipedia.org/wiki/Special:BookSources/978-0-471-00005-1).
- <a id="CITEREFApostol1969"></a> [Apostol, Tom](Tom%20Apostol.md) \(1969\). [_Calculus_](https://archive.org/details/calculus01apos). Vol. 2: Multi-Variable Calculus and Linear Algebra with Applications. Wiley. [ISBN](ISBN%20(identifier).md) [978-0-471-00007-5](https://en.wikipedia.org/wiki/Special:BookSources/978-0-471-00007-5).
- <a id="CITEREFHeinbockel2001"></a> Heinbockel, J. H. \(2001\), [_Introduction to Tensor Calculus and Continuum Mechanics_](http://www.math.odu.edu/~jhh/counter2.html), Trafford Publishing, [ISBN](ISBN%20(identifier).md) [1-55369-133-4](https://en.wikipedia.org/wiki/Special:BookSources/1-55369-133-4).
- <a id="CITEREFItô1993"></a> Itô, Kiyosi \(1993\), _Encyclopedic Dictionary of Mathematics_ \(2nd ed.\), [MIT Press](MIT%20Press.md), [ISBN](ISBN%20(identifier).md) [978-0-262-59020-4](https://en.wikipedia.org/wiki/Special:BookSources/978-0-262-59020-4).
- <a id="CITEREFIvanov2001"></a> Ivanov, A.B. \(2001\) \[1994\], ["Vector"](https://www.encyclopediaofmath.org/index.php?title=Vector), _[Encyclopedia of Mathematics](Encyclopedia%20of%20Mathematics.md)_, [EMS Press](European%20Mathematical%20Society.md).
- <a id="CITEREFKaneLevinson1996"></a> Kane, Thomas R.; Levinson, David A. \(1996\), _Dynamics Online_, Sunnyvale, California: OnLine Dynamics.
- <a id="CITEREFLang1986"></a> [Lang, Serge](Serge%20Lang.md) \(1986\). _Introduction to Linear Algebra_ \(2nd ed.\). Springer. [ISBN](ISBN%20(identifier).md) [0-387-96205-0](https://en.wikipedia.org/wiki/Special:BookSources/0-387-96205-0).
- <a id="CITEREFPedoe1988"></a> [Pedoe, Daniel](Daniel%20Pedoe.md) \(1988\). [_Geometry: A comprehensive course_](https://archive.org/details/geometrycomprehe0000pedo). Dover. [ISBN](ISBN%20(identifier).md) [0-486-65812-0](https://en.wikipedia.org/wiki/Special:BookSources/0-486-65812-0).

### physical treatments

- <a id="CITEREFAris1990"></a> Aris, R. \(1990\). [_Vectors, Tensors and the Basic Equations of Fluid Mechanics_](https://archive.org/details/vectorstensorsba00aris). Dover. [ISBN](ISBN%20(identifier).md) [978-0-486-66110-0](https://en.wikipedia.org/wiki/Special:BookSources/978-0-486-66110-0).
- <a id="CITEREFFeynmanLeightonSands2005"></a> [Feynman, Richard](Richard%20Feynman.md); Leighton, R.; Sands, M. \(2005\). "Chapter 11". [_The Feynman Lectures on Physics_](The%20Feynman%20Lectures%20on%20Physics.md). Vol. I \(2nd ed.\). Addison Wesley. [ISBN](ISBN%20(identifier).md) [978-0-8053-9046-9](https://en.wikipedia.org/wiki/Special:BookSources/978-0-8053-9046-9).

## external links

> ![Wikiquote logo](../../archives/Wikimedia%20Commons/Wikiquote-logo.svg) Wikiquote has quotations related to ___[Euclidean vector](https://en.wikiquote.org/wiki/Special%3ASearch/Euclidean%20vector)___.

<!-- markdownlint MD028 -->

> ![Wikimedia Commons logo](../../archives/Wikimedia%20Commons/Commons-logo.svg) Wikimedia Commons has media related to ___[Vectors](https://commons.wikimedia.org/wiki/Category%3AVectors)___.

<!-- markdownlint MD028 -->

> ![Wikibooks logo](../../archives/Wikimedia%20Commons/Wikibooks-logo-en-noslogan.svg) The Wikibook _[Waves](https://en.wikibooks.org/wiki/Waves)_ has a page on the topic of: ___[Vectors](https://en.wikibooks.org/wiki/Waves/Vectors)___

- ["Vector"](https://www.encyclopediaofmath.org/index.php?title=Vector), _[Encyclopedia of Mathematics](Encyclopedia%20of%20Mathematics.md)_, [EMS Press](European%20Mathematical%20Society.md), 2001 \[1994\]
- [Online vector identities](https://web.archive.org/web/20120801005307/http://wwwppd.nrl.navy.mil/nrlformulary/vector_identities.pdf) \([PDF](Portable%20Document%20Format.md)\)
- [Introducing Vectors](http://www.marco-learningsystems.com/pages/roche/introvectors.htm) A conceptual introduction \([applied mathematics](applied%20mathematics.md)\)

|                                                     | <!-- - [v](https://en.wikipedia.org/wiki/Template:Linear%20algebra) <br/> - [t](https://en.wikipedia.org/wiki/Template%20talk:Linear%20algebra) <br/> - [e](https://en.wikipedia.org/wiki/Special:EditPage/Template%3ALinear%20algebra) <br/> --> [Linear algebra](linear%20algebra.md)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               |                                                                                                                                          |
| --------------------------------------------------: | --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ---------------------------------------------------------------------------------------------------------------------------------------- |
|                                                     | - [Outline](outline%20of%20linear%20algebra.md) <br/> - [Glossary](glossary%20of%20linear%20algebra.md)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               |                                                                                                                                          |
|                                  __Basic concepts__ | - [Scalar](scalar%20(mathematics).md) <br/> - [Vector](Euclidean%20vector.md) <br/> - [Vector space](vector%20space.md) <br/> - [Scalar multiplication](scalar%20multiplication.md) <br/> - [Vector projection](vector%20projection.md) <br/> - [Linear span](linear%20span.md) <br/> - [Linear map](linear%20map.md) <br/> - [Linear projection](projection%20(linear%20algebra).md) <br/> - [Linear independence](linear%20independence.md) <br/> - [Linear combination](linear%20combination.md) <br/> - [Multilinear map](multilinear%20map.md) <br/> - [Basis](basis%20(linear%20algebra).md) <br/> - [Change of basis](change%20of%20basis.md) <br/> - [Row and column vectors](row%20and%20column%20vectors.md) <br/> - [Row and column spaces](row%20and%20column%20spaces.md) <br/> - [Kernel](kernel%20(linear%20algebra).md) <br/> - [Eigenvalues and eigenvectors](eigenvalues%20and%20eigenvectors.md) <br/> - [Transpose](transpose.md) <br/> - [Linear equations](system%20of%20linear%20equations.md) | [![Three dimensional Euclidean space](../../archives/Wikimedia%20Commons/Linear%20subspaces%20with%20shading.svg)](Euclidean%20space.md) |
|           __[Matrices](matrix%20(mathematics).md)__ | - [Block](block%20matrix.md) <br/> - [Decomposition](matrix%20decomposition.md) <br/> - [Invertible](invertible%20matrix.md) <br/> - [Minor](minor%20(linear%20algebra).md) <br/> - [Multiplication](matrix%20multiplication.md) <br/> - [Rank](rank%20(linear%20algebra).md) <br/> - [Transformation](transformation%20matrix.md) <br/> - [Cramer's rule](Cramer's%20rule.md) <br/> - [Gaussian elimination](Gaussian%20elimination.md) <br/> - [Productive matrix](productive%20matrix.md) <br/> - [Gram matrix](Gram%20matrix.md)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  |                                                                                                                                          |
|                   __[Bilinear](bilinear%20map.md)__ | - [Orthogonality](orthogonality.md) <br/> - [Dot product](dot%20product.md) <br/> - [Hadamard product](Hadamard%20product%20(matrices).md) <br/> - [Inner product space](inner%20product%20space.md) <br/> - [Outer product](outer%20product.md) <br/> - [Kronecker product](Kronecker%20product.md) <br/> - [Gram–Schmidt process](Gram–Schmidt%20process.md)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        |                                                                                                                                          |
| __[Multilinear algebra](multilinear%20algebra.md)__ | - [Determinant](determinant.md) <br/> - [Cross product](cross%20product.md) <br/> - [Triple product](triple%20product.md) <br/> - [Seven-dimensional cross product](seven-dimensional%20cross%20product.md) <br/> - [Geometric algebra](geometric%20algebra.md) <br/> - [Exterior algebra](exterior%20algebra.md) <br/> - [Bivector](bivector.md) <br/> - [Multivector](multivector.md) <br/> - [Tensor](tensor.md) <br/> - [Outermorphism](outermorphism.md)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         |                                                                                                                                          |
| __[Vector space](vector%20space.md) constructions__ | - [Dual](dual%20space.md) <br/> - [Direct sum](direct%20sum%20of%20modules.md#construction%20for%20two%20vector%20spaces) <br/> - [Function space](function%20space.md#in%20linear%20algebra) <br/> - [Quotient](quotient%20space%20(linear%20algebra).md) <br/> - [Subspace](linear%20subspace.md) <br/> - [Tensor product](tensor%20product.md)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |                                                                                                                                          |
|    __[Numerical](numerical%20linear%20algebra.md)__ | - [Floating-point](floating-point%20arithmetic.md) <br/> - [Numerical stability](numerical%20stability.md) <br/> - [Basic Linear Algebra Subprograms](Basic%20Linear%20Algebra%20Subprograms.md) <br/> - [Sparse matrix](sparse%20matrix.md) <br/> - [Comparison of linear algebra libraries](comparison%20of%20linear%20algebra%20libraries.md)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      |                                                                                                                                          |
|                                                     | - ![category icon](../../archives/Wikimedia%20Commons/Symbol%20category%20class.svg) <br/>  [Category](https://en.wikipedia.org/wiki/Category:Linear%20algebra)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       |                                                                                                                                          |

|                                                                                                                                                                                                                                                                  |                                              |
| ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------:| -------------------------------------------- |
| __[Authority control databases](https://en.wikipedia.org/wiki/Help:Authority%20control): National [![Edit this at Wikidata](../../archives/Wikimedia%20Commons/OOjs%20UI%20icon%20edit-ltr-progressive.svg)](https://www.wikidata.org/wiki/Q44528#identifiers)__ | - [Germany](https://d-nb.info/gnd/4202708-1) |

> [Categories](https://en.wikipedia.org/wiki/Help:Category):
>
> - [Kinematics](https://en.wikipedia.org/wiki/Category:Kinematics)
> - [Abstract algebra](https://en.wikipedia.org/wiki/Category:Abstract%20algebra)
> - [Vector calculus](https://en.wikipedia.org/wiki/Category:Vector%20calculus)
> - [Linear algebra](https://en.wikipedia.org/wiki/Category:Linear%20algebra)
> - [Concepts in physics](https://en.wikipedia.org/wiki/Category:Concepts%20in%20physics)
> - [Vectors \(mathematics and physics\)](https://en.wikipedia.org/wiki/Category:Vectors%20%28mathematics%20and%20physics%29)
> - [Analytic geometry](https://en.wikipedia.org/wiki/Category:Analytic%20geometry)
> - [Euclidean geometry](https://en.wikipedia.org/wiki/Category:Euclidean%20geometry)
